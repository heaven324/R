■ R 을 배워야하는 이유

■ R 시작하기
	- R의 자료구조

■ 기본 데이터 검색									문제 1 ~ 3

■ R에서 사용하는 연산자 총정리							문제 4 ~ 5

■ R shiny 설치									문제 6

■ 기타 비교 연산자									문제 7 ~ 13
	- 중복제거 작업								문제 14
	- 정렬 작업									문제 15 ~ 22
	- 함수
	- 문자함수									문제 23 ~ 27
	- gsub 설명									문제 28 ~ 35

■ 날짜함수										문제 36 ~ 39
	- R로 next_day 함수 만들기							문제 40
	- 변환함수									문제 41 ~ 47

■ R에서의 그룹 함수									문제 48 ~ 73

■ R로 조인하는 방법									문제 74 ~ 84

■ 팩터(factor) 자료형이란?								문제 85 ~ 96

■ R로 서브쿼리 구현하기								문제 97 ~ 104
	
■ 순위 출력을 R로 구현하는 방법							문제 105 ~ 108

■ R shiny 사용 방법									문제 109 ~ 113

■ R에서 그래프 그리는 방법
	- 막대 그래프									문제 114 ~ 123
	- 데이터 분석 시각화 가격
	- 원형 그래프를 샤이니로 시각화						문제 124 ~ 129
	- 라인(plot) 그래프								문제 130 ~ 135
	- ggplot2 막대 그래프 그리기							문제 136
	- plotly 원형 그래프								문제 137
	- 소리를 그래프로 시각화 하는 방법						문제 138 ~ 141
	- 산포도와 상관관계								문제 142 ~ 143
	- 사분위수 그래프								문제 144
	- 샤이니에 데이터 테이블 표시하는 방법					문제 145
	- 오라클 database 와 R 과의 연동						문제 146 ~ 150
	- Rjava 오류 해결
	- 지도 그래프 									문제 151 ~ 161

■ R을 활용한 머신러닝
	- 머신러닝 책 수업 목차 

■ 1장. 머신러닝이란 ? 

■ 2장. 머신러닝을 배우기 위해 기본적으로 알고 있어야 하는 내용
	- 데이터의 종류
	- 평균값									문제 162 ~ 164
	- 편향										문제 165
	- 왜도와 첨도 (p99)								문제 166 ~ 168
	- 최빈값									문제 169
	- 범위 										문제 170 ~ 172
	- 분산과 표준편차								문제 173
	- 범주형 데이터 살펴보기(p 103)						문제 174
	- 산포도 그래프 (p 106)							문제 175 ~ 176
		
■ 이원 교차표 p108 									문제 177 ~ 179
	- 머신러닝에서 이원교차표를 어떻게 활용하는가 ?
	- R 에서의 함수 생성 방법							문제 180 ~ 181
	- R 에서의 for  loop 문 							문제 182 ~ 184
	- R에서의 if문 								문제 185 ~ 186

■ knn
	- knn 알고리즘의 장단점
	- knn으로 분류하기 전에 전처리 해야하는 사항				문제 187 ~ 193
	- Knn 의 분류 실습 ( 유방암 데이터 악성과 양성 분류)
	- 현업에서 데이터 분석할때 필요한 사항
	- data shuffle 시키고 내리기
	- train 과 test 로 나누기

■ 4장. 나이브 베이즈 분류
	- 확률에 대한 기본적인 이해 (pdf)
	- 나이브 베이즈 알고리즘 (p 152)
	- 나이브 베이즈 복습 								문제 194 ~ 198
	- 라플라스 추정기 (P 155 페이지) 						문제 199 ~ 200

■ 5장. 의사결정 트리와 규칙 기반 분류
	- 엔트로피와 정보 획득량
	- 엔트로피(entropy) 함수							문제 201 ~ 206
	- C5.0패키지를 이용해서 분류 모델 생성
	- 백화점 화장품 고객 중에 구매가 예상이 되는 고객이 누구인가?		문제 207 ~ 208
	- 은행 대출 채무 불이행할 것 같은 고객이 누구인가 ?			문제 209 ~ 211
	- 규칙 기반 알고리즘
	- 규칙 기반 분류 알고리즘 (oneR 실습)
	- 규칙 기반 분류 알고리즘 (JRiper 실습)

■ 6장. 회귀 분석
	- 단순 선형 회귀 분석 이론
	- 회귀 분석이란 ?
	- 최소 제곱 추정법 (p253)							문제 213 ~ 220
	- 상관관계 (p256)								문제 221 ~ 226
	- 다중 선형 회귀 분석 (p 258)
	- 다중 회귀식의 베타값을 구하는 함수 생성하는 방법			문제 227 ~ 232
	- 다중 선형 회귀를 이용한 의료비 예측 실습					문제 235 ~ 238
	- Multiple R-squared와 Adjusted R-squared의 차이 ?
	- p-value값 확인								문제 239
	- 다중 회귀 세번째 ppt설명
	- 정규화(표준화)를 하는 경우와 안하는 경우					문제 240
	- 회귀 트리 (p282)
	- 회귀 트리 (Regression Tree)  						문제 241
	- 와인 데이터로 의사결정 트리 시각화
	- 와인 데이터의 품질을 예측하는 모델을 모델트리를 이용해서 생성

■ 7장. 신경망과 서포트 벡터 머신
	- 활성화 함수 소개 								문제 242 ~ 244
	- 신경망 실습1 (콘크리트 데이터)
	- 회귀 트리일 때 사용했던 와인 데이터를 신경망에 넣고 테스트
	- 신경망 실습 2(와인 데이터 )						문제 245
	- 신경망 실습 2 ( 필기체 데이터 )						문제 246 ~ 247
	- 보스톤 집값을 예측하는 신경망 구현하기					문제 248 ~ 250

■ 8장. 연관규칙
	- apriori 알고리즘 예제 1  (맥주와 기저귀)					문제 251
	- 영화 라라랜드의 긍정적 평가와 부정적 평가에 대한 워드 클라우드	문제 252

■ 9장 K-means 군집화
	- k-means군집화 이론 수업
	- k-means 기본 실습								문제 253
	- k평균 군집화 실습1 ( 국영수 점수를 가지고 학생 분류 )			문제 254 ~ 258 
	- k 평균 군집화 실습( 소개팅 데이터 )					문제 259 ~ 260
	- k 평균 군집화 실습2(쇼설 미디어에 같은 성향을 갖는 사람들을 분류)	문제 261

■ 10장. 모델 성능 평가
	- 모델 성능 평가가 중요한 이유가 무엇인가?
	- 정확도란 무엇인가?
	- 그럼 다른 성능 척도에는 무엇이 있는가?
	- 이원 교차표에서 정확도와 오류율을 확인하는 방법				문제 262
	- 카파 통계량 									문제 263
	- 민감도와 특이도 (p440)
	- 정밀도와 재현율(p 442)							문제 264 ~ 265
	- F 척도 ( p 445)								문제 266
	- 성능 트레이드 오프 시각화 (p 446)
	- 홀드 아웃 방법 ( p453 )
	- k-폴드 교차 검증 테스트

■ 11장. 모델 성능 개선
	- 정확도를 올리기 위한 방법에 대한 질문 3가지 (p 468)
	- caret 패키지를 이용한 모델 파라미터 자동 튜닝
	- 독일 은행의 대출 여부 데이터로 의사결정 트리 실습
	- 자동 파라미터 튜닝했을때 정확도
	- 튜닝 절차 커스터 마이징 하기 (p 475)					문제 267
	- 앙상블의 이해 (p 481)
	- 독일 채무 불이행자를 예측하는 모델을 bagging기법으로 실습 		문제 268
	- 랜덤 포레스트 (p 493)							문제 269 ~ 270
	- 부스팅(Boosting) (p 486)

■ 7장. 서포트 벡터 머신
	- 서포트 벡터 머신에서 오버피팅을 줄이는 방법				문제 277 ~ 280
■ 문제 모음
■ R 수업  

 * R 수업 일정

  1. R 기본 문법을 익히는 수업 (1주일)
        - R 을 배워야하는 이유
        - R 의 자료구조
        - R 의 연산자
        - R 의 함수
        - R 에서의 조인
        - R 에서의 서브쿼리
        - R 에서의 그래프
        - R 에서의 if 문과 loop 문 사용법

  2. R 을 활용한 머신러닝 (2주일)

        - 머신러닝의 종류 3가지
            1. 지도학습 :
                  분류 : 의사결정트리, 신경망,
                         서포트 백터 머신, 나이브 베이즈,
                         knn
                  회귀 : 선형회귀
            2. 비지도 학습 : K-means
            3. 강화학습     

  3. 통계수업 (오전 통계 수업, 오후 포트폴리오 제작)
         - 데이터의 종류
         - 데이터 수치 요약
         - 확률과 확률변수
         - 확률과 표본분포
         - 통계적 추정
         - 통계적 가설검정

  R 포트폴리오 --->  개별로 만들어도 되고 그룹으로 만들어도 된다.

	  데이터 분석가 와                      딥러닝 연구원
	     ↓                                     ↓
	  R , python , 기본 통계지식 필수 사항    python, 딥러닝
	    
	    포트폴리오                             포트폴리오







■  R 을 배워야하는 이유

	 " 데이터 분석가 모집요망에 SQL 과 R , Python 은 필수이다 "
	
	 카카오톡이 2010년 3월에 서비스를 시작한 이후 폭발적으로 성장해서 2012년 말에 8000 만명의
	 가입자를 넘어 섰다.
	  
	 하루 평균 43분간 카카오톡을 하고 하루 방문자가 2700만명, 하루 최대 메세지 이용건수가 42억건에 달함.

	 문자해 ---> 카톡해
	
	 이런 성공에도 불구하고 마땅한 수익모델이 없어서
	
	 2010년 41억 적자
	 2011년 153억 적자
	
	         <------ 카톡 사용자들에 대한 data분석이 있음 다음
	                 부터
	 2012년에 애니팡의 인기에 힘입어 흑자라인으로 들어섰다.
	 개발자 통장에 하루 1억씩 입금
	
	 중간에 카톡 사용자들을 어떻게 분석
	
	 1. 누가(성별,연령)
	 2. 무엇을(게임 아이템)
	 3. 언제 ( 아이템 구매시간)
	 4. 얼마나 (아이템 구매빈도)
	 5. 어떻게 (결제 방법)
■ R 시작하기


★ R 설치

	  - 기본 R 프로그램
	
	  - R studio  <--- SQL gate, spider, pycham 와 같은툴













★ 작업 디렉토리 변경 및 emp.csv 로드하는 방법

	* 작업 디렉토리 변경

		> setwd("c:\\R")
		> emp <- read.csv("emp.csv", header=T)
		>
		> emp
		   empno  ename       job  mgr   hiredate  sal comm deptno
		1   7369  SMITH     CLERK 7902 1980-12-17  800   NA     20
		2   7499  ALLEN  SALESMAN 7698 1981-02-20 1600  300     30
		3   7521   WARD  SALESMAN 7698 1981-02-22 1250  500     30
		4   7566  JONES   MANAGER 7839 1981-04-02 2975   NA     20
		5   7654 MARTIN  SALESMAN 7698 1981-09-28 1250 1400     30
		6   7698  BLAKE   MANAGER 7839 1981-05-01 2850   NA     30
		7   7782  CLARK   MANAGER 7839 1981-06-09 2450   NA     10
		8   7788  SCOTT   ANALYST 7566 1987-04-19 3000   NA     20
		9   7839   KING PRESIDENT   NA 1981-11-17 5000   NA     10
		10  7844 TURNER  SALESMAN 7698 1981-09-08 1500    0     30
		11  7876  ADAMS     CLERK 7788 1987-05-23 1100   NA     20
		12  7900  JAMES     CLERK 7698 1981-12-03  950   NA     30
		13  7902   FORD   ANALYST 7566 1981-12-03 3000   NA     20
		14  7934 MILLER     CLERK 7782 1982-01-23 1300   NA     10
		15  9292   JACK     CLERK 7782 1982-01-23 3200   NA     70










★ SQL과 R의 차이 ?

	"아주 긴 SQL코드를 R 코드로는 단순하게 작성할 수 있다."

	SQL> select deptno, sum(decode(job, 'SALESMAN', sal, 0 ) ),
			    sum(decode(job, 'ANALYST', sal, 0 ) )
		from emp
		group by deptno;

	R> attach(emp)
	R> tapply(sal, list(deptno, job), sum)
	    ANALYST CLERK MANAGER PRESIDENT SALESMAN
	 10      NA  1300    2450      5000       NA
	 20    6000  1900    2975        NA       NA
	 30      NA   950    2850        NA     5600
	 70      NA  3200      NA        NA       NA

		"데이터를 시각화할 수 있다."

	R> pie(emp$sal, col=rainbow(14))











★ R이란 무엇인가?

	뉴질랜드의 aukland대학의 robert gentlman과 Ross ihaka가 1995년에 개발한 소프트웨어이고 데이터
	분석을 위한 통계 및 그래픽스를 지원하는 무료 소프트웨어이다.











★ R을 왜 사용해야 하는가?

	1. R is ★free★
	2. data 분석을 위해서 가장 많이 쓰는 통계 플랫폼
	3. 복잡한 데이터를 다양한 그래프로 표현할 수 있다.
	4. 분석을 위한 데이터를 쉽게 저장하고 조작할 수 있다.
	5. 누구든지 ★유용한 패키지★를 생성해서 공유할 수 있고, 새로운 기능에 대한 전달이 빠르다.
	6. 어떠한 OS에서도 설치가 가능하다. (심지어 아이폰에서도 설치가 가능하다.)












★ R의 자료구조
	

	1. vector : 같은 데이터 타입을 갖는 1차원 배열구조
	2. matrix : 같은 데이터 타입을 갖는 2차원 배열구조
	3. array  : 같은 데이터 타입을 갖는 다차원 배열구조
	4. data.frame : 각각의 데이터 타입을 갖는 컬럼으로 이루어진 2차원 배열구조
			(rdbms의 테이블과 유사함)

		예 : 오라클 	vs	 R
		     desc emp 		str(emp)

		> str(emp)
		'data.frame':   15 obs. of  8 variables:
		 $ empno   : int  7369 7499 7521 7566 7654 7698 7782 7788 7839 7844 ...
		 $ ename   : Factor w/ 15 levels "ADAMS","ALLEN",..: 13 2 15 8 10 3 4 12 9 14 ...
		 $ job     : Factor w/ 5 levels "ANALYST","CLERK",..: 2 5 5 3 5 3 3 1 4 5 ...
		 $ mgr     : int  7902 7698 7698 7839 7698 7839 7839 7566 NA 7698 ...
		 $ hiredate: Factor w/ 13 levels "1980-12-17","1981-02-20",..: 1 2 3 4 8 5 6 12 9 7 ...
		 $ sal     : int  800 1600 1250 2975 1250 2850 2450 3000 5000 1500 ...
		 $ comm    : int  NA 300 500 NA 1400 NA NA NA NA 0 ...
		 $ deptno  : int  20 30 30 20 30 30 10 20 10 30 ...

	5. list : 서로다른 데이터 구조(vector, data frame, matrix, array)인 데이터 타입이 중첩된 구조
■ 기본 데이터 검색
문제 1 ~ 3
■ R에서 사용하는 연산자 총정리
문제 4 ~ 5
	1. 산술연산자 : * / + -
	2. 비교연산자 : >, <, >=, <=, ==, !=
	3, 논리연산자 : &  : and (벡터화된 연산)
			&& : amd (벡터화되지 않은 연산)
			 | : or  (벡터화된 연산)
			|| : or  (벡터화되지 않은 연산)
			 ! : not

	※ 벡터화된 연산 vs 벡터화되지 않은 연산
		예 :
			x <- c(1,2,3)
			x > c(1,1,1) & x < c(3,3,3)

			x <- 1
			x > -2 && x < 2




■ R shiny 설치
문제 6
	install.packages("shiny")
	library(shiny)
	runExample("01_hello")
	runExample("02_text")
	runExample("03_reactivity")
	runExample("04_mpg")	
	runExample("05_sliders")
	runExample("06_tabsets")
	runExample("07_widgets")
	runExample("08_html")
	runExample("09_upload")
	runExample("10_download")
	runExample("11_timer")

	전기수 누가 만든 Shinycode 실행해보기
■ 기타 비교 연산자
문제 7 ~ 13
		SQL 		vs	 	R
	1. in				       %in%
	2. like				       grep
	3. is null			       is.na
	4. between .. and		emp$sal >= 1000 &
					emp$sal <= 3000




★ 중복제거 작업
문제 14





★ 정렬 작업
문제 15 ~ 22
		SQL 		vs		R
	     order by			1. data frame에서 order옵션
					2. doBy 패키지를 설치하고
					   orderBy함수를 사용




★ 함수
	1. 문자함수
	2. 숫자함수
	3. 날짜함수
	4. 변환함수
	5. 일반함수




★ 문자함수
문제 23 ~ 27
		SQL		vs		R
	       upper			      toupper
	       lower			      tolower
	       substr			      substr
	       replace			      gsub



★ gsub 설명 ─▶ gsub('h', 'H', text)
			특정 text에서 소문자 h를 대문자 H로 변경해라~
문제 28 ~ 35
■ 날짜함수
문제 36 ~ 39
		SQL		vs		R
	      sysdate			    Sys.Date()
	      add_months		    difftime
	      months_between		    사용자 정의 함수
	      last_day			    사용자 정의 함수
	      next_day			    사용자 정의 함수



setwd("c:\\R")

source('C:/R/start.R', local=TRUE, echo=TRUE,  encoding = 'UTF-8')




★ R로 next_day 함수 만들기
문제 40



★ 변환함수
문제 41 ~ 47
		SQL		vs		R
	      to_char			   as.character ───▶ 문자로 형변환
	      to_number			   as.integer   ───▶ 숫자로 형변환
	      to_date			   as.Date      ───▶ 날짜로 형변환
					   as.Factor    ───▶ factor형으로 변환하는 함수

					   format 함수
						%Y ─▶ 년도
						%m ─▶ 달
						%d ─▶ 일
						%A ─▶ 요일
■ R에서의 그룹 함수
문제 48 ~ 73
		Oracle		vs		R
		1. max				max
		2. min				min
		3. sum				sum
		4. avg				mean
		5. count			length (가로)
						table  (세로)
■ R로 조인하는 방법
문제 74 ~ 84
		오라클		vs		R
	      equi join
	     non equi join			merge
	      outer join
	       self join
■ 팩터(factor) 자료형이란?
문제 85 ~ 96
	- 범주(값의 목록)을 갖는 vector
	- 종류가 2가지 인데
		1. nominal ─▶  level의 순서의 값이 무의미 하다.
		 		 (알파벳 순서로 정의)
		2. ordinal ─▶  level의 순서의 값을 직접 정의해서 원하는 순서로 정의 할 수 있다.

	# 예제 :
		a <- c("middle", "low", "high")
		str(a)
		
		b <- factor(a)
		str(b)
		
		c <- factor(a, order=TRUE, level = c("low", "middle", "high"))
		str(c)
		
		max(c)
		min(c)
		c[order(c,decreasing = F)]




install.packages("plotrix")
install.packages("igraph")
install.packages("googleVis")
■ R로 서브쿼리 구현하기
문제 97 ~ 104
	* 오라클의 서브쿼리 3가지
		1. single row subquery
		2. multiple row subquery
		3. multiplecolumn subquery

■ 순위 출력을 R로 구현하는 방법
문제 105 ~ 108
		SQL		vs		R
	     dense_rank			       rank
■ R shiny 사용 방법
문제 109 ~ 113
	https://shiny.rstudio.com/gallery/


★ R shiny가 무엇인가?

	R의 강력한 그래픽 기능과 통계 분석 능력을 이용하고, 사용자 상호작용을 쉽게 만들 수 있는 언어

	샤이니 패키지를 이용해서 편하게 사용자 인터페이스(User Interface)를 이용할 수 있다.


★ R 샤이니 기본 골격

	유저 인터페이스와 서버
	   ↓		   ↓
	frontier 	backend tier


	1. 화면 개발
		UI <- ......

	2. 서버단 개발
		server <- .......

	3. 실행하는 명령어
		shinyApp(ui=ui, server=server)





샤이니 기본 예제 1.

	install.packages("DT")
        install.packages("ggplot2")
        library(DT)
        library(ggplot2)
        
        head(mpg)
        str(mpg)
        
        #install.packages("DT")
        
        library(DT)
        library(shiny)
        library(ggplot2)
        
        # Define UI ----
        ui <- fluidPage(
            titlePanel("Basic DataTable"),
            
            # Create a new Row in the UI for selectInputs
            fluidRow(
                column(4,
                       selectInput("man",
                                   "Manufacturer:",
                                   c("All",
                                     unique(as.character(mpg$manufacturer))))
                ),
                column(4,
                       selectInput("trans",
                                   "Transmission:",
                                   c("All",
                                     unique(as.character(mpg$trans))))
                ),
                column(4,
                       selectInput("cyl",
                                   "Cylinders:",
                                   c("All",
                                     unique(as.character(mpg$cyl))))
                )
            ),
            # Create a new row for the table.
            DT::dataTableOutput("table")
        )
        )
        # Define server logic ----
        server <- function(input, output) {
            # Filter data based on selections
            output$table <- DT::renderDataTable(DT::datatable({
                data <- mpg
                if (input$man != "All") {
                    data <- data[data$manufacturer == input$man,]
                }
                if (input$cyl != "All") {
                    data <- data[data$cyl == input$cyl,]
                }
                if (input$trans != "All") {
                    data <- data[data$trans == input$trans,]
                }
                data
            }))
        }
        
        # Run the app ----
        shinyApp(ui = ui, server = server)








샤이니 기본 예제 2.

	#install.packages("DT")
        
        #library(DT)
        library(shiny)
        library(ggplot2)
        
        emp <- read.csv("d:\\emp.csv",header=T)
        
        # Define UI ----
        ui <- fluidPage(
            titlePanel("EMP 데이터 테이블"),
            
            
            # Create a new Row in the UI for selectInputs
            fluidRow(
                column(4,
                       selectInput("job",
                                   "job:",
                                   c("All",
                                     unique(as.character(emp$job))))
                ),
                column(4,
                       selectInput("deptno",
                                   "deptno:",
                                   c("All",
                                     unique(as.character(emp$deptno))))
                ),
                column(4,
                       selectInput("sal",
                                   "sal:",
                                   c("All",
                                     unique(as.character(emp$sal))))
                )
            ),
            # Create a new row for the table.
            DT::dataTableOutput("table")
        )
        
        
        )
        
        # Define server logic ----
        server <- function(input, output) {
            # Filter data based on selections
            output$table <- DT::renderDataTable(DT::datatable({
                data <- emp
                if (input$job != "All") {
                    data <- data[data$job == input$job,]
                }
                if (input$deptno != "All") {
                    data <- data[data$deptno == input$deptno,]
                }
                if (input$sal != "All") {
                    data <- data[data$sal == input$sal,]
                }
                data
            }))
            
            
        }
        
        # Run the app ----
        shinyApp(ui = ui, server = server)
■ R에서 그래프 그리는 방법

	1. 막대 그래프
	2. 원형 그래프
	3. 라인 그래프
	4. 특수 그래프 (지도, 소리 시각화, 워드 클라우드)
	5. 사분위수 그래프 ( 평균, 중앙값, 이상치 )





★ 막대 그래프
문제 114 ~ 123



★ 데이터 분석 시각화 가격

	테블로 분석 시각화 툴 -> 한사람당 300만원(슈퍼유저),
				일반유저 120만원

				1년, 2년 라이센스







★ 원형 그래프를 샤이니로 시각화
문제 124 ~ 129



★ 라인(plot) 그래프
문제 130 ~ 135


★ ggplot2 막대 그래프 그리기
문제 136
install.packages("ggplot2")

xdata <- as.factor(create_cnt[,"X"])
ydata <- as.factor(create_cnt[,"치킨집"])

xdata
ydata


fdata = data.frame(x=xdata, y=ydata)
fdata

library(ggplot2)

ggplot(fdata) + geom_bar(aes_string(x='x', y='y', fill='x'), stat="identity", show.legend=F)
						   ↓				↓
						legend 설정			legend 안보이게




★ plotly 원형 그래프
문제 137
install.packages("plotly")

library(plotly)

plot_ly(create_cnt, labels = ~colnames(create_cnt)[-1], values= ~as.factor(create_cnt[create_cnt$X=="2013",-1]), type="pie")





★ 소리를 그래프로 시각화 하는 방법
문제 138 ~ 141
	* 소리를 시각화 하기 위한 R 코드
		install.packages("tuneR")
		library(tuneR)
		audio <- readWave("output.wav")
		play(audio)
		head(audio@left, 1000)
		plot(head(audio@left,1000))





★ 산포도와 상관관계
문제 142 ~ 143
	" 산포도 그래프를 데이터간의 상관관계를 나타낼때 유용하다 "

	예제 : 나이와 소득관의 상관관계가 있는지 데이터를 시각화 하시오

		age_income <- read.csv("age_income.csv" , header=T)
		age_income

		plot(age_income$age,age_income$month_income, xlab="나이", ylab="소득", col="red", pch=16)

		




★ 사분위수 그래프
문제 144
	* 사분위수 그래프로 분석해야하는 데이터

	1. 데이터의 퍼짐정도가 매우 큰 경우
	2. 이상치 있는 경우
	3. 평균 하나로는 통계를 대표할 수 없다.
		중앙값, 최빈값, 최대값, 최소값, 평균값

	4. 사분위수 그래프를 가로로 눕혀놓고 보면 정규분포 모양을 확인할 수 있다.


	예제 :
		library(lattice)
		bwplot(emp$sal)
		summary(emp$sal)

		   Min. 	1st Qu.  	Median    	Mean 		3rd Qu.    	Max.
		    800    	1250    	1600    	2148    	2988    	5000
		    ↑		 ↑		 ↑		 ↑		 ↑		 ↑
		  최소값   1번째 사분위수       중앙값         평균값 	    3번째 사분위수     최대값
				(Q1)		 (Q2)				(Q3)




★ 샤이니에 데이터 테이블 표시하는 방법
문제 145
	샤이니 테이블 형태 출력_기본1.txt 참고




★ 오라클 database 와 R 과의 연동
문제 146 ~ 150
	install.packages('DBI')
	install.packages('RJDBC')
	
	library(RJDBC)
	library(DBI)	
	
	# ojdb6.zip ─▶ ojdbc6.jar 이름 변경
	driver <- JDBC('oracle.jdbc.driver.OracleDriver', 'ojdbc6.jar')
	
	oracle_db <- dbConnect(driver, 'jdbc:oracle:thin:@//127.0.0.1:1521/xe', 'scott', 'tiger')
	#포트 번호 확인하는 방법 :
	
	emp_query <- 'select * from emp'
	
	emp_data <- dbGetQuery(oracle_db, emp_query)
	
	emp_data



★ Rjava 오류 해결

	http://cafe.daum.net/oracleoracle/SRv4/13 <-- 참고
		
	1. 아래에서 java 64비트를 다운로드 받는다
	
	https://www.java.com/en/download/manual.jsp
	
	2. 자바 설치시 대상 폴더 변경으로 설치
	
	
	3. 아래와 같이 환경설정을 한다.
	
	Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre1.8.0_201')
	
	4. 설치를 한다.
	install.packages("rJava")
	
	library(rJava)





★ 지도 그래프
문제 151 ~ 161
■ R을 활용한 머신러닝

	통계수업

		-
		-
		-
		- 확률과 표본분포
		- 통게적 추정
		-


통계학 개론 ─────▶ 머신러닝








★ 머신러닝 책 수업 목차

		머신러닝  ◀─────  머신러닝

	1. 머신러닝이 무엇인지> (1장)

	2. 머신러닝을 배우기 위해 기본적으로 알아야하는 내용 (2장)  ◀── 1장. 데이터 종류
									   2장. 데이터 수치 요약
	3. 지도학습
		분류 :  knn		◀─── 산포도 그래프
			의사 결정 트리  ◀─── 엔트로피
			서포트 벡터 머신◀─── 오즈 비율 ───▶ 시그모이드
							   ───▶ 로지스틱 회귀
			나이브베이즈    ◀─── 확률 (3장. 확률과 확률 변수)
			신경망		◀─── 딥러닝
		회귀 :	선형회귀	◀─── 상관계수, 결정계수 (5장. 통계적 추정)

	4. 비지도 학습 : k-means ◀──── 산포도 그래프 + 거리계산

	5. 기타 머신러닝 기법 : 부스팅, 배깅 ◀───── Cohne's kappa

■ 1장. 머신러닝이란 ?

	ppt 참고





■ 2장. 머신러닝을 배우기 위해 기본적으로 알고 있어야 하는 내용

	- 통계학 개론
		1. 데이터의 종류
		2. 데이터 수치 요약 (평균값, 중앙값, 최빈값, 사분위수, 분산, 표준편차)
		3. 범주형 데이터
		4. 그래프
			- 산포도 그래프
			- 이원 교차표





★ 1. 데이터의 종류
	1. 범주형 데이터
		- 명목형(norminal) 데이터 : 몇개의 범주로 나누어진 자료
			예 : high, low, middle

		- 순서형(ordinal) 데이터 : 명목형 데이터 + 순서
			예 : low, middle, high


	2. 수치형 데이터
		- 이산형 데이터 (discreat : 뚜렷이 구별되다)
			주사위처럼 1 ~ 6 까지의 숫자
				예 : 2016년 음주운전 적발 건수 22만 6599건
				     계수(헤아려 얻는 것)

		- 연속형 데이터 : 연속적인 값을 갖는 데이터
			예 : 신장, 체중(82.321)
			     계량 (측정해서 얻는 것)
			이산형 데이터 보다는 연속형 데이터가 얻을 수 있는 정보가 많다

		* 연속형 데이터에 대한 기술적인 통계를 이용한 자료 요약 3가지

			1. 데이터의 중심화 경향      : 중앙값, 평균값, 최빈값

			2. 데이터의 퍼짐 정도	     : 분산(데이터의 퍼짐 정도),
						       표준편차(평균에 대한 범위,
						       범위

			3. 데이터의 분포와 대칭 정도 : 왜도(좌우로 기울어짐의 정도),
						       첨도(위아래로 뾰족한 정도)

	
	딥러닝 ──▶  분류
	통계   ──▶  분석

		두가지 데이터 분석 질문을 던지고 해결하는 방법으로 위의 통계기법들을 사용해볼 것이다.

			1. 헬스클럽에 오는 특정 사람에게 가장 적합한 훈련교실을 선정
				사용할 통계 기법? 평균값, 중앙값, 최빈값

			2. 농구선수 3명의 점수를 가지고 3명중에 가장 적합한 1명을 선택하기위한 분석
				사용할 통계 기법? 분산, 표준편차, 사분위수 그래프





★ 평균값
문제 162 ~ 164
	헬스클럽에 찾아와서 자신과 비슷한 나이대의 사람들이 있는 운동교실을 알려달라고 했다
		추천해준 교실의 사람들 나이대

		나이  19  20  21  145  147
		도수   3   6   3    1    1





★ 편향
문제 165
	만약 데이터가 오른쪽으로 편향되면 평균값은 중앙값의 오른쪽(높음)에 위치한다.
	만약 데이터가   왼쪽으로 편향되면 평균값은 중앙값의   왼쪽(낮음)에 위치한다.




★ 왜도와 첨도 (p99)
문제 166 ~ 168
	- 왜도 : 데이터의 좌우로 기울어짐의 정도 (skeness)
		왜도값 > 0  : 오른쪽으로 꼬리가 길다.
		왜도값 < 0  : 왼쪽으로 꼬리가 길다.

	- 첨도 : 위아래 뾰족한 정도 (kurtosis)
		첨도값이 3에 가까울 수록 정규분포에 해당하고 3보다 작은 경우는 완만한 곡선
		3보다 크면 뾰족한 곡선




★ 최빈값
문제 169
	  ○
 	 -↑-		" 저랑 나이대가 비슷한 10대들이 있는 수영교실에 저를 등록시켜 주세요 ~ "
 	 ↙↘
     10대 여학생	swim_class 나이  1  2  3  32  32  33
				   도수  3  4  2   2   4   3




# swim_class를 생성하고 평균값과 중앙값을 구하시오 !
        
        swim_class <- c(rep(1, 3), rep(2, 4), rep(3, 2), rep(31, 2), rep(32, 4), rep(33, 3))
        swim_class
        
        mean(swim_class)     # 17
        median(swim_class)   # 17

	이 여학생이 등록을 해서 가봤더니 수영교실 이름이
	" 엄마와 아기가 함께하는 수영교실 " 이었다.

	──▶ 평균값과 중앙값에 뭔가 문제가 있다는 것이다.

	1  1  1  2  2  2  2  3  3 □ 31 31 32 32 32 32 33 33 33
				  ↑
			       평균값 17
			       중앙값 17

	이 교실의 평균값과 중앙값은 교실에 17세인 사람이 없음에도 불구하고 모두 17이다.
	학생수가 짝수여서 존재하지 않는 값인 17이 나온게 문제다.
	그렇다면 홀수가 되면 중앙값이 어떻게 되는가?
	
	1  1  1  2  2  2  2  3  3  3 31 31 32 32 32 32 33 33 33
				  ↑
			       중앙값 3
				
	1  1  1  2  2  2  2  3  3 31 31 32 32 32 32 33 33 33 33
				  ↑
			       중앙값 31

	그래서 필요한 값이 "최빈값"이다.



☆ 최빈값(mode)이란?  평균과 중앙값 이외의 세번째 종류의 평균이 존재하는데 그게 바로 최빈값이다.

	최빈값이란 가장 흔하게 나타나는 값을 말한다.
	아래의 나온 2개의 데이터가 이 데이터를 대표할 수 있는 값이다.

			swim_class 나이  1  2  3  32  32  33
				   도수  3  4  2   2   4   3
					   ↑	      ↑




★ 범위
문제 170 ~ 172
	"평균값과 중앙값과 최빈값만으로는 데이터 분석을 하기엔 부족한 경우가 있다. 이런 평균데이터는
	 중심이 어디쯤인지 알려주지만 데이터가 어떤식으로 변화하는지에 대해서는 알려주지 않는다.
	 특정 데이터가 평균을 중심으로 어떻게 분포되어있는지 알려면 범위를 알아야 한다."

	질문 :  어느 농구단의 감독이 아래의 3명의 농구선수중 한명을 선택해야 할려고 데이터 분석을
		하려고 한다.
		아래의 3명의 선수의 게임장 점수를 가지고 평균값, 중앙값, 최빈값을 구하시오 !

		x1 <- c(7, 8, 9, 9, 10, 10, 11, 11, 12, 13)
        	x2 <- c(7, 9, 9, 10, 10, 10, 10, 11, 11, 13)
        	x3 <- c(3, 3, 6, 7, 7, 10, 10, 10, 11, 13, 30)
        	mean(x1)   # 10
        	mean(x2)   # 10
        	mean(x3)   # 10
        	median(x1) # 10
        	median(x2) # 10
        	median(x3) # 10
        	getmode(x1)# 9
        	getmode(x2)# 10
        	getmode(x3)# 10

		중앙값, 평균값, 최빈값이 다 동일해서 특정 선수를 선택하기가 어렵다. 그래서 감독이
		각 선수의 점수가 어떻게 분포가 되어 있는지 분포 방식을 측정할 수 있으면 결정을 내리는데
		도움을 줄 수 있을 것이다.

		range(x1)  # 7 13
		range(x2)  # 7 13
		range(x3)  # 3 30

		범위는 그 자체로는 데이터의 폭만을 설명할 뿐 그 안에서 데이터가 분포되는 방식은 설명해
		주지 않는다.
		특히 이상치에 민감하다.
		3번째 선수 같은 경우 만약 어쩌다 한번 잘한 게임(30점)인 이상치 때문에 범위가 넓어져
		버리게 되면 분석하기 어렵다.

		그래서 이상치로부터 멀어질 필요가 있다.

		사분위수 범위로 해결할 수 있다. (미니범위)
			사분범위 = 상한 사분위수 - 하한 사분위수





★ 분산과 표준편차
문제 173
   	사분위수 범위(미니범위) 가 유용한것 처럼 보이지만 때때로 정말 낮은 점수를 올리는 선수가 있다면
	어떻게 할까?

   	어떤 선수가 시합날 분위기를 망치면 우리는 리그를 포기해야 하나?

   	범위 혹으 사분범위가 가장 일관성 있는 선수가 누구인지 확실히 측정할 수 있을까?

  	더 정확하게 측정할 수는 없을까?

   	다시 말해 선수가 올린 점수의 변이를 측정하고 싶은것이다.

   	그 방법중에 하나가 각각의 값들이 평균으로부터 얼마나 떨어져 있는지를 확인하는 것이다.

   	만약 값들이 평균값들로부터 많이 떨어져 있다면 시합당일에 어떤 모습을 보여줄지 예상하기가
	어렵다.

   	그러나 값들이 평균값에 가까우면 시합날 어떤 모습일지 예측할 수 있다.

   	그게 무엇인가 ?      " 분산 " 이다.


	              ∑(x - 평균)²
	      분산 = ---------------
	                    n


   	그런데 우리가 정말 필요한것은 평균값으로부터의 거리를 제곱한 것이 아니라 그냥 거리 자체가
	분포되어 있는 양상을 알려주는 수이다.

   	그게 무엇인가 ?      " 표준 편차 " 이다.

	      표준편차(σ) = √분산
	
	      표준편차(σ)²= 분산


   	즉 정리하면 평균은 데이터의 중심에 어느 값이 있는지 설명해주지만 그것만으로는 부족하다.
	그래서 표준편차는 데이터가 어떻게 변동하는지 말해준다.


	선수1.    평균(μ) = 70
	          표준편차(σ) = 20
	          (슛 성공 확률)X = 75
	                    X -  μ
	   Z(표준점수) = ------------
	                      σ

	선수 1의 표준점수는 0.25


	선수2.    평균(μ) = 40
	          표준편차(σ) = 10
		  (슛 성공 확률)X = 55

		         X -  μ
	 Z(표준점수) = ------------
		            σ

	선수 2의 표준점수는 1.5



		※ 표준점수 혹은 z점수란?

   		평균 값과 표준편차가 서로 다른 데이터 집합을 비교하는 방법이다.
   		값 x 에 대한 표주넘수를 구하려면 아래의 공식을 사용한다.


		           X -  μ
	   Z(표준점수) = ------------
	         	     σ





★ 범주형 데이터 살펴보기(p 103)
문제 174
	prop.table( table(emp$deptno)) * 100

	       10        20        30        70
	20.000000 33.333333 40.000000  6.666667




★ 산포도 그래프 (p 106)
문제 175 ~ 176
■ 이원 교차표 p108
문제 177 ~ 179



★ 머신러닝에서 이원교차표를 어떻게 활용하는가 ?

	학습시킨 모델의 정확도를 확인하고 분석하기 위해서 사용한다.

	 P -> 암     ,  T -> 맞춘것이고
	 N -> 정상   ,  F -> 틀린것이다.




★ R 에서의 함수 생성 방법
문제 180 ~ 181
     * 함수생성하는 문법

	 함수명 <-  function(인수 또는 입력값) {
	                 
	                    계산 처리1
	                    계산 처리2
	                    ..............
	
	               return  (계산 결과 반환)
	
	                                       }


	예제 :  normalize <-  function(x) {
	
	          return   ((x - min(x) ) / ( max(x) - min(x) ))
	
	                                   }

		normalize( c(55,64,77,81,90) )  # 몸무게
		
		[1] 0.00 0.25 0.50 0.75 1.00
		
		normalize( c(165,172,177,181,186) )  # 키
		
		[1] 0.00 0.25 0.50 0.75 1.00
		
			    키, 몸무게, ......, 체질량 지수
			   177    78              비만
			                          복비
			                          정상




★ R 에서의 for  loop 문
문제 182 ~ 184
 문법 예제 :

          for  ( 루프변수  in  리스트 )  {
 
                         반복할 문장
 
                                         }

 예제 :     aaa <-  function(x) {
 
                        for  ( i  in  1:x) {
 
                              print(i)

                                           }
                                }

            aaa(10)




★ R에서의 if문
문제 185 ~ 186
	if문 예제 :
		if (조건식) {
			조건식이  true 일 때 실행되는 식
			    }
			else if (조건식) {
				조건식이 true일 때 실행되는 식
					 }
			else {
				위에 조건식들에 만족하지 않을 경우 실행되는 식
			     }
■ knn

	지도학습 -> 분류 -> knn

	* 분류문제란 새로운 데이터가 들어왔을때 이 데이터가 기존에 있던 데이터의 그룹중에 어느 그룹에
	  속한건지를 분류하는 것을 말합니다.


	knn 은 k nearest neighbor 의 약자

	여기서 k 는 몇번째로 가까운 데이터를 살펴볼 것인가를 정한 숫자


	knn 알고리즘은 무엇인가 ?

	" k nearest neighbor 의 약자로 머신러닝의 지도학습의 분류에 해당하는 알고리즘이다. "

	  새로 들어온 데이터가 기존 데이터의 그룹에 어느 그룹에 속하는 지를 찾을 때 거리가 가까운
	  데이터의 그룹을 자기 그룹으로 선택하는 아주 간단한 알고리즘이다.









★ knn 알고리즘의 장단점

	 - 장점 : 단순하고 효율적이다.
	     훈련 단계가 빠르다.
	
	 - 단점 : 모델을 생성하지 않아 특징과 클래스간의
	          관계를 이해하는 능력이 제약된다.

	     적절한 k 값을 사용자가 직접 알아내야 한다.

	   예 : wbcd_test_pred <- knn( train= wbcd_train, test= wbcd_test,
	                                    c1= wbcd_train_labels, k = 21 )

	   k값      테스트 데이터의 정확도
	   1         75%
	   2         79%
	   :         :

	     명목형 데이터와 결측치에 대한 추가 처리작업이 필요하다.








★ knn으로 분류하기 전에 전처리 해야하는 사항
문제 187 ~ 193
	1. 명목형 데이터는 더미 코딩해서 숫자 0 또는 1로 변환한다.

	2. 변수간에 서로 단위가 다른 데이터이므로 min/max정규화 또는 z 표준화를 해야한다.
		- min/max함수는 데이터를 0 ~ 1 사이의 숫자로 변환 ( 정규화 )
		- z표준화는 평균이 0이고 표준편차가 1인 데이터의 분포로 구성하는 작업 ( 표준화 )

	3. 데이터를 3가지로 나눈다.
	    전체 data 가 10000개
		1. train data ( 6000개 )
		2. vaildation data ( 2000개 ) ─▶ 훈련데이터의 일부를 모델을 학습시키기 위해 쓰는
						   데이터
		3. test data ( 2000개 ) ─▶ 실전 데이터
		4. 라벨의 class가 양성과 악성 두가지면 두개의 비율이 비슷해야 한다.
		   즉, 양성 50%, 악성 50% 로 데이터의 갯수를 맞춰주고 학습 시켜야 한다.

	※ knn은 거리를 계산하기 때문에 반드시 정규화 또는 표준화 작업을 수행해야 한다.






★ Knn 의 분류 실습 ( 유방암 데이터 악성과 양성 분류)

	1.데이터 게시판에서 유방암 데이터를 내려받는다

		wisc_bc_data.cv
		
		wbcd <- read.csv("wisc_bc_data.csv", stringsAsFactors=FALSE)
	
		str(wbcd)
		
		라벨 : B --> 양성,  M --> 악성
		
		table(wbcd$diagnosis)
		  B   M
		357 212
		
		 총 : 569 명중 1/3 이 악성이고 2/3 가 양성이다.


	2. 라벨 컬럼을 팩터로 변환
		wbcd$diagnosis <- factor(wbcd$diagnosis, levels = c("B","M"),
	                                 labels=c("Benign","Maliganant") )
		str(wbcd)


	3. 양성과 악성의 비율이 어떻게 되는지 확인한다.
		round( prop.table( table(wbcd$diagnosis) ), 1 ) * 100


	4. 정규화 작업 (normalize 함수로 작업)
		normalize <-  function(x) {
		    return   ((x - min(x) ) / ( max(x) - min(x) ))
		}
		wbcd_n <- as.data.frame(lapply(wbcd[,3:32], normalize) )

		* 정규화가 잘 되었는지 확인 ( 0 ~ 1 사이에 있는지)

		summary(wbcd_n)


	5. 훈련 데이터와 테스트(실험) 데이터를 나누는 작업
	   ( 4/5 )        ( 1/5 )

	  " 훈련 데이터로 기계학습 시켜서 모델을 생성한후 실험 데이토로 검증하는 작업 "

		nrow(wbcd_n)
		569

		wbcd_train <- wbcd_n[1:469, ]
		wbcd_test  <- wbcd_n[470:569, ]

		wbcd_train_label <- wbcd[1:469,2]
		wbcd_test_label  <- wbcd[470:569,2]

		wbcd_test_label


	6. knn 알고리즘으로 기계학습 시켜서 모델을 생성한다.

		library(class)

		훈련데이터의 갯수 469 의 제곱근  21

		result1 <- knn(train=wbcd_train, test=wbcd_test,
		               cl= wbcd_train_label, k = 21 )

		result1

		data.frame(wbcd[470:569,2], result1)


	7. 이 모델의 정확도가 몇 % 인지 알아내시오 !

		prop.table( table(ifelse(wbcd[470:569,2]==result1,"o","x" )))

		   o    x
		0.98 0.02

	8. 이원 교차표를 이용해서 모델을 분석하시오 !

		library(gmodels)

		CrossTable(x= wbcd[470:569,2]  , y = result1,
		           prop.chisq=FALSE )
	
		Total Observations in Table:  100

 
		                 | result1
		wbcd[470:569, 2] |     Benign | Maliganant |  Row Total |
		-----------------|------------|------------|------------|
		          Benign |         61 |          0 |         61 |
		                 |      1.000 |      0.000 |      0.610 |
		                 |      0.968 |      0.000 |            |
		                 |      0.610 |      0.000 |            |
		-----------------|------------|------------|------------|
		      Maliganant |          2 |         37 |         39 |
		                 |      0.051 |      0.949 |      0.390 |
		                 |      0.032 |      1.000 |            |
		                 |      0.020 |      0.370 |            |
		-----------------|------------|------------|------------|
		    Column Total |         63 |         37 |        100 |
		                 |      0.630 |      0.370 |            |
		-----------------|------------|------------|------------|




★ 현업에서 데이터 분석할때 필요한 사항

	1. 오라클 데이터베이스에 있는 데이터를 csv 로 내리지 않고 바로 오라클과 R 을 연동한다든지
	   오라클과 파이썬을 연동해서 바로 분석할 수 있게 하는게 중요하다.

  	2. 현업 담당자들이 바로 분석할 수 있도록 UI 를 만들어 UI 를 배포 ( 샤이니 기술 요구 )





★ data shuffle 시키고 내리기

setwd("d://data")

set.seed(11)

iris <- read.csv("iris.csv", header=T)

iris_shuffle <- iris[sample(nrow(iris)), ]

write.csv(iris_shuffle,file="iris_shuffle.csv", row.names = FALSE)











★ ㅊ


train_num<-round(0.7*nrow(skin_shuffle),0)

skin_train <- skin_shuffle[1:train_num,]
skin_test <-skin_shuffle[(train_num+1):nrow(skin_shuffle),]
■ 4장. 나이브 베이즈 분류

	* 4장 목차
		1. 확률에 대한 기본적인 이해 (pdf)
		2. 나이브 베이즈 알고리즘
		3. 나이브 베이즈 실습
			- 독버섯과 정상버섯의 분류
			- 영화 장르 선호도 분류
			- 스팸메일과 햄메일의 분류(책 실습)  ──▶ text mining 실습
		4.





★ 1. 확률에 대한 기본적인 이해 (pdf)

	pdf 로 설명





★ 2. 나이브 베이즈 알고리즘 (p 152)

	       비아그라(w1)      돈(w2)        식료품(w3)    주소삭제(w4)
	 우도    Yes    No      Yes    No        Yes    No    Yes    No   
	 스팸    4/20  16/20   10/20  10/20   0/20  20/20   12/20  8/20     20
	 햄      1/80  79/80   14/80  66/80   8/80  71/80   23/80  57/80    80  
	 총합   5/100  95/100  24/100 76/100  8/100  9/100  35/100  65/100  100

		* 스팸 메일과 햄 메일을 정확하게 분류하기 위해서는 ?
			비아그라 단어 하나만 가지고 스팸메일인지를 분류하면 정확하게 분류가 안될 수
			있으니 다른 단어들도 같이 포함시켜서 확률을 구해야 한다.

			예 : 비아그라, 돈, 식료품, 주소삭제

			용어 : ㄱ : 존재하지 않는다 (부정)
			       ㅋ : 존재한다. (긍정)

			예제 : 비아그라와 주소삭제라는 단어는 포함되어있는 메일인데 돈과 식료품은
			       포함하지 않는 메일은 스팸일 확률이 어떻게 되는가?

	p( 스팸 | 비아그라 ∩ ㄱ돈 ∩ ㄱ식료품 ∩ 주소삭제 ) = ?

	   p( 비아그라 ∩ ㄱ돈 ∩ ㄱ식료품 ∩ 주소삭제 | 스팸 ) * p(스팸)
	= ────────────────────────────────
                   p(비아그라 ∩ ㄱ돈 ∩ ㄱ식료품 ∩ 주소삭제)

	   p(비아그라|스팸) * p(ㄱ돈|스팸) * p(ㄱ식료품|스팸) * p(주소삭제|스팸) * p(스팸)
	= ──────────────────────────────────────────
		           p(비아그라) * p(ㄱ돈) * p(ㄱ식료품) * p(주소삭제)

	   4/20 * 10/20 * 20/20 * 12/20 * 20/100
	= ──────────────────── = 0.85	(스팸일 확률)
	     5/100 * 76/100 * 91/100 * 35/100	


	       비아그라(w1)      돈(w2)        식료품(w3)    주소삭제(w4)
	 우도    Yes    No      Yes    No        Yes    No    Yes    No   
	 스팸    4/20  16/20   10/20  10/20   0/20  20/20   12/20  8/20     20
	 햄      1/80  79/80   14/80  66/80   8/80  71/80   23/80  57/80    80  
	 총합  5/100  95/100  24/100 76/100  8/100  9/100  35/100  65/100  100
	
	* 스팸일 확률 ? 스팸일 우도 ?
	
	 P(비아그라|스팸) * P(ㄱ돈|스팸) * P(ㄱ식료품|스팸) * P(주소삭제|스팸) * P(스팸)
	       4/20            10/20              20/20             12/20          20/100
	
	 = 0.012
	
	* 햄일 확률 ? 햄일 우도 ?
	
	
	 P(비아그라|햄) * P(ㄱ돈|햄) * P(ㄱ식료품|햄) * P(주소삭제|햄) * P(햄 )
	     1/80            66/80         71/80            23/80         80/100
	
	 = 0.002    
	
	
	                        0.012
	 스팸일 우도 ?  ------------------------- = 0.85
	                    0.012 + 0.002   
	
	                     0.002  
	 햄일 우도  ?   ------------------------- = 0.15
	                   0.012 + 0.002   
	
	
	
	왜  분모가   P( 비아그라 ∩ ㄱ돈 ∩ ㄱ식료품 ∩ 주소삭제) 가
	            스팸의 우도 + 햄의 우도와 같냐면 ?  
	
	 증명하면 ?
	
	   P( 비아그라 ∩ ㄱ돈 ∩ ㄱ식료품 ∩ 주소삭제) 를 그냥
	   
	   비아그라 하나면 보고
		
	   P(비아그라) = P(스팸 ∩ 비아그라) + P(햄 ∩ 비아그라)
	               = P(비아 | 스팸) x P(스팸) + P(비아|햄) x P(햄)
	                   스팸의 우도               햄의 우도
	     
	
	 정리하면 비아그라, 주소삭제가 포함되어져 있고 돈과 식료품이 포함되지
	 않은 메세지가 스팸일 확률은 85% 가 된다.





■ 나이브 베이즈 복습
문제 194 ~ 198
	  1. knn 과 나이브 베이즈의 차이 ?
	
	      knn 은 데이터간의 거리를 계산해서 가장 가까운 거리에 있는
	      데이터가 나의 이웃이라고 분류하는 분류 방법이고
	
	      나이브 베이즈는 확률을 이용하여 분류하는 분류 기법
	
	  2. 언제 knn 을 사용하고 언제 나이브베이즈를 사용해서 분류해야하는가 ?
	
	      -  knn -->  분석하려는 데이터가 수치형 데이터일때
	
	          예:  유방암 데이터       
	
	      -  naive bayes -> 분석하려는 데이터가 명목형 데이터 일때
	
	          예:  영화 선호도 데이터
	
	  3. knn 과 나이브 베이즈로 분석하려는 질문 리스트 ?
	
	    - knn 의 질문 ?
	
	         1. 종양의 크기와 모양만 보고 악성 종양인지 양성 종양인지를
	            분류할 수 있을까 ?
	       
	         2. 붓꽃의 모양만 보고 붓꽃의 종류를 알아맞힐수 있을까 ?  
	
	    - naive bayes 의 질문 ?
	
	        1. 직업과 나이, 성별, 직업유무를 가지고 어느 영화를 더
	           선호할지 선호도를 알아 맞힐수 있을까 ?
	
	           예: movie.csv
	
	        2. 버섯의 모양, 색깔, 향기 등의 정보를 가지고 독버섯인지
	           일반 버섯인지 알아 맞힐 수 있을까 ?  
	
	           예: mushrooms.csv
	
	  4. 나이브 베이즈의 원리  복습  
	
	
	        비아그라
	        예    아니오   총계
	 스팸   4       16     20
	 햄     1       79     80
	        5        95   100
	
	
	  P(스팸 | 비아그라 ∩ 돈 ∩ 식료품 ∩ 주소삭제)  =   확률 ?
	
	            스팸의 우도
	   -----------------------------
	     햄의 우도 + 스팸의 우도
	
	  P(공포 | '30대' ∩ '여자' ∩'IT' ∩ '미혼') =  확률 ?  
	
	        공포의 우도
	  -------------------------------------------------
	  공포 + 로멘틱 + 코믹 + 무협 + 스릴러 + 액션 + SF






★ 라플라스 추정기 (P 155 페이지)
문제 199 ~ 200

	       비아그라(w1)      돈(w2)        식료품(w3)    주소삭제(w4)
	 우도    Yes    No      Yes    No        Yes    No    Yes    No   
	 스팸    4/20  16/20   10/20  10/20   0/20  20/20   12/20  8/20     20
	 햄      1/80  79/80   14/80  66/80   8/80  71/80   23/80  57/80    80  
	 총합  5/100  95/100  24/100 76/100  8/100  9/100  35/100  65/100  100
	    
	스팸의 우도 ?  
	
	  P(비아그라|스팸) * P(돈|스팸) * P(식료품|스팸) * P(주소삭제|스팸) * P(스팸)
	
	      4/20             10/20         0/20
	      
	 ※ 설명: 식료품으로 인해서 다른 증거들이 다 무효가 되어벼렸다.
	          이를 해결하기 위해서 프랑스의 수학자 피에르 시몬 라플라스가
	          확률이 0 이 되지 않기 위해서 빈도표의 각 값에 작은 수를
	          추가를 했다.  
	     
	    4/20       x     10/20    x     0/20    x   12/20  x    20/100
	
	                               ↓
	
	    5/24       x     11/24    x     1/24    x   13/24  x    20/100
	
	
	햄의 우도 ?
	
	  P(비아그라|햄) * P(돈|햄) * P(식료품|햄) * P(주소삭제|햄) * P(햄)
	
	                       스팸의 우도
	   스팸일 확률 = ----------------------
	                  스팸의 우도 + 햄의 우도
■ 5장. 의사결정 트리와 규칙 기반 분류

 	 의사결정트리란 ?
	
	  의학에서 질병에 대한 진행 과정을 바탕으로 올바른 처방을
	  위해 결정해야하는 경우나 은행에서 대출을 해줄때 대출을
	  해줄지 말지의 여부를 기업 데이터를 보고 결정해야 하는 경우등에
	  사용하는 지도학습 머신러닝 알고리즘  

	머신러닝의 종류 3가지

		1. 지도학습 ─▶ 라벨이 있다.
			- knn : 데이터 간의 거리를 이용해서 분류
			- naive bayes : 확률을 이용해서 분류
			- decision tree : 정보 획득량으로 분류
					      ↓
					공식 ? 분할전 엔트로피 - 분할 후 엔트로피
				정보획득량으로 가장 먼저 질문해야할 변수들을 알아내고 분류를 하는
				것이다.

		2. 비지도 학습 ─▶ 라벨이 없다.

		3. 강화학습 ─▶ 환경을 스스로 agent가 학습해 나가는 방법




★ 엔트로피와 정보 획득량

	 결정트리를 만들때 가장 먼저 해야할 일이 무엇인가 ?
	    
	               ↓
	
	    중요한 컬럼(변수) 를 찾는 것이다.
	
	               ↓
	
	    정보 획득량이 높은 변수
	
	               ↓
	
	     엔트로피 함수를 사용






★ 엔트로피(entropy) 함수
문제 201 ~ 206
	  " 데이터의 불확실성이 얼마나 되는가 ? "  
	
	  엔트로피 지수가 높다는것은 불확실성이 높다는 것
	
	      그림
	
	
	  정보획득량 = 분할전 엔트로피 - 분할후 엔트로피




★ C5.0패키지를 이용해서 분류 모델 생성

	" 백화점 화장품 고객 중에 구매가 예상이 되는 고객이 누구인가? "

	" 은행 대출 채무 불이행할 것 같은 고객이 누구인가 ? "
			↓
	의사결정 트리로 분류를 할 것이다.







★ 백화점 화장품 고객 중에 구매가 예상이 되는 고객이 누구인가?
문제 207 ~ 208
	1. 의사결정 패키지인 c50 패키지를 설치한다.
		install.packages("C50")
		library(C50)
	
	2. 백화점 화장품 고객 데이터를 로드하고 shuffle 한다.
		skin <- read.csv("skin.csv", header = T)
		nrow(skin)
		
		skin_real_test_cust <- skin[30, ]
		skin2 <- skin[1:29, ]
		nrow(skin2)
		
		   cust_no gender age job marry car cupon_react
		30      30 female  40 YES   YES  NO         YES

		skin2 <- skin2[, -1] # 고객번호를 제외시킨다.
		
		set.seed(11)
		skin2_shuffle <- skin2[sample(nrow(skin2)), ] # shuffle 시킴

	3. 화장품 고객 데이터를 9대 1로 train과 test로 나눈다.
		train_num <- round(0.7 * nrow(skin2_shuffle), 0)
		skin2_train <- skin2_shuffle[1:train_num, ]
		skin2_test <- skin2_shuffle[(train_num+1):nrow(skin2_shuffle), ]
		
		nrow(skin2_train) # 20
		nrow(skin2_test)  #9

	4. C50패키지를 이용해서 분류 모델을 생성한다.
		# skin_model <- C5.0(skin2_train[, -6], skin2_train$cupon_react, trials = 6) # 다맞춤
		skin_model <- C5.0(skin2_train[, -6], skin2_train$cupon_react) # 1개 틀림
				       ↑			↑
			    라벨을 뺀 train 전체 data   train 데이터의 라벨

	5. 위에서 만든 skin_model을 이용해서 테스트 데이터의 라벨을 예측하시오 !
		skin2_result <- predict(skin_model, skin2_test[ , -6])
							↑
					    라벨을 뺀 테스트 데이터 전체

	6. 이원 교차표로 결과를 확인하시오 !
		library(gmodels)
		CrossTable(skin2_test[, 6], skin2_result)





★ 은행 대출 채무 불이행할 것 같은 고객이 누구인가 ?
문제 209 ~ 211
	데이터 : cradit.csv (독일 은행의 고객데이터)

	1. 데이터를 로드한다
		credit<- read.csv("credit.csv")

	2. 데이터에 각 컬럼명을 이해한다.
		라벨컬럼 : defult ──▶ yes : 대출금 상환 안함
					 no  : 대출금 상환
		prop.table(table(credit$default))
		 no yes
		0.7 0.3
	    - 계좌 소개 : checking_balance ─▶ 예금계좌
			  saving_balance   ─▶ 적금계좌
	    - amount : 대출금액 250마르크 ~ 18424마르크 ( 100 마르크가 우리나라돈 6 ~ 7만원 )
		summary(credit$amount)
		   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
		    250    1366    2320    3271    3972   18424

		은행의 목표 : 과거의 데이터를 분석해보니 대출금 상환 불이행자가 30%나 되어서 앞으로는
			      30%이내로 떨어뜨리게끔 하는게 은행의 목표라서 거기에 맞는 model을
			      생성해야 한다.

	3. 데이터가 명목형 데이터인지 확인해본다.
		str(credit)

	4. 데이터를 shuffle시킨다.
		set.seed(31)
		credit_shuffle <- credit[sample(nrow(credit)), ]

	5. 데이터를 9:1로 나눈다.
		train_num <- round(0.9 * nrow(credit_shuffle), 0)
		credit_train <- credit_shuffle[1:train_num, ]
		credit_test <- credit_shuffle[(train_num+1) : nrow(credit_shuffle), ]

	6. C5.0패키지와 훈련데이터를 이용해서 모델을 생성한다.
		library(C50)
		credit_model <- C5.0(credit_train[, -17], credit_train[, 17])


	7. 위에서 만든 모델을 이용해서 테스트 데이터의 라벨을 예측한다.
		credit_result <- predict(credit_model, credit_test[, -17])

	8. 이원 교차표로 결과를 확인한다.
		library(gmodels)
		CrossTable(credit_test[, 17], credit_result)






★ 규칙 기반 알고리즘

	1. oneR  알고리즘 : p 223

		"하나의 사실만 가지고 간단하게 분류하는 알고리즘 "
		간단하긴하지만 오류가 많아진다.

		예 : 가슴통증의 유무에 따라 심장질환이 있는지 분류
		     가슴통증 하나만 보고 심장질환이 있다고 분류하기에는 오류가 많아진다. 왜나하면
		     식도염, 폐질환도 가슴통증이 있기 때문이다.


	2. Riper 알고리즘 : p 226

		"복수개의 사실(조건)을 가지고 분류하는 알고리즘"

		예 : 하늘을 날고 털이 있다면 그것은 포유류이다.
		     땅을 걷고 털이 있다면 그것은 포유류이다.





★ 규칙 기반 분류 알고리즘 (oneR 실습)

	"독버섯 데이터"

	나이브 베이즈와 비교해보기 위해서 나이브 베이즈로 독버섯과 일반버섯을 분류한 이원 교차표를
	아래에 출력하시오 !
	
	                  | result
	                  |    edible | poisonous | Row Total |
	------------------|-----------|-----------|-----------|
	           edible |      1257 |         3 |      1260 |
	                  |   558.656 |   601.007 |           |
	                  |     0.998 |     0.002 |     0.517 |
	                  |     0.995 |     0.003 |           |
	                  |     0.516 |     0.001 |           |
	------------------|-----------|-----------|-----------|
	        poisonous |         6 |      1171 |      1177 |
	                  |   598.051 |   643.389 |           |
	                  |     0.005 |     0.995 |     0.483 |
	                  |     0.005 |     0.997 |           |
	                  |     0.002 |     0.481 |           |
	------------------|-----------|-----------|-----------|
	     Column Total |      1263 |      1174 |      2437 |
	                  |     0.518 |     0.482 |           |
	------------------|-----------|-----------|-----------|



	1. 버섯 데이터를 R로 로드한다.
		mushroom <- read.csv("mushrooms.csv", stringsAsFactors = T)

	2. mushroom데이터를 훈련 데이터와 테스트 데이터로 나눈다.
	   (훈련데이테 75%, 테스트 데이터 25%)
		set.seed(11)
		dim(mushroom)
		train_cnt <- round(0.75*dim(mushroom)[1])
		train_index <- sample(1:dim(mushroom)[1], train_cnt, replace = F)
		mushroom_train <- mushroom[train_index, ]
		mushroom_test <- mushroom[-train_index, ]

	3. 규칙 기반 알고리즘인 oneR을 이용해서 독버섯과 일반버섯을 분류하는 모델을 생성한다.
		install.packages("OneR")
		library(OneR)
		model1 <- OneR(type~. , data=mushroom_train)
		model1
		summary(model1)

	4. 위에서 생성한 모델을 가지고 테스트 데이터로 결과를 확인한다.
		result1 <- predict(model1, mushroom_test[ , -1])
		library(gmodels)
		CrossTable(mushroom_test[ ,1], result1)

	                   | result1
	mushroom_test[, 1] |    edible | poisonous | Row Total |
	-------------------|-----------|-----------|-----------|
	            edible |      1028 |         0 |      1028 |
	                   |   446.170 |   489.958 |           |
	                   |     1.000 |     0.000 |     0.506 |
	                   |     0.967 |     0.000 |           |
	                   |     0.506 |     0.000 |           |
	-------------------|-----------|-----------|-----------|
	         poisonous |        35 |       968 |      1003 |
	                   |   457.291 |   502.170 |           |
	                   |     0.035 |     0.965 |     0.494 |
	                   |     0.033 |     1.000 |           |
	                   |     0.017 |     0.477 |           |
	-------------------|-----------|-----------|-----------|
	      Column Total |      1063 |       968 |      2031 |
	                   |     0.523 |     0.477 |           |
	-------------------|-----------|-----------|-----------|








★ 규칙 기반 분류 알고리즘 (JRiper 실습)

	install.packages("RWeka")
	library(RWeka)
	
	model2 <- JRip(type~. , data=mushroom_train)
	model2
	summary(model2) # 작은 이원교차표가 하나 보임
	
	result2 <- predict(model2, mushroom_test[ , -1])
	library(gmodels)
	CrossTable(mushroom_test[, 1], result2)

	                   | result2
	mushroom_test[, 1] |    edible | poisonous | Row Total |
	-------------------|-----------|-----------|-----------|
	            edible |      1028 |         0 |      1028 |
	                   |   495.327 |   507.673 |           |
	                   |     1.000 |     0.000 |     0.506 |
	                   |     1.000 |     0.000 |           |
	                   |     0.506 |     0.000 |           |
	-------------------|-----------|-----------|-----------|
	         poisonous |         0 |      1003 |      1003 |
	                   |   507.673 |   520.327 |           |
	                   |     0.000 |     1.000 |     0.494 |
	                   |     0.000 |     1.000 |           |
	                   |     0.000 |     0.494 |           |
	-------------------|-----------|-----------|-----------|
	      Column Total |      1028 |      1003 |      2031 |
	                   |     0.506 |     0.494 |           |
	-------------------|-----------|-----------|-----------|
■ 6장. 회귀 분석

	* 6장 목차
		1. 단순 선형 회귀 분석 이론
		2. 단순 선형 회귀 실습1 (탄닌 함유량과 애벌레 성장간의 관계)
		3. 단순 선형 회귀 실습2 (우주 왕복선 챌린저호 폭발 원인 분석)
		4. 단순 선형 회귀 실습3 (코스피 지수 수익률과 삼성, 현대 자동차 주식 수익율의
					 상관관계 분석)
		5. 다중 선형 회귀 이론
		6. 다중 선형 회귀 실습1 (스마트폰 만족에 미치는 영향도 분석)
		7. 다중 선형 회귀 실습2 (미국 대학 입학에 가장 영향이 높은 과목 분석)
		8. 다중 선형 회귀 실습3 (보험회사의 보험료 선정에 미치는 요소 분석)
		9. 다중 선형 회귀 실습4 (날씨와 전력사용량과의 상관관계)







★ 1. 단순 선형 회귀 분석 이론

	* 머신러닝의 종류 3가지 ?
		1. 지도학습
			- 분류 : KNN, naivebayes, decesion tree, 규칙기반 알고리즘
			- 회귀 :

		2. 비지도 학습

		3. 강화학습






★ 회귀 분석이란 ?

	회귀 분석은 하나의 변수가 나머지 다른 변수들과의 선형적 괸계를 갖는가의 여부를 분석하는
	방법으로 하나의 종속변수(예측하고자 하는 값)와 족립변수 사이의 관계를 명시하는 것

	예 : 집값에 가장 영향을 주는 요소가 무엇인가?

	- 독립변수 : 종속변수에 영향을 주는 변수 ( 평수, 역세권, 학군, .... )
	- 종속변수 : 서로 관계를 가지고 있는 변수들 중에서 다른 변수에 영향을 받는 변수 (집값)

	회귀식 : y = αx + β
		↓     ↓
	       집값   평수

	예 : 1986년 1월 28일 미국의 스페이스 셔틀 챌린져호의 승무원 7명이 모두 사망했다. 우주 왕복선이
	     발사 도중에 폭파하는 바람에 사망을 했다. 원인분석을 했는데 그 원인이 ?

		" 발사 온도에 대한 o형링의 파손이 원인 "

		y = αx + β

		y가 o형링의 파손수, x가 발사 온도
		여기서 회귀 모수인 α, β 를 기계가 구하게끔 해야한다.
		일단 α가 -0.057이고 β가 4.3이라고 기계학습 결과로 알아냈다면 식은
			y = -0.057 * x + 4.3



★ 최소 제곱 추정법 (p253)
문제 213 ~ 220
	최적의 α(기울기)와 β(절편)을 결정하기 위해서 정규 최소 제곱법으로 알려진 추정기법을 사용한다.
			 ∧
	실제값 y와 예측값 y 사이의 수직 직선이 오차(잔차)를 제곱해서 구한 총합을 알아야 한다.
			 ∧
		Σ (yi - yi)^2
		    ↑   ↑
	 	실제값  예상값
		      ∧
	     Σ (yi - yi)^2
	α = ────────
		      ∧
	     Σ (xi - xi)^2

	이를 다시 아래의 식으로 나타내면 ?

	     Σ (x값 - x값의 평균) * (y값 - y값의 평균)
	α = ─────────────────────
	              Σ (x값 - x값의 평균)^2

	     x와 y의 공분산      cov(x, y)
	α = ───────  =  ─────  =  기울기
	          분산            var(x)

	y = αx + β
	    ↓
	  기울기





★ 상관관계 (p256)
문제 221 ~ 226
	상관분석은 두 변수가 서로 어떠한 괸계인지를 파악하는 분석
	기울기에 따라 양의 상관관계, 음의 상관관계로 나눌 수 있다.

	점들이 흩어져 있는 모습을 보고 두 변수의 관계를 파악하는데 밀도의 차이에 따라서 상관계수를
	나타낸다.

	상관계수의 기호는 "r"을 사용한다.

	상관계수의 수치가 0에 가까울 수록 상관관계가 약하다는 뜻이고 +1에 가까우면 양의 상관관계가 강하다.
	-1에 가까우면 음의 상관관계가 강하다.

	예 : 온도와 0형링 파손수 두 변수간의 상관관계가 강한지 약한지 알아내시오 !

		attach(launch)
		cor(temperature, distress_ct)

		[1] -0.5111264



	install.packages('corrplot')
	library(corrplot)
	
	z <- c(1,5,10,15)
	x <- c(3,9,21,29)
	y <- c(1,11,19,31)
	d <- data.frame(z,x,y)
	d
	# 일반 상관계수
	cor(d)
	
	part1 <- lm(y~x, data=d)
	summary(part1)
	cov(x,y) / ( sqrt(var(x))*sqrt(var(y)) )
	cor(d$x, d$y)






★ 다중 선형 회귀 분석 (p 258)

	단순 선형 회귀 분석의 목적이 하나의 독립변수만을 가지고 종속변수를 예측하기 위한 회귀모형을
	만들기 위한 것이었다면 다중회귀분석의 목적은 여러개의 독립변수들을 가지고 종속변수를 예측하기
	위한 회귀모형을 만드는 것이다.

	예를들면 집값에 영향을 미치는 요소가 단순히 평수만 있는게 아니다.

	집값 ◀──	평수, 교통, 신도시, 범죄율, 층수, 방갯수 ...
	 ↑		 ↑
      종속변수 	     독립변수들

	집값 = β(절편) + α1*x1 + α2*x2 + α3*x3 + α4*x4 ..... + ε
	
	독립변수들이 여러개 이므로 단순 회귀와는 다르게 행렬을 이용해서 회귀모수를 구해야 한다.





★ 다중 회귀식의 베타값을 구하는 함수 생성하는 방법
문제 227 ~ 232




★ 다중 선형 회귀를 이용한 의료비 예측 실습
문제 235 ~ 238	
	" 보험회사에서 보험료를 산정하기위해 미국 국민의 의료비가 얼마나 드는지를 예측하는 회귀모델을
	  생성하는게 목표 "

	독립변수들					종속변수

	나이
	성별
	bmi				──────▶ 의료비 예측
	부양가족수
	흡연유무
	미국의 어느지역에 사는지


	1. 미국 국민의 의료비 데이터를 로드한다.
		insurance <- read.csv("insurance.csv", header = T)
		head(insurance)
		  age    sex  bmi children smoker    region expenses
		1  19 female 27.9        0    yes southwest 16884.92
		2  18   male 33.8        1     no southeast  1725.55
		3  28   male 33.0        3     no southeast  4449.46
		4  33   male 22.7        0     no northwest 21984.47
		5  32   male 28.9        0     no northwest  3866.86
		6  31 female 25.7        0     no southeast  3756.62

		종속변수 : expenses(의료비)
		독립변수 : age, sex, bmi, children, smoker. region


	2. 의료비의 분포가 어떻게 되는지 확인한다.
		summary(insurance$expenses)
		   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
		   1122    4740    9382   13270   16640   63770 	


	3. 의료비의 분포를 확인하기 위해 히스토그램 그래프를 그린다.
		hist(insurance$expenses)

	4. 독립변수와 종속변수간의 상관관계 분석
	   그리고 독립변수들간의 상관관계를 분석
		cor(insurance[c("age", "bmi", "children", "expenses")])

		               age        bmi   children   expenses
		age      1.0000000 0.10934101 0.04246900 0.29900819
		bmi      0.1093410 1.00000000 0.01264471 0.19857626
		children 0.0424690 0.01264471 1.00000000 0.06799823
		expenses 0.2990082 0.19857626 0.06799823 1.00000000


	5. pairs함수를 이용해서 독립변수들간의 상관관계를 확인하시오 !
		install.packages("psych")
		library(psych)
		pairs.panels(insurance[c("age", "bmi", "children", "expenses")])


	※ 다중 공선성
		회귀 분석에서 사용된 모형의 일부 설명변수(독립변수)가 다른 독립변수와의 상관정도가
		높아 데이터 분석시 부정적인 영향을 미치는 현상을 말한다.

		두 독립변수들 끼리 서로에게 영향을 주고 있다면 둘 중 하나의 영향력을 검증할 때 다른
		하나의 영향력을 완전히 통제할 수 없게 된다.

		예를 들면, 음주가 학업 성취도에 미치는 영향을 알아보기 위해서 회귀분석을 한다고
		가정해보면 학업 성취도를 종속변수로 y로 보고 이를 설명해주는 독립변수 x는 일평균
		음주량, 또 다른 독립변수 x2는 혈중 알코올 농도라고 한다면
		일평균 음주량과 혈중 알코올 농도는 서로 아주 강한 상관정도를 보인다.
		이 상태에서 회귀분석을 하면 분명히 x1와 x2 둘중에 하나는 유의한 변수로 드러나게 된다.
		실제로 x1과 x2의 값이 증가 또는 감소 할수록 y값이 증가 또는 감소할것인데 이중 하나는
		굉장히 불안정한 계수값을 보이게 된다.


	    예제 : car 데이터로 회귀 분석 전에 다중 공선성을 보이는 변수를 찾아내시오 !
		# https://lovetoken.github.io/r/2017/04/16/vif.html 참고
		
		install.packages("car")
		library(car)
		
		data(Boston, package = "MASS")
		summary(Boston)
		str(Boston)
		data <- subset(Boston, select = -c(chas, rad))
		# integer type 인 chas, rad 변수 독립변수에서 제외
		
		lmfit <- lm(medv ~ . , data = data)
		summary(lmfit)
		vif(lmfit)
		vif(lmfit) > 10

		   crim      zn   indus     nox      rm     age     dis     tax
		  FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE   FALSE
		ptratio   black   lstat
		  FALSE   FALSE   FALSE
	
			설명 : 이 데이터에서는 다중 공선성을 보이는 변수는 없는 것으로 확인이 되었다.

		x1과 x2 두개가 서로 강한 상관정도가 있어서 둘다 종속변수에 대한 영향력이 높다면 예를들어
		x2가 설명할 부분을 x1이 가져가 버리기 때문에 x2의 설명력은 분명 작아지게 된다.
		그럼 쓸모없어진 x2의 p_value가 커서 유의수준을 넘어버리게 된다.

		회귀분석 알고리즘 두번째.pdf 참고

		vif(lmfit) > 10

		분산팽창계수는 보통 10보다 큰것으로 골라내고 엄격하게 하려면 5보다 큰것으로 골라낸다
		느슨하게 하려면 15또는 20으로 주고 골라낸다.





★ 1. Multiple R-squared와 Adjusted R-squared의 차이 ?

	결정계수란 회귀모형의 데이터에 대한 설명력을 나타내는 척도이다.

	좋은 회귀모형에는 두가지 조건이 있다.

		1. 데이터를 잘 설명한다.
		2. 간단하다.

	독립변수(설명변수)가 많은 회귀모형의 경우에는 첫번째 조건을 만족한다. 그러나 두번째 조건에서는
	탈락이라고 볼 수 있다.

	아무리 설명력이 좋아도 복잡하다면 그다지 좋은 모형이 아니다.
	그래서 결정계수가 높다고 좋은 모형이라며 쉽사리 결론을 지으면 안된다.
	결정계수가 모형의 설명력을 측정하기 좋은 척도라는 것은 사실이지만 위에서 이야기했던 것과 같은
	단점을 보완하기 위해 보완된 척도가 등장하게 되는데 그것이 바로
		"조정된 결정계수(Adjusted R-squared)"
	이 척도는 다행스럽게도 독립변수의 숫자가 증가한다고 해서 무작정 처지지 않는다.








★ 2. p-value값 확인
문제 239
	귀무가설에서 얻은 검정 통계량의 값 이상으로 대립가설에서 유리한 데이터를 얻을 수 있는 확률

	P값 > 유의수준 ──▶ 귀무가설 채택
	P값 < 유의수준 ──▶ 귀무가설 기각

	일부 P값에는 별이 있는데, 추정치로 충족되는 유의수준을 나타내는 각주에 해당이 된다.
	유의수준보다 낮은 P값은 통계적으로 유의한 것으로 간주된다.





★ 다중 회귀 세번째 ppt설명

문제 1.
	회귀분석의 회귀란 평균으로 되돌아 간다는 의미이다.



문제 2.


문제 3.
	편차 ?
		괸측치가 평균으로 부터의 떨어져있는 정도
		즉, 평균과의 차이 (yi - yi의 평균)

	잔차 ?
		회귀선으로 설명할 수 없는 편차
		관측치와 회귀식의 예측치와의 차이
		즉, 잔차는 편차의 일부분이다. ( yi - y의 예측치)

	오차 ?
		회귀선으로 설명할 수 있는 편차
		편차와 달리 예측하기 위하여 추정된 값과 실제값과의 차이 ( yi - y의 예측치)

	결정계수 ?
		추정된 회귀선이 실제값과 평균 사이의 편차를 얼마나 줄여주는가를 나타내는 지수


문제 4.


문제 5.

★ 정규화(표준화)를 하는 경우와 안하는 경우
문제 240
	1. 정규화를 하는 경우
		보험비용에 가장 영향을 크게 미치는 변수가 무엇인지 확인할 때

		예 : 몸무게와 키는 단위가 다르므로 단위를 생각해서 가장 영향이 큰 변수를 확인할 때 사용

	2. 정규화를 안하는 경우
		나이가 한살 더 늘어날 때 또는 부양가족이 한명 더 늘어날 때의 보험료가 얼마나 인상되어야
		하는지를 예측할 때

	예 : 부양가족이 한명 더 늘어날수록 의료비가 475달러 더 증가한다.
	     비만 지수 1증가는 매년 의료비를 339달러를 만든다.
	     나이의 1살 증가는 매년 의료비를 256달러 만든다.

	만족도 = 1.873 + 0.195*통화품질 + 0.250*이미지


문제 6.


문제 7.



문제 8.
	4개의 수준을 갖는 계절변수를 봄을 기준으로 하여 3개의 더미변수로 아래와 같이 코딩한다.

	계절	더미변수1	더미변수2	더미변수3
	봄		0		0		0
	여름		1		0		0
	가을		0		1		0
	겨울		0		0		1





★ 회귀 트리 (p282)

	1. 회귀트리란? 수치를 예측하는 트리 ──▶ 분류
						  ↙  ↘
						구매  비구매
		- 의사결정 트리의 결과 그림
	

		- 회귀트리 결과 그림
	


	2. 특정 숫자를 예측하는데 다중 회귀분석을 이용하지 않고 왜 회귀트리를 사용하는가?

		예측해야 하는 특정 숫자(집값) ◀── 평수, 학군, 지하철과의 거리 ....
		와인의 등급(숫자)  ◀── 휘발성, 알코올 함량, 자유 이산화황.....

		수치 예측 작업을 할 때 일반적으로 전통적인 회귀방법을 가장 먼저 선택하지만, 경우에 따라
		수치 의사결정트리가 분명한 이점을 제공하기도 한다.

		예를들어 의사결정트리의 장점을 수치 예측에 활용할 수 있다.

		의사결정 트리는 작업이 특징이 많거나 특징과 결과간에 매우 복잡하고 비선형적인 관계를
		가질 때 잘 맞는 반면 회귀는 이럴때 어려움이 있다.

		회귀의 경우는 독립변수의 갯수 많으면
			1. 다중공선성도 고려를 해야했고
			2. 결정계수를 높이기 위해 파생변수를 추가 해야하는 모델의 성능을 높이기 위한
			   작업들이 필요했다.

	3. 회귀트리의 원리?

		회귀 트리와 모델트리의 이해.pdf


	4. 회귀트리의 나눔의 기준인 SDR 테스트

		p284표
			

		속성 A와 속성 B중에 어떤게 더 균일하게 나누었는지 SDR을 확인한다.

		#원본데이터
		tee <- c(1, 1, 1, 2, 2, 3, 4, 5, 5, 6, 6, 7, 7, 7, 7)
		
		#원본데이터를 A속성으로 나누었을 때의 데이터
		
		at1 <- c(1, 1, 1, 2, 2, 3, 4, 5, 5)
		at2 <- c(6, 6, 7, 7, 7, 7)
		
		#원본 데이터를 B속성으로 나누었을 때의 데이터
		
		bt1 <- c(1, 1, 1, 2, 2, 3, 4)
		bt2 <- c(5, 5, 6, 6, 7, 7, 7, 7)
		
		# A속성과 B속성의 SDR을 구한다.
		sdr_a <- sd(tee) - (length(at1) / length(tee) * sd(at1) +
		                    length(at2) / length(tee) * sd(at2))
		sdr_b <- sd(tee) - (length(bt1) / length(tee) * sd(bt1)+
		                    length(bt2) / length(tee) * sd(bt2))
		sdr_a # [1] 1.202815
		sdr_b # [1] 1.392751
		
		
		#sdr이 더 높은 속성으로 나눔을 결정하고 각각 bt1과 bt2의 평균값을 구해서 등급을 예측!
		mean(bt1)	# 2로 예측한다.
		mean(bt2)	# 6.25로 예측한다.
		
			트리 다이어그램
				








★ 회귀 트리 (Regression Tree)  
문제 241
	 1. 와인 데이터에 대한 소개





★ 와인 데이터로 의사결정 트리 시각화

 
	#fixed.acidity       : 고정 산도
	#volatile.acidity    : 휘발성 산도
	#citric.acid         : 시트르산
	#residual.sugar      : 잔류 설탕
	#chlorides           : 염화물
	#free.sulfur.dioxide : 자유 이산화황
	#total.sulfur.dioxide: 총 이산화황
	#density             : 밀도
	#pH                  : pH
	#sulphates           : 황산염
	#alcohol             : 알코올
	#quality             : 품질
	
		wine <- read.csv("whitewines.csv")


	2. 와인의 quality 데이터가 정규분포에 속하는 안정적인
	   데이터 인지 확인

		hist(wine$quality)

		설명 : 와인 품질값이 6근처를 중심으로 매우 정규적인 벨 모양의 분포를 따르는 것처럼
		       보인다.
		       대부분의 와인이 평균 품질이기 때문에 직관적으로 이해가 된다.
		이상치가 있는지 확인해본다
		summary(wine$quality)

		   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
		  3.000   5.000   6.000   5.878   6.000   9.000
	

	3. wine 데이터를 train 데이터와 test 데이터로 나눈다.

		wine_train <- wine[1:3750,  ]
		wine_test  <- wine[3751:4898, ]


	4. train 데이터를 가지고 model 을 생성한다.

		library(rpart)

		model <-  rpart( quality ~ . , data=wine_train)

		model

		n= 3750
		
		node), split, n, deviance, yval
		      * denotes terminal node
		
		 1) root 3750 2945.53200 5.870933  	
		   2) alcohol< 10.85 2372 1418.86100 5.604975  	
		     4) volatile.acidity>=0.2275 1611  821.30730 5.432030  
		       8) volatile.acidity>=0.3025 688  278.97670 5.255814 *
		       9) volatile.acidity< 0.3025 923  505.04230 5.563380 *
		     5) volatile.acidity< 0.2275 761  447.36400 5.971091 *
		   3) alcohol>=10.85 1378 1070.08200 6.328737  
		     6) free.sulfur.dioxide< 10.5 84   95.55952 5.369048 *
		     7) free.sulfur.dioxide>=10.5 1294  892.13600 6.391036  
		      14) alcohol< 11.76667 629  430.11130 6.173291  
		        28) volatile.acidity>=0.465 11   10.72727 4.545455 *
		        29) volatile.acidity< 0.465 618  389.71680 6.202265 *
		      15) alcohol>=11.76667 665  403.99400 6.596992 *

			설명 : * 표시가 있는 노드는 앞노드로, 노드에서 예측이 이뤄진다는 것을 의미한다.
			       와인 데이터이면 예측 등급이다.
			       5.97이라는 등급으로 예를 들면 alcohol < 10.85 이고
			       volatile.acidity < 0.2275이면 모든 와인 샘플 품질값이 5.97로 예측된다.


	5. 위에서 나온 모델로 트리를 시각화 하시오 !

		library(rpart.plot)
		rpart.plot( model, digits=3)

		rpart.plot(model, digits=3, fallen.leaves=T, type=3, extra=101)


	6. 위에서 만든 모델로 테스트 데이터의 라벨을 예측하시오 !

		result <- predict(model, wine_test)
		result

		    3751     3752     3753     3754     3755     3756     3757
		6.596992 5.255814 6.202265 5.971091 5.563380 6.596992 5.255814
		    3758     3759     3760     3761     3762     3763     3764
					:
					:
		5.971091 6.596992 5.563380 5.971091 5.255814 5.563380 5.563380
		    4745     4746     4747     4748     4749     4750
		5.255814 6.596992 5.255814 6.202265 5.255814 6.596992
		 [ reached getOption("max.print") -- omitted 148 entries ]


	7. 테스트 데이터의 실제 라벨(품질) 과 예측결과(품질) 을 비교한다

		cbind( round(result), wine_test$quality)


	8. 테스트 데이터의 라벨과 예측 결과와 상관관계가 어떻게 되는지
	   확인한다.

		cor(result, wine_test$quality)	# [1] 0.5369525

		설명 : 0.53은 두 데이터간의 연관 강도만 측정하는것이다.

		      그래서 두 데이터간의 오차율이 어떻게 되는지 확인해서
		      이 오차율을 줄여나가겠금 모델을 튜닝을 한다.


	9. 두 데이터간의 오차율을 확인

		MAE <-  function( actual, predicted) {
		             mean(  abs( actual - predicted) )
                                     }

		MAE( result, wine_test$quality) 	# [1] 0.5872652

		0.58  <---   이 모델의 경우 다른 모델인 서포트 벡터 머신에서의
		             오차는 0.45 인데 0.58이면 상대적으로 좀 큰 오차이
		             므로 개선의 여지가 필요하다.


		개선방법이 회귀트리 ----> 모델트리로 변경해서 개선을 한다.










★ 와인 데이터의 품질을 예측하는 모델을 모델트리를 이용해서 생성


	 분할한 후에 평균값 대신 회귀식을 이용해서 수치를 예측한다.

	1. 회귀트리 모델 생성하는 작업의 1번 ~ 3번까지 다시 반복

	2. 모델트리를 구현하기 위한 패키지 설치

		  library(RWeka)
	
	3. 와인의 품질을 예측하는 모델을 생성한다.
	
	4. 만든 모델과 테스트 데이터로 예측을 한다.

		  p.m5p <- predict( m.m5p, wine_test)

	5. 예측값(p.m5p) 과 테스트 데이터의 라벨간의 상관관계를 확인한다

		  cor( p.m5p , wine_test$quality )

		  0.62729

	5. 예측값(p.m5p) 과 테스트 데이터의 라벨간의 평균절대오차를 확인한다.

		  MAE( wine_test$quality, p.m5p)  

		  0.5463


		3?? 05, 2019 11:35:00 ???? com.github.fommil.netlib.BLAS <clinit>
		????: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
		3?? 05, 2019 11:35:00 ???? com.github.fommil.netlib.BLAS <clinit>
		????: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
		3?? 05, 2019 11:35:00 ???? com.github.fommil.netlib.LAPACK <clinit>
		????: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
		3?? 05, 2019 11:35:00 ???? com.github.fommil.netlib.LAPACK <clinit>
		????: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK
■ 7장. 신경망과 서포트 벡터 머신

	  * 목차  
	
		   1. 활성화 함수 소개
		   2. 신경망 실습 1 ( 콘크리트 데이터)
		   3. 신경망 실습 2 ( 필기체 데이터 )
		   4. 신경망 실습 3 ( 전력 생산량 데이터)









★ 1. 활성화 함수 소개
문제 242 ~ 244
	  활성화 함수란 ?   입력신호의 총합이 활성화를 일으킬지를
	                    정하는 역활을 하는 함수

	   k =  x0*w0 + x1*w1 + x2*w2
	
	   y = f(k)
	
	   1  :  신호가 흐른다.
	   0  :  신호가 안흐른다.
	
	 * 활성화 함수의 종류
	
		    1. 계단함수
		    2. 시그모이드 함수
		    3. 렐루 함수





★ 신경망 실습1 (콘크리트 데이터)


	" 콘크리트의 강도를 예측하는 신경망을 만드는 학습 "
	
	자갈, 모래, 시멘트등을 몇대 몇 비율로 섞었을 때 어느정도 강도가 나오는지 예측하는 신경망





	1.  콘크리트 데이터 소개
	
		* 콘크리트 데이터
		
		 1. mount of cement: 콘크리트의 총량
		 2. slag  :  시멘트
		 3. ash   :  분 (시멘트)
		 4. water :  물
		 5. superplasticizer :  고성능 감수재(콘크리트 강도를 높이는 첨가제)
		 6. coarse aggregate :  굵은 자갈
		 7. fine  aggregate :  잔 자갈
		 8. aging time  :  숙성시간
		
	2.  콘크리트 데이터를 R 로 로드한다.
	
	 -  머신러닝 데이터 116번
	
		concrete <- read.csv("concrete.csv")
		str(concrete)
	
	3.  정규화 함수로 데이터를 정규화 작업
	
		normalize <- function(x) {
		    return ( (x-min(x)) / (max(x) - min(x) ) )
		                         }
		
		concrete_norm <- as.data.frame(lapply(concrete,normalize) )
	
	4.  0~1사이로 데이터가 잘 변경되었는지 확인
	
		summary( concrete_norm$strength)
	
		# 본래 데이터의 최소값, 최대값과 비교
		
		summary( concrete$strength)
	
	5.  훈련 데이터,테스트 데이터를 나눈다 (8:2)
	
		concrete_train <- concrete_norm[1:773, ]
		concrete_test  <- concrete_norm[774:1030, ]
	
	6.  neuralnet 패키지를 설치한다.
	
		install.packages("neuralnet")
		library(neuralnet)
	
	7.  neuralnet 패키지에 콘크리트 훈련 데이터를 넣어서
	    모델을 생성한다.
	
		concrete_model <- neuralnet(formula=strength ~ cement + slag + ash  +
		water +superplastic + coarseagg  + fineagg  + age,
		 data =concrete_train)   
		
	
	9. 모델(신경망) 을 시각화
	
		plot(concrete_model )
	
	10. 만든 모델로 테스트 데이터를 가지고 테스트 한다
	
		model_results <-  compute(concrete_model, concrete_test[1:8])
	
		predicted_strength <-  model_results$net.result
	
	11.  예측값과 실제값간의 상관관계를 확인
	     
		cor(predicted_strength, concrete_test$strength)
		
		 0.806285848
	
	12. 모듈의 성능 개선
	
		concrete_model2 <- neuralnet(formula = strength ~ cement + slag+
		                                ash + water + superplastic + coarseagg + fineagg + age,
		                              data = concrete_train, hidden = c(5,2) )
		
		※ 설명 : hidden c(5,         2)
  			           ↑         ↑
			은닉 1층의 노드수   은닉 2층의 노드수
		
		plot(concrete_model2)
		
	13. 만든 모델로 테스트 데이터를 가지고 테스트 한다
		
		model_results2 <-  compute(concrete_model2, concrete_test[1:8])
		
		predicted_strength2 <-  model_results2$net.result
	
	14.  예측값과 실제값간의 상관관계를 확인
	     
		cor(predicted_strength2, concrete_test$strength)
		
		 0.9310356










★ 회귀 트리일 때 사용했던 와인 데이터를 신경망에 넣고 테스트

	회귀트리 모델의 결과 (상관관계) : 0.53





★ 5. 신경망 실습 2(와인 데이터 )
문제 245
	 신경망 R 패키지 : 1. neuralnet 패키지(콘크리트 데이터)
	
	                   2. nnet  패키지 (와인 데이터)
	
	1. nnet 패키지를 설치한다
	
		install.packages("nnet")
		library(nnet)
	
	2. wine 데이터를 로드한다
	
		wine <- read.csv("wine.csv")
		head(wine)
		str(wine)
	
	3. 정규화 작업을 진행한다
	
		wine_norm <- cbind(wine[1], scale(wine[-1]) )
		size <- nrow(wine_norm)
		size
	
		summary(wine_norm)
	
	4. 7:3으로 훈련데이터와 테스트 데이터를 분리한다
	
		set.seed(100)
		index <- c( sample(1:size, size *0.7) )
		
		train <- wine_norm[index, ]
		test  <- wine_norm[-index, ]
	
	
	5. 훈련 데이터로 신경망 모델을 생성한다.
	
		wine_model <- nnet(Type ~ ., data = train, size=2,
		                    decay=5e-04 , maxit=200 )  
	
		설명 :  size =2 은닉층의 뉴런수
		        decay = 5e-04 가중치감소
			maxit = 200    200에폭
	   
	6. 테스트 데이터를 모델에 넣어서 결과를 예측한다.
	
		predicted_result <- predict(wine_model, test, type = 'class')
		
		predicted_result
	
	7. 이원 교차표를 그리고 정확도를 확인한다.
	
		actual <- test$Type
		table(actual, predicted_result)
	
		model.confusion.matrix <- table(actual, predicted_result)
		
		library(gmodel)
		CrossTable(model.confusion.matrix)
	
		             | predicted_result2
		      actual |        t1 |        t2 |        t3 | Row Total |
		-------------|-----------|-----------|-----------|-----------|
		          t1 |        18 |         0 |         0 |        18 |
		             |    24.000 |     6.000 |     6.000 |           |
		             |     1.000 |     0.000 |     0.000 |     0.333 |
		             |     1.000 |     0.000 |     0.000 |           |
		             |     0.333 |     0.000 |     0.000 |           |
		-------------|-----------|-----------|-----------|-----------|
		          t2 |         0 |        18 |         1 |        19 |
		             |     6.333 |    21.491 |     4.491 |           |
		             |     0.000 |     0.947 |     0.053 |     0.352 |
		             |     0.000 |     1.000 |     0.056 |           |
		             |     0.000 |     0.333 |     0.019 |           |
		-------------|-----------|-----------|-----------|-----------|
		          t3 |         0 |         0 |        17 |        17 |
		             |     5.667 |     5.667 |    22.667 |           |
		             |     0.000 |     0.000 |     1.000 |     0.315 |
		             |     0.000 |     0.000 |     0.944 |           |
		             |     0.000 |     0.000 |     0.315 |           |
		-------------|-----------|-----------|-----------|-----------|
		Column Total |        18 |        18 |        18 |        54 |
		             |     0.333 |     0.333 |     0.333 |           |
		-------------|-----------|-----------|-----------|-----------|





★ 3. 신경망 실습 2 ( 필기체 데이터 )
문제 246 ~ 247
	* mnist 데이터
	
	  short_prac_train.csv
	  short_prac_test.csv
	
	setwd("d://data")
	mnist_test <- read.csv("short_prac_test.csv")
	mnist_train <- read.csv("short_prac_train.csv")
	
	dim(mnist_train) # 5000  785
	dim(mnist_test)  # 1000  785
	
	mnist_test[ , 1]   # 라벨 확인





★ 보스톤 집값을 예측하는 신경망 구현하기
문제 248 ~ 250
■ 8장. 연관규칙

	    - 쿠팡의 예
	    - 교보문고 홈페이지
	    - 아마존 홈페이지
	
	
	 * 연관 규칙 ?   분유와 맥주와의 관계를 알아낸 대표적인 기계학습 방법
	  
	   관련된 알고리즘 ---> Apriori 알고리즘
	
	 * Apriori 알고리즘 ?   간단한 성능 측정치를 이용해 거대한 DB 에서
	                        데이터간의 연관성을 찾는 알고리즘
	
	 * Apriori 알고리즘은 어떤 데이터의 패턴을 찾을 때 유용한가 ? (p 354)
	
	   1. 암 데이터에서 빈번히 발생하는 DNA 패턴과 단백질의 서열을 검색할때
	
	   2. 사기성 신용카드 및 보험의 이용과 결합되어 발생하는 구매 또는
	      의료비 청구의 패턴 발견
	
	 * 연관규칙를 사람이 하기 어려운 이유가 무엇인가 ?  (P 356 )
	
	    아이템의 집합을 아이템의 갯수만큼 만들려면
	
	    아이템의 갯수를 K 라고 하면 2의 K 승개의 아이템 집합이 생성되는데
	    아이템이 100개면 2의 100승개의 아이템 집합이 생기므로
	    사람이 그 많은 데이터를 직접 분석하기 어렵다 .
	
	
	    쿠팡 데이터 센터 사진 첨부
	
	 * 연관 규칙에서 사용하는 두가지 통계 척도가 무엇인가 ?  p 359
	
	  지지도 ? 특정 아이템이 데이터에서 발생하는 빈도
	
	                                 count(x)   <--- 아이템 x 의 거래건수
	   수학공식 :  support(x)  = --------------------------
	                                        N   <--- 데이터베이스의 전체 거래
	                  ↑                             건수
	     아이템 x 에 대한 지지도
	
	  신뢰도 ?    예측능력이나 정확도의 측정치
	
	                                      support(x,y)  
	   수학공식 :  confidence(x->y) = ------------------------------
	                                       support(x)
	
	     x, y 를 모두 포함하는 아이템 집합의 지지도를
	     x 만 포함하는 아이템 집합의 지지도로 나눈값
	
	예:  
	
	Transaction ID     Items Bought
	         1           우유, 버터, 시리얼
	         2           우유, 시리얼
	         3           우유, 빵
	         4           버터, 맥주, 오징어
	
	 지지도(우유 -> 시리얼) ? 우유와 시리얼을 동시에 구매할 확률 (결합확률)
	
	 신뢰도(우유 -> 시리얼) ? 우유를 구매할때 시리얼도 같이 구매할 조건부 확률
	                  
	 * 전체 아이템에서 우유와 시리얼이 동시에 출현될 확률은 ?
	
	   답 :     2/4 (50%)
	
	 * 우유를 샀을때 , 시리얼을 살 조건부 확률은 ?
	
	   답 :  2/3  (66%)
	
	 * 이와는 반대로 시리얼을 샀을때 우유를 동시에 구매할 확률은 ?  
	
	   답 :   2/2  (100%)
	
	 * 우유와 시리얼을 샀을때 지지도와 신뢰도를 각각 구하시오 !
	
	  답 :                           지지도  ,    신뢰도
	             우유 ---> 시리얼 :    50%   ,      66%
	             시리얼---> 우유  :    50%   ,      100%
	
	   
	    우유를 x 라고 하고 시리얼을 y 라고 하면
	    x 와 y 의 지지도와 신뢰도를 구하는데 모든 아이템들에 대해서
	    다 지지도와 신뢰도를 구한다.
	
	    그중에 최소 지지도 이상인 데이터만 필터링하고서
	    필터링 된것 중에 신뢰도가 가장 좋은것을 찾는다.
	    
	 * 어떻게 필터링을 하는가 ?
	
	
	TID     Items
	
	100    A C D
	200    B C E
	300    A B C E
	400    B E
	
	 * 위의 아이템에 대해서 지지도를 산정해보시오 ! 원래 지지도는
	    구매건수/전체 구매건수  로 계산할 수 있지만 여기서는 단순하게
	    아이템 갯수로 처리하시오 !
	
	 답:       아이템      지지도
	             A           2
	             B           3
	             C           3
	             D           1
	             E           3
	
	  * 이것에 대해서 지지도가 1보다 큰것만 추출해서 다시 정리하시오 !
	
	
	 답:       아이템      지지도
	             A           2
	             B           3
	             C           3
	             E           3
	
	  * 이제 아이템들간의 연관규치을 알아야하므로 다시 아이템들간의 조합으로
	    재구성하고 지지도를 다시 구하시오 !
	
	  답 :      아이템       지지도
	            A  B            1
	            A  C            2
	            A  E            1
	            B  C            2
	            B  E            3
	            C  E            2
	
	참고 :
	
	TID     Items
	
	100    A C D
	200    B C E
	300    A B C E
	400    B E
	
	     *  위의 결과에서 지지도가 1 인것은 제외하시오 !
	
	
	  답 :      아이템       지지도
	          
	            A  C            2
	            B  C            2
	            B  E            3
	            C  E            2
	
	     *  이제 각각의 아이템 목록에서 첫번째 아이템을 기준으로 동일한것을
	        찾아보시오
	
	          답 :    아이템 목록    지지도  
	                   B  C  E         2
	
	     질문 :  첫번째 아이템을 기준으로 찾는 이유는 ?
	             두번째인 C 를 기준으로 보면
	  
	참고 :
	
	TID     Items
	
	100    A C D
	200    B C E
	300    A B C E
	400    B E






★ apriori 알고리즘 예제 1  (맥주와 기저귀)
문제 251
	  " 맥주와 기저귀 판매 목록 데이터를 가지고 기저귀를 사면 맥주를
	    산다는 연관 규칙을 발견하시오 ! "
	
	1. 데이터를 로드한다.
	
	x <- data.frame(
	beer=c(0,1,1,1,0),
	bread=c(1,1,0,1,1),
	cola=c(0,0,1,0,1),
	diapers=c(0,1,1,1,1),
	eggs=c(0,1,0,0,0),
	milk=c(1,0,1,1,1) )
	
	x
	
	  beer bread cola diapers eggs milk
	1    0     1    0       0    0    1
	2    1     1    0       1    1    0
	3    1     0    1       1    0    1
	4    1     1    0       1    0    1
	5    0     1    1       1    0    1
	
	
	2. arules 패키지를 설치한다.
	
	 install.packages("arules")  
	 library(arules)
	
	 trans <-  as.matrix( x, "Transaction")
	 trans
	
	3. apriori 함수를 이용해서 연관관계를 분석한다.
	
	 rules1 <- apriori(trans, parameter=list(supp=0.2, conf=0.6,                    target="rules") )
	
	 rules1
	
	
	set of 49 rules  <-- 49개의 규칙이 발견되었고
	
	inspect(sort(rules1))
	                                     지지도    신뢰도     lift     count
	[5]  {beer}               => {diapers} 0.6     1.0000000  1.2500000 3    
	[6]  {diapers}            => {beer}    0.6     0.7500000  1.2500000 3    
	[7]  {milk}               => {bread}   0.6     0.7500000  0.9375000 3    
	[8]  {bread}              => {milk}    0.6     0.7500000  0.9375000 3    
	[9]  {milk}               => {diapers} 0.6     0.7500000  0.9375000 3    
	[10] {diapers}            => {milk}    0.6     0.7500000  0.9375000 3    
	[11] {bread}              => {diapers} 0.6     0.7500000  0.9375000 3    
	[12] {diapers}            => {bread}   0.6     0.7500000  0.9375000 3    
	[13] {cola}               => {milk}    0.4     1.0000000  1.2500000 2    
	[14] {cola}               => {diapers} 0.4     1.0000000
	
	설명 :  신뢰도가 클수록 연관관계가 높다는 의미이다.
	        lift 는 상관관계를 나타낸다.
	        연관규칙을 평가하는 지수는 지지도,신뢰도 말고도 많은데
	        그중에 꽤 많이 쓰이는것이 lift(향상도) 이다.
	
	 * 위의 맥주와 기저귀 연관 관계를 시각화 하기
	
	install.packages("sna")
	install.packages("rgl")
	library(sna)
	library(rgl)
	
	
	#visualization
	b2 <- t(as.matrix(trans)) %*% as.matrix(trans)
	library(sna)
	library(rgl)
	b2.w <- b2 - diag(diag(b2))
	#rownames(b2.w)
	#colnames(b2.w)
	gplot(b2.w , displaylabel=T , vertex.cex=sqrt(diag(b2)) , vertex.col = "green" , edge.col="blue" ,
 	      boxed.labels=F , arrowhead.cex = .3 , label.pos = 3 , edge.lwd = b2.w*2)





★ 영화 라라랜드의 긍정적 평가와 부정적 평가에 대한  워드 클라우드
문제 252

	1.  라라랜드 데이터를 로드한다.  
	
	library(KoNLP)
	library(wordcloud)
	
	lala <- read.csv('라라랜드.csv', header=T, stringsAsFactors = F)
	
	2. 영화평점이 9점이상은 긍정변수넣고 2점 이하는 부정변수에 넣는다
	
	lala_positive <- lala[lala$score>=9,c('content')]
	lala_negative <- lala[lala$score<=2,c('content')]
	
	head(lala_positive)
	head(lala_negative)
	
	3. 긍정게시판 변수에서 명사만 추출하고 데이터 정제 작업을 한다.
	
	po <- sapply(lala_positive, extractNoun, USE.NAMES=F)
	po2 <- unlist(po)
	po2 <- Filter(function(x){nchar(x)>=2},po2)
	po3 <- gsub('\\d+','',po2)
	po3 <- gsub('관람객','',po3)
	po3 <- gsub('평점', '', po3)
	po3 <- gsub('영화', '', po3)
	po3 <- gsub('진짜', '', po3)
	po3 <- gsub('완전', '', po3)
	po3 <- gsub('시간', '', po3)
	po3 <- gsub('올해', '', po3)
	po3 <- gsub('장면', '', po3)
	po3 <- gsub('남자', '', po3)
	po3 <- gsub('여자', '', po3)
	po3 <- gsub('만큼', '', po3)
	po3 <- gsub('니가', '', po3)
	po3 <- gsub('년대', '', po3)
	po3 <- gsub('옆사람', '', po3)
	po3 <- gsub('들이', '', po3)
	po3 <- gsub('저녁', '', po3)
	
	write(unlist(po3), 'lala_positive.txt')
	po4 <- read.table('lala_positive.txt')
	po_wordcount <- table(po4)
	
	
	4. 라라랜드 영화에 부정적인 평가 게시글들 명사로 변경하고
	   정재 작업을 수행한다.
	
	ne <- sapply(lala_negative, extractNoun, USE.NAMES=F)
	ne2 <- unlist(ne)
	ne2 <- Filter(function(x){nchar(x)>=2},ne2)
	ne3 <- gsub('\\d+','',ne2)
	ne3 <- gsub('관람객','',ne3)
	ne3 <- gsub('평점', '', ne3)
	ne3 <- gsub('영화', '', ne3)
	ne3 <- gsub('진짜', '', ne3)
	ne3 <- gsub('완전', '', ne3)
	ne3 <- gsub('시간', '', ne3)
	ne3 <- gsub('올해', '', ne3)
	ne3 <- gsub('장면', '', ne3)
	ne3 <- gsub('남자', '', ne3)
	ne3 <- gsub('여자', '', ne3)
	ne3 <- gsub('만큼', '', ne3)
	ne3 <- gsub('니가', '', ne3)
	ne3 <- gsub('년대', '', ne3)
	ne3 <- gsub('옆사람', '', ne3)
	ne3 <- gsub('들이', '', ne3)
	ne3 <- gsub('저녁', '', ne3)
	
	write(unlist(ne3), 'lala_negative.txt')
	ne4 <- read.table('lala_negative.txt')
	ne_wordcount <- table(ne4)
	
	
	5. 긍정 단어와 부정단어를 각각 워드 클라우드로 그려서 한 화면에
	   출력한다.
	
	graphics.off()
	palete <- brewer.pal(9,'Set1')
	par(new=T, mfrow=c(1,2))
	
	wordcloud(names(po_wordcount), freq=po_wordcount, scale=c(3,1), rot.per=0.1, random.order = F,
	          random.color = T, col=rainbow(15))
	title(main='라라랜드의 긍정적인 평가', col.main='blue')
	
	wordcloud(names(ne_wordcount), freq=ne_wordcount, scale=c(3,1), rot.per=0.1, random.order = F,
	          random.color = T, col=rainbow(15))
	title(main='라라랜드의 부정적인 평가', col.main='red')
■ 9장 K-means 군집화

	* 9장 목차

		1. k-means 군집화 이론수업
		2. k-means 군집화 실습1 (국영수 점수)
		3. k-means 군집화 실습2 (소셜 미디어에 같은 성향을 갖는 사람들을 분류)

	* 머신러닝의 종류 3가지

		1. 지도학습 :
			분류 : 의사결정트리, 나이브베이즈, knn
			회귀 : 다중 회귀 분석

		2. 비지도 학습 : k-means ─▶ 정답(라벨)없이 기계학습 시키는 학습방법

		3. 강화학습






★ 1. k-means군집화 이론 수업

	* k 평균 군집화 알고리즘이란 ? ( 문제 21번 답 )
		k평균 알고리즘은 주어진 데이터를 k개의 클러스터로 묶는 알고리즘으로 각 클러스터와 거리
		차이의 분산을 최소화 하는 방식으로 동작한다.

		이 알고리즘은 자율학습의 일종으로 레이블이 달려있지 않은 입력데이터에 레이블을 달아주는
		역할을 수행한다.

	* 컴퓨터가 어떻게 클러스터 구성에 대한 사전 지식 없이 레이블이 없는 데이터에 군집화를 가능하게
	  할까? (문제 22 답)
		클러스트 안에 있는 아이템들은 서로 아주 비슷해야 하지만 클러스터 밖에 있는 아이템들과는
		아주 달라야 한다는 원칙을 따르면 가능하다. (p 388)

	* k평균 알고리즘의 목표가 무엇인가? (문제 24)
		클러스터 내의 차이를 최소화하고 클러스터간의 차이를 최대화 하는 것이다.

	* knn과 k_means의 공통점과 차이점 ? (문제 25)
		공통점? 거리함수(유클리드 거리)를 이용해서 중심에서 가까운 거리에 있는 데이터를
		        클러스터링 한다.
		차이점? knn은 라벨(정답)이 있고 k-means는 라벨(정답)이 없다.






★ k-means 기본 실습
문제 253
	1. 기본 데이터셋을 만든다.
	2. 위에서 만든 데이터셋으로 plot그래프를 그린다.
	3. k-means패키지를 설치한다.
	4. k-means함수로 데이터를 분류한다.
	5. 분류한 파라미터값을 가지고 다시한번 시각화를 한다.
	6. 원래 데이터로 그린 plot그래프와 분류한 그래프를 같이 출력한다.




	1. 기본 데이터 셋을 만든다
	
		 c <- c(3,4,1,5,7,9,5,4,6,8,4,5,9,8,7,8,6,7,2,1)
		 row <- c("A","B","C","D","E","F","G","H","I","J")
		 col <- c("X","Y")
		data <- matrix( c, nrow= 10, ncol=2, byrow=TRUE, dimnames=list(row,col))
		data
		  X Y
		A 3 4
		B 1 5
		C 7 9
		D 5 4
		E 6 8
		F 4 5
		G 9 8
		H 7 8
		I 6 7
		J 2 1

	 2. 위에서 만든 데이터셋으로 plot 그래프를 그린다

		plot(data)
	
	 3. k-means 패키지를 설치한다

		install.packages("stats")
		library(stats)

	 4. kmeans 함수로 데이터를 분류한다.

		 ※ k 개 구하는 공식 : k=squart(n/2) (문제 29번)
	
		km <- kmeans(data,2)

		> km
		K-means clustering with 2 clusters of sizes 5, 5

		Cluster means:
		  X   Y
		1 7 8.0
		2 3 3.8

		Clustering vector:
		A B C D E F G H I J
		2 2 1 2 1 2 1 1 1 2

		Within cluster sum of squares by cluster:
		[1]  8.0 20.8
		 (between_SS / total_SS =  74.5 %)

		Available components:
		
		[1] "cluster"      "centers"      "totss"        "withinss"    
		[5] "tot.withinss" "betweenss"    "size"         "iter"        
		[9] "ifault"
		
		     
		> km$center  # 중앙점이 어딘지 확인한다.
		  X   Y
		1 7 8.0
		2 3 3.8
			
		> cbind(data, km$cluster)
		 X Y  	
		A 3 4 2
		B 1 5 2
		C 7 9 1
		D 5 4 2
		E 6 8 1
		F 4 5 2
		G 9 8 1
		H 7 8 1
		I 6 7 1
		J 2 1 2


	 5. 분류한 파라미터값을 가지고 다시 한번 시각화를 한다.  

		plot(round(km$center), col=km$center, pch=22,
		   bg=km$center, xlim=range(0:10),ylim=range(0:10))


	 6. 원래 데이터를 그린 plot 그래프와 위의 그래프를 합쳐서 출력한다.


		plot(round(km$center), col=km$center, pch=22,
		   bg=km$center, xlim=range(0:10),ylim=range(0:10))
		
		par(new=T)
		
		plot( data, col=km$cluster+1,
		      xlim=range(0:10), ylim=range(0:10) )





★ k평균 군집화 실습1 ( 국영수 점수를 가지고 학생 분류 )
문제 254 ~ 258 



★ k 평균 군집화 실습( 소개팅 데이터 )
문제 259 ~ 260




★ 3. k 평균 군집화 실습2(쇼설 미디어에 같은 성향을 갖는 사람들을 분류)
문제 261

	 1. 데이터를 로드한다.

		teens <-  read.csv("snsdata.csv")
		str(teens)

	 2. 성별이 남자가 몇명이고 여자가 몇명인지 확인한다.

		table(teens$gender)

		    F     M
		22054  5222

	 3. 성별에 NA 가 몇개인지도 출력되게하시오

		table(teens$gender, useNA="ifany")

		    F     M  <NA>
		22054  5222  2724

	 4. 고등학생 데이터라는 정확한 데이터 분석을 위해서
	    나이가 13세 ~ 20세 가 아니면 다 NA 처리해라 !  

		 teens$age <- ifelse(teens$age>=13 & teens$age <20,
		                      teens$age, NA)

		 summary(teens$age)


	5. 정확한 데이터 분석을 위해 성별에 관련한 더미변수 2개를
	   생성한다.


		teens$female <- ifelse(teens$gender=="F" & !is.na(teens$gender),
		                       1, 0)

		teens$no_gender <- ifelse(is.na(teens$gender),1,0)


		table(teens$gender, useNA="ifany")

		    F     M  <NA>
		22054  5222  2724

		table(teens$female, useNA="ifany")
		   0     1
		 7946 22054

		table(teens$no_gender, useNA="ifany")

		    0     1
		27276  2724


	6. 나이가 결측치로 나온 데이터를 졸업년도로 나이를 추정해서
	   결측치를 채워넣는 작업


		ave_age <- ave(teens$age, teens$gradyear,
		               FUN=function(x) mean(x, na.rm=TRUE) )

		ave_age

		teens$age <- ifelse( is.na(teens$age), ave_age, teens$age)

		summary(teens$age)

		 Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
		  13.03   16.28   17.24   17.24   18.21   20.00

	7. sns 에 나타났던 관심사 횟수를 표현하는 36개의 수치형 데이터
	    컬럼을 정규화 시킨다.


		interests <- teens[5:40]

		interests_z <- as.data.frame(lapply(interests, scale))

		head(interests_z)


	8. kmeans 함수로 5개의 클래스로 분류 한다.

		set.seed(2345)
		teen_clusters <- kmeans(interests_z, 5)

		teen_clusters

	9. 각 클래스의 갯수가 각각 어떻게 되는지 확인하시오

		 teen_clusters$size

		[1]   871   600  5981  1034   21514

		10. 클러스터의 중심점의 좌표를 확인한다

		 teen_clusters$centers
■ 10장. 모델 성능 평가





★ 모델 성능 평가가 중요한 이유가 무엇인가?

	머신러닝(학생)이 수행한 결과(분류, 예측)에 대한 공정한 평가를 통해 머신러닝(학생)이 앞으로도
	미래의 데이터에 대해서 잘 분류하고 예측할 수 있도록 해주고 분류결과가 요행수로 맞힌게 아니다
	라는 것을 확신하게 해주며 분류 결과를 좀 더 일반화 할 수 있기 때문이다.








★ 정확도란 무엇인가?

	학습자가 맞거나 틀린 경우의 비율을 말한다.





☆ 모델 성능평가를 위해 정확도만으로는 충분하지 않은 이유?

	암 판정하는 분류기가 99%의 정확도를 갖고 있다고 하면 1%의 오류율이 있기 때문에 어떤 데이터에
	대해서는 오류를 범할수도 있게 된다. 그래서 정확도 만으로는 성능을 측정하는데 충분치 않다.
	정확도와 더불어서 유용성에 대한 다른 성능 척도를 정의하는 것이 중요하다.
		" 정확도 + 다른 성능 척도 "





★ 그럼 다른 성능 척도에는 무엇이 있는가?

	1. 카파 통계량
	2. 민감도와 특이도
	3. 정밀도와 재현율
	4. Roc 곡선





★ 이원 교차표에서 정확도와 오류율을 확인하는 방법
문제 262







★ 카파 통계량
문제 263
    * Cohen's Kappa Coefficient ( 카파 상관계수 ) ?'
	두 관찰자간의 측정 범주 값에 대한 일치도를 측정하는 방법이다.
	      Pr(a) - Pr(e)
	k = ────────
	        1 - Pr(e)

		Pr(a) : 데이터에서 관찰된 2명의 평가자들의 일치 확률
		Pr(e) : 2명의 평가자들이 데이터로부터 계산된 확률적으로 일치할 확률(우연히 일치할 확률)

	k(카파 상관계수)가 0이면 완전 불일치이고, 1이면 완전 일치이다.

	p 436 카파지수

	예시 : 시험을 응시한 학생이 100명이라고 할 때
		2명의 평가자가 합격, 불합격을 각각 판정하고 두 평가자의 일치도를 아래와 같이 보여주고
		있다.

		설명 : 평가자 A와 B모두 40명에게 합격을, 30명에게 불합격을 주었다.
			Pr(a)는 2명의 평가자들이 일치할 확률이므로 0.7이 되게된다.
				  40 + 30        70
			Pr(a) = ────── = ─── = 0.7
				    100 	 100

			Pr(a) : 데이터에서 관찰된 2명의 평가자들의 일치 확률
			Pr(e) : 2명의 평가자들의 데이터로부터 계산된 확률적으로 일치할 확률(우연히 일치)

			Pr(e)를 계산하기 위해서는 평가자 A와 평가자 B의 각각의 합격과 불합격을 줄 확률을
			구해야 한다.

			1. 평가자 A : 합격을 60번, 불합격을 40번 주었다.
				평가자 A는 합격을 60/100 = 60%의 확률,
				         불합격을 40/100 = 40%의 확률

			2. 평가자 B : 합격을 50번, 불합격을 50번 주었다.
				평가자 B는 합격을 50/100 = 50%의 확률,
					 불합격을 50/100 = 50%의 확률
				평가자 A와 평가자 B둘 모두 확률적으로 "합격"을 줄 확률은
				0.6x0.5=0.3이다.
				평가자 A와 평가자 B둘 모두 확률적으로 "불합격"을 줄 확률은
				0.4x0.5=0.2 이다.

			Pr(e)는 데이터로부터 계산된 확률적으로 일치할 확률이므로 이 둘을 더해서
			0.3 + 0.2 = 0.5 이다.

			     Pr(a) - Pr(e)    0.7 - 0.5
			k = ─────── = ───── = 0.4 (보통일치 p436)
			       1 - Pr(e)       1 – 0.5





★ 민감도와 특이도 (p440)

	유용한 분류기를 찾으려면 보통 지나치게 보수적인 예측과 지나치게 공격적인 예측 사이에서 균형이
	필요하다.

	보수적인 예측과 공격적인 예측에 대한 것을 정하는 기준이 되는 정보가 민감도와 특이도이다.

    * 정확도 = (TP + TN) / (TP+TN+FP+FN)
	     = (20 + 880) / (20 + 90 + 10 + 880)
	     = 90%

    * 민감도 = 실제 참인것 중에서 참이라고 예측하는 비율
	     = 구매할 것으로 예측한 사람들 중에 구매한 사람의 비율
	     = TP / (TP + FN) = 20 / (20 + 10 ) = 0.66

    * 특이도 = 실제 거짓인 것중에 거짓으로 예측하는 비율
	     = 구매 안할것으로 예측한 사람들 중에 구매 안한 사람의 비율
	     = TN / (FP + TN) = 880 / (90 + 880) = 0.907

	책 442 페이지에 나와 있듯이 민감도와 특이도는 0에서 1까지의 범위에 있으며, 값이 1에 가까울 수록
	바람직 하나 실제로는 한쪽이 높으면 한쪽이 낮아져서 둘다 높게 맞출수가 없다.

	그래서 여러 모델중에 하나를 선택해야 한다면 민감도를 최고로 높게 맞춰놓고 그중에 특이도 높은것을
	선택한다.

	민감도가 높으면 특이도가 다소 낮더라도 유용한 모델이라고 볼 수 있는가?

	예를들어 예전에 신종 플루가 처음 유행했을 때 신속검사를 받아본 사람들은
	"이 검사는 정확도가 높지 않으며 추후 2~3일 소요되는 확진검사를 통해 확진판정을 내린다."
	는 말을 들어보았을 것이다.

	이런 상황이라면 민감도가 높으면 특이도가 다소 낮더라도 가치는 충분하다.






★ 정밀도와 재현율(p 442)
문제 264 ~ 265
	정밀도 = TP / (TP + FP) = 20 / (20+90) = 0.18
	       = 실제로 구매한 사람들 중에서 구매할 것으로 예측한 사람들의 비율

	재현율 = TP / (TP + FN) = 20 / (20 + 10) = 0.66
	       = 구매할 것으로 예측한 사람들 중에서 구매한 사람들의 비율 (민감도와 같다.)

	1. 소극적 예측 : 암이라고 판단하는것 자체를 소극적으로 봐서 확실한 경우가 아니면 암으로 판단
			 하지 않는 것이다. ( 정밀도 ↑, 재현율 ↓)
		병원의 경우는 안좋은 모델이다. 왜냐하면 암인 사람을 암이 라고 판단을 잘 안한다.

	2. 공격적 예측 : 조금만 의심이 가도 다 암이라고 판단한다. ( 정밀도 ↓, 재현율 ↑ )
		이 모델은 암인데 암이라고 판단하면 잘한거고 혹시 암이 아닌 사람을 암으로 예측한
		것이어서 실제로 검사 결과가 정상이었다면 오히려 다행이고 그냥 다시 재검사 받으면 된다.






★ F 척도 ( p 445)
문제 266
	정밀도와 재현율을 하나의 값으로 결합한 성능척도를 F척도라고 말한다.
	F척도는 모델의 성능을 하나의 숫자로 설명하기 때문에 모델을 나란히 비교할 수 있는 편리한 방법을
	제공한다.

		2 x 정밀도 x 재현율          2 x TP
	F척도 = ────────── = ─────────
		   재현율 + 정밀도 	2 x TP + FP + FN

	모델을 평가하려면 특이도와 민감도를 다 보고 평가를 해야하는데 그냥 F척도 하나만 보고 단순히
	비교할 수 있다.






★ 성능 트레이드 오프 시각화 (p 446)

	민감도와 특이도 또는 정밀도와 재현율과 같은 통계치가 모델의 성능을 하나의 숫자로 압축시키려고
	한다면 시각화는 다양한 조건에서 학습자가 어떻게 실행 하는지 보여준다.

    * ROC curve (p 447)
	거짓긍정을 피하면서 참 긍정을 탐지하는 것 사이의 트레이드 오프를 관찰하는데 유용하게 사용된다.

    * AUC(Area under the ROC curve)란 ?
	ROC곡선이 쓸모없는 분류기를 나타내는 점선보다 완벽한 곡선에 가깝다는 것을 정량적으로 확인할 수
	있는 수치

	## Confusion matrixes in R ----
	sms_results <- read.csv("sms_results.csv")
	
	# the first several test cases
	head(sms_results)
	
	## Visualizing Performance Tradeoffs ----
	library(ROCR)
	pred <- prediction(predictions = sms_results$prob_spam,
	                   labels = sms_results$actual_type)
	
	# ROC curves
	perf <- performance(pred, measure = "tpr", x.measure = "fpr")
	plot(perf, main = "ROC curve for SMS spam filter", col = "blue", lwd = 2)
	
	# add a reference line to the graph
	abline(a = 0, b = 1, lwd = 2, lty = 2)
	
	# calculate AUC
	perf.auc <- performance(pred, measure = "auc")
	str(perf.auc)
	unlist(perf.auc@y.values)







★ 홀드 아웃 방법 ( p453 )

	홀드 아웃 방법이란 훈련 데이터셋과 테스트 데이터셋으로 분할하는 절차를 말한다.

	이 때 훈련 데이터를 2/3, 테스트 데이터를 1/3로 나눠서 훈련 시키는데 이때 훈련 데이터는
	무작위로 샘플링 하여 추출한다.

	그런데 무작위로 추출한 훈련 데이터중에 대표적이지 않은 데이터(Outlier)가 추출되어 훈련될
	가능성이 있다. (Outlier가 섞임)

	이런 가능성을 예방하기 위한 방법으로 반복 홀드 아웃이라는 기법이 있다.





★ k-폴드 교차 검증 테스트

	데이터 : credit.csv (부도예측)
	모델 : C5.0 의사결정트리 모델
		"k-폴드 교차검증을 통해서 credit데이터로 부도 예측을 하는 모델의 평균 카파지수를 확인
		 하는게 목표가 된다."

## Estimating Future Performance ----

# partitioning data
library(caret)
credit <- read.csv("credit.csv")

# Holdout method
# using random IDs
random_ids <- order(runif(1000))
credit_train <- credit[random_ids[1:500],]
credit_validate <- credit[random_ids[501:750], ]
credit_test <- credit[random_ids[751:1000], ]

# using caret function
in_train <- createDataPartition(credit$default, p = 0.75, list = FALSE)
credit_train <- credit[in_train, ]
credit_test <- credit[-in_train, ]

# 10-fold CV
folds <- createFolds(credit$default, k = 10)
str(folds)
credit01_test <- credit[folds$Fold01, ]
credit01_train <- credit[-folds$Fold01, ]

## Automating 10-fold CV for a C5.0 Decision Tree using lapply() ----
library(caret)
library(C50)
library(irr)

credit <- read.csv("credit.csv")

set.seed(123)
folds <- createFolds(credit$default, k = 10)

cv_results <- lapply(folds, function(x) {
  credit_train <- credit[-x, ]
  credit_test <- credit[x, ]
  credit_model <- C5.0(default ~ ., data = credit_train)
  credit_pred <- predict(credit_model, credit_test)
  credit_actual <- credit_test$default
  kappa <- kappa2(data.frame(credit_actual, credit_pred))$value
  return(kappa)
})

str(cv_results)
mean(unlist(cv_results))
■ 11장. 모델 성능 개선

    * 11장 목차
	1. caret패키지를 이용한 모델 파라미터 자동 튜닝
	2. 앙상블 기법
		- bagging
		- boosting





★ 정확도를 올리기 위한 방법에 대한 질문 3가지 (p 468)
	1. 데이터에 대해 어떤 종류의 머신러닝 모델을 사용할 것인가?
		예 : 독버섯 데이터의 경우 나이브베이즈보다 규칙기반 리퍼 알고리즘이 더 정확도가 좋았다.

	2. 해당모델에 대해서 파라미터 튜닝은 어떻게 할 것인가?
		예 : knn의 k값 파라미터
		해결 방법 ? caret 패키지의 자동 파라미터 튜닝 기법을 사용

	3. 데이터를 가지고 여러 모델을 만들었을 때 이 모델중 하나를 선택해야해서 모델을 평가해야 한다면
	   어떠한 기준을 사용할 것인가?
		예 : 10장 정확도에 따른 척도 (카파계수, 정밀도, 재현율)
		해결 방법 ? caret 패키지를 활용하면 된다.




★ caret 패키지를 이용한 모델 파라미터 자동 튜닝

	" 독일은행의 채무 불이행자를 예측하는 모델 (C5.0 모델) 생성하는데 자동 파라미터 튜닝 안했을	때의
	  정확도를 비교해보는 테스트 "





1. 자동 파라미터 튜닝 안했을때의 코드

★ 독일 은행의 대출 여부 데이터로 의사결정 트리 실습


	 데이터 :   credit.csv ( 데이터 게시판 71번)

	1. 데이터를 로드한다.

	credit <- read.csv("credit.csv")
	str(credit)

	2. 데이터에 각 컬럼들을 이해한다.

	 - 라벨컬럼:   default  -->  yes  : 대출금 상환 안함
                             no   : 대출금 상환

	  예 :   prop.table( table(credit$default) )

	 no yes
	0.7 0.3


	 - 계좌 소개 :  checking_balance --> 예금계좌
	                saving_balance --->  적금계좌

	 - amount  :   대출 금액  250마르크 ~ 18424 마르크
	               ( 100 마르크 우리나라돈 6~7만원)

	  예:   summary( credit$amount)  
	  Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
	    250    1366    2320    3271    3972   18424
	>


	 과거의 데이터를 분석해보니 대출금 상환 불이행자가
	 30% 나 되어서 앞으로는 30% 이내로 떨어뜨리게
	 은행의 목표가 되겠금 model 을 생성해야한다.      

	3. 데이터가 명목형 데이터인지 확인해본다

	  str(credit)

	4. 데이터를 shuffle 시킨다

	set.seed(31)
	credit_shuffle <-  credit[sample(nrow(credit)),  ]

	5. 데이터를  9 대 1로 나눈다

	train_num<-round(0.9*nrow(credit_shuffle),0)

	credit_train <- credit_shuffle[1:train_num,]
	credit_test <- credit_shuffle[(train_num+1):nrow(credit_shuffle),]  

	6. C5.0 패키지와 훈련데이터를 이용해서 모델을 생성한다.

	library(C50)
	credit_model <- C5.0(credit_train[, -17], credit_train[,17] )

	7. 모델과 테스트 데이터로 결과를 예측한다.

	credit_result <- predict( credit_model, credit_test[ , -17] )


	8. 이원 교차표로 결과를 살펴본다.

	library(gmodels)
	CrossTable( credit_test[ , 17] , credit_result )
	                실제                예측


	 - 라벨컬럼:   default  -->  yes  : 대출금 상환 안함
	                             no   : 대출금 상환

	
	                  | credit_result
	credit_test[, 17] |        no |       yes | Row Total |
	------------------|-----------|-----------|-----------|
	               no |        66 |         9 |        75 |
	                  |     1.179 |     3.946 |           |
	                  |     0.880 |     0.120 |     0.750 |
	                  |     0.857 |     0.391 |           |
	                  |     0.660 |     0.090 |           |
	------------------|-----------|-----------|-----------|
	              yes |        11 |        14 |        25 |
	                  |     3.536 |    11.837 |           |
	                  |     0.440 |     0.560 |     0.250 |
	                  |     0.143 |     0.609 |           |
	                  |     0.110 |     0.140 |           |
	------------------|-----------|-----------|-----------|
	     Column Total |        77 |        23 |       100 |
	                  |     0.770 |     0.230 |           |
	------------------|-----------|-----------|-----------|




★ 2. 자동 파라미터 튜닝했을때 정확도

	library(caret)

	m <- train(default ~. , data =credit_train  , method="C5.0")

	m

	p <- predict(m, credit_test[ , -17])

	table( p, credit_test[,17])

	p     no yes
	  no  68  11
	  yes  7  14

	※ 결과 설명
		1. 독일 채무 불이행 데이터의 라벨 클래스에 대한 설명
		   1000개씩 샘플링을 한다.

		2. 25개의 부트스트랩 샘플이 사용되었다.
		   1000개씩 25번 샘플링해서 훈련시켰다.

		3. 총 12개의 모델이 C5.0튜닝 파라미터 model, trial, window의 조합으로 테스트 되었다는 것을
		   확인할 수 있다.
		   각 후보 모델의 정확도와 카파 통계량을 나타낸다
		   m <- train(default ~. , data =credit_train  , method="C5.0")

		4. 각주에 설명된 것처럼 가장 큰 정확도를 갖는 모델이 trials=20, model=tree, winnow=FALSE인
		   모델이다 라는 것을 알려주고 있다.

		위에서 생성한 모델 m으로 예측을 하고 실제 라벨과 비교를 한다.
		p <- predict(m, credit_test[ , -17])
		table( p, credit_test[,17])
		p     no yes
		  no  68  11
		  yes  7  14





★ 튜닝 절차 커스터 마이징 하기 (p 475)
문제 267
    * 이전 방법
    m <- train(default ~. , data =credit_train  , method="C5.0")

    * 이후 방법 (튜닝 절차 커스터마이징 한 후) p479
    ctrl <- trainControl(method="cv", number=10, selectionFunction="oneSE")
    	※ 설명 : cv    ─▶ p476 k-폴드 교차검증
    	          oneSE ─▶ p477 selectionFunction 파라미터는 다양한 후보중에서 최적의 모델을 선택하는
    	                     함수를 지정하는데 사용한다.
    	                     그런 함수는 3가지가 있는데 best, oneSE, tolerance이다.
    	                     best는 단순히 명시된 성능척도에 대해 최고값을 갖는 후보를 선택하는 것이고
    	                     이 값이 default이다.
    	                     oneSE는 최고 성능의 1표준오차 내의 가장 단순한 후보를 선택한다.

    grid <- expand.grid(.model="tree", .trials=c(1, 5, 10, 20, 25, 30, 35), .winnow="FALSE")

    m <- train(default ~. , data =credit_train  , method="C5.0", metric="Kappa", trcControl=ctrl,
    	       tuneGrid=grid)






★ 앙상블의 이해 (p 481)

	앙상블.pdf 참고






★ 독일 채무 불이행자를 예측하는 모델을 bagging기법으로 실습
문제 268
	# bagging test
	install.packages("ipred")
	library(ipred)
	credit <- read.csv("credit.csv")
	set.seed(300)
	mybag <- bagging(default~., data=credit, nbagg=25)
	"""
	nbagg 파라미터는 앙상블에서 투표할 수 있는 의사결정 트리의 수를 제어하는데 사용한다.
	(디폴트값이 25이다.)
	이 숫자를 증가시키면 모델의 성능을 한계점까지 향상시킬 수 있다.
	단점은 트리가 많은 경우 어느정도 시간이 걸린다.
	"""
	credit_pred <- predict(mybag, credit)
	table(credit_pred, credit$default)

	credit_pred  no yes
	        no  699   2
	        yes   1 298






★ 랜덤 포레스트 (p 493)
문제 269 ~ 270
	random forest는 decision tree와 bagging을 결합한 알고리즘을 말한다.

	다른 앙상블 기반의 방법들과 비교해서 랜덤포레스트는 매우 경쟁력이 있고 사용하기 쉽고 쉽게
	과적합되지 않는다.

	장점 : 1. 모든 문제에 대해 잘 수행되는 다목적 모델이다.
		   2. 범주형 또는 연속특징 뿐만아니라 잡음이 있는 데이터나 누락데이터(결측치)를 다룰 수 있다.

	단점 : 모델 해석이 쉬운 의사결정트리 와는 다르게 않게 모델 해석이 쉽지 않다.


	예제 : 독일 채무 불이행자를 예측하는 랜덤포레스트 모델 생성

		credit <- read.csv("credit.csv")
		set.seed(300)
		# install.packages("randomForest")
		library(randomForest)
		rf <- randomForest(default~., data = credit)
		rf

		Call:
		 randomForest(formula = default ~ ., data = credit)
		               Type of random forest: classification
		                     Number of trees: 500
		No. of variables tried at each split: 4

		        OOB estimate of  error rate: 23.3%
		Confusion matrix:
		     no yes class.error
		no  638  62  0.08857143
		yes 171 129  0.57000000

		credit_pred <- predict(rf, credit)
		table(credit_pred, credit$default)

		credit_pred  no yes
		        no  700   0
		        yes   0 300





★ 부스팅(Boosting) (p 486)

	앙상블.pdf 참고


	● 독일은행의 채무 불이행자를 예측하는 모델을 boosting으로 구현
		 credit <- read.csv("credit.csv")
		 install.packages("adabag")
		 library(adabag)
		 set.seed(300)
		 model_ada <- boosting(default ~ ., data=credit)
		 predict_ada <- predict(model_ada, credit)

		 # 예측 결과 확인
		 predict_ada$confusion

		               Observed Class
		Predicted Class  no yes
		            no  700   0
		            yes   0 300

		처음보는 데이터에 대한 좀 더 정확한 성능평가를 하려면 다른 평가방법을 할 필요가 있다.

		set.seed(300)
		adaboost_cv <- boosting.cv(default~., data = credit)

		i:  1 Tue Mar 12 15:52:18 2019
		i:  2 Tue Mar 12 15:52:47 2019
		i:  3 Tue Mar 12 15:53:15 2019
		i:  4 Tue Mar 12 15:53:43 2019
		i:  5 Tue Mar 12 15:54:11 2019
		i:  6 Tue Mar 12 15:54:39 2019
		i:  7 Tue Mar 12 15:55:07 2019
		i:  8 Tue Mar 12 15:55:34 2019
		i:  9 Tue Mar 12 15:56:02 2019
		i:  10 Tue Mar 12 15:56:30 2019

		adaboost_cv$confusion

		               Observed Class
		Predicted Class  no yes
		            no  594 151
		            yes 106 149
■ 7장. 서포트 벡터 머신

	아래의 검정 돌과 하얀 돌을 잘 분리하고 있는 선이 어디 입니까?

	아래에서 좀더 여유있게 분류를 하고있는 선은 B1입니까?, B2입니까?

	B1이 좀 더 여유있게 분류를 하고 있다. 이 둘사이의 거리를 마진(margin)이라고 한다.
	이 선은 단순히 생긴 선이 아니고, 수학적으로 계산이 되어서 이루어진 선이다.
	이 선을 분리선이라고 부르고 초평면(hyperplane)이라고 부르기도 한다.
	위에서 분리를 하고 있는 그림은 2차원 그림이고 3차원 그림으로 다시 나타내면 아래와 같다.

	w벡터(방향 + 힘)를 사용하는 이유? 방향을 나타내기 위해서 벡터를 사용한다.
	W : 가중치, b : 바이어스, x : 입력 데이터

	행렬의 전치는 대각선을 변경하는 건데 벡터의 전치는 방향이 90도로 변경 된다.
	다시 원래 2차원으로 나타내면 아래와 같다.



	여기에서 여유있게 분리하는 마진 선에 걸쳐 있는 데이터를 서포트 벡터라고 한다.
	이 과정의 목표는 이 공식을 이용해 두 초평면을 명시하는 가중치의 집합을 찾는 것이다. 두 평면간
	거리를 계산해야 한다.

	만약에 2차원에서는 점과 점사이의 거리를 구하면 되지만 3차원에서는 평면과 평면사이의 거리를
	구해야 해서 벡터로 거리를 구해야 한다.

	두 평면간의 거리를 다음과 같이 정의한다.

	여기서 ||W||는 유클리드 놈(원점에서 벡터 W까지의 거리)을 나타낸다.

	두 평면사이의 마진을 최대화 하는 공식 max에 있는 분자 분모를 뒤집어서 min에 나타난 식이다.
	위의 가중치 벡터인 W를 알아내는 것이 서포트머신 알고리즘의 훈련의 목표이다.


★ 서포트 벡터 머신에서 오버피팅을 줄이는 방법
문제 277 ~ 280
	C가 추가되면서 W벡터에 대한 패널티를 부여하고 있다.

	C값을 변경해 가면서 오버피팅을 예방할 수 있다.






실습1. 필기체 데이터 SVM 으로 분류 모델 생성하기(알파벳)

	|1. 데이터 로드

		letters <- read.csv("letterdata.csv")

		str(letters)

	2. 훈련 데이터와 테스터 데이터 구분 ( 8대 2로 나눈다)

		letters_train <- letters[1:16000, ]

		letters_test  <- letters[16001:20000, ]

	 3. 데이터로 모델 훈련 ----

		# 단순 선형 SVM을 훈련으로 시작

		install.packages(“kernlab”)

		library(kernlab)

		letter_classifier <- ksvm(letter ~ ., data = letters_train, kernel = "vanilladot")

	4. 모델에 대한 기본 정보 확인

		letter_classifier

	 5..모델 성능 평가 ----

	# 테스트 데이터셋에 대한 예측

		letter_predictions <- predict(letter_classifier, letters_test)
		head(letter_predictions)
		table(letter_predictions, letters_test$letter)

	 6. 일치/불일치 예측을 표시하는 TRUE/FALSE 벡터 생성

		agreement <- letter_predictions == letters_test$letter
		table(agreement)
		prop.table(table(agreement))

		agreement
		  FALSE    TRUE
		0.16075 0.83925
■ 문제 모음


문제 1. emp 데이터 프레임에서 이름과 월급을 출력하시오 !

	emp[, c("ename", "sal")]

	    ename  sal
	1   SMITH  800
	2   ALLEN 1600
	3    WARD 1250
	4   JONES 2975
	5  MARTIN 1250
	6   BLAKE 2850
	7   CLARK 2450
	8   SCOTT 3000
	9    KING 5000
	10 TURNER 1500
	11  ADAMS 1100
	12  JAMES  950
	13   FORD 3000
	14 MILLER 1300
	15   JACK 3200





문제 2. 월급이 3000인 사원들의 이름과 월급을 출력하시오 !

	> emp[emp$sal == 3000, c("ename", "sal")]
	   ename  sal
	8  SCOTT 3000
	13  FORD 3000

	> attach(emp)
	> emp[sal == 3000, c("ename", "sal")]
	   ename  sal
	8  SCOTT 3000
	13  FORD 3000




문제 3. 월급이 2000 이상인 사원들의 이름과 월급을 출력하시오 !

	emp[sal >= 2000, c("ename", "sal")]
	
	   ename  sal
	4  JONES 2975
	6  BLAKE 2850
	7  CLARK 2450
	8  SCOTT 3000
	9   KING 5000
	13  FORD 3000
	15  JACK 3200




문제 4. 직업이 SALESMAN이 아닌 사원들의 이름과 월급과 직업을 출력하시오 !

	emp[job != 'SALESMAN', c("sal", "job")]

	    sal       job
	1   800     CLERK
	4  2975   MANAGER
	6  2850   MANAGER
	7  2450   MANAGER
	8  3000   ANALYST
	9  5000 PRESIDENT
	11 1100     CLERK
	12  950     CLERK
	13 3000   ANALYST
	14 1300     CLERK
	15 3200     CLERK





문제 5. 직업이 SALESMAN이고 월급이 1000 이상인 사원들의 이름과 월급과 직업을 출력하시오 !

	emp[job == "SALESMAN" & sal >= 1000, c("ename", "job")]
	
	    ename      job
	2   ALLEN SALESMAN
	3    WARD SALESMAN
	5  MARTIN SALESMAN
	10 TURNER SALESMAN




문제 6. 아래와 같이 결과를 출력하시오 !

	 SQL> select ename || " 의 직업은 " || job
	        from emp;
	
	paste(emp$ename, "의 직업은 ", emp$job)
	
	install.packages("data.table")
	library(data.table)
	data.table(paste(emp$ename, "의 직업은 ", emp$job))

	                            V1
	 1:     SMITH 의 직업은  CLERK
	 2:  ALLEN 의 직업은  SALESMAN
	 3:   WARD 의 직업은  SALESMAN
	 4:   JONES 의 직업은  MANAGER
	 5: MARTIN 의 직업은  SALESMAN
	 6:   BLAKE 의 직업은  MANAGER
	 7:   CLARK 의 직업은  MANAGER
	 8:   SCOTT 의 직업은  ANALYST
	 9:  KING 의 직업은  PRESIDENT
	10: TURNER 의 직업은  SALESMAN
	11:     ADAMS 의 직업은  CLERK
	12:     JAMES 의 직업은  CLERK
	13:    FORD 의 직업은  ANALYST
	14:    MILLER 의 직업은  CLERK
	15:      JACK 의 직업은  CLERK




문제 7. 직업이 sALESMAN, ANALYST인 사원들의 이름과 직업을 출력하시오 !

	emp[emp$job %in% c("SALESMAN", "ANAYST"), c("ename", "sal") ]
	
	    ename  sal
	2   ALLEN 1600
	3    WARD 1250
	5  MARTIN 1250
	10 TURNER 1500




문제 8. 직업이 SALESMAN, ANAYST가 아닌 사원들의 이름과 직업을 출력하시오 !

	emp[!emp$job %in% c("SALESMAN", "ANAYST"), c("ename", "sal") ]
	
	    ename  sal
	1   SMITH  800
	4   JONES 2975
	6   BLAKE 2850
	7   CLARK 2450
	8   SCOTT 3000
	9    KING 5000
	11  ADAMS 1100
	12  JAMES  950
	13   FORD 3000
	14 MILLER 1300
	15   JACK 3200




문제 9. 커미션이 null인 사원들의 이름과 월급과 커미션을 출력하시오 !

	emp[is.na(emp$comm), c("ename", 'sal', "comm")]

	    ename  sal comm
	1   SMITH  800   NA
	4   JONES 2975   NA
	6   BLAKE 2850   NA
	7   CLARK 2450   NA
	8   SCOTT 3000   NA
	9    KING 5000   NA
	11  ADAMS 1100   NA
	12  JAMES  950   NA
	13   FORD 3000   NA
	14 MILLER 1300   NA
	15   JACK 3200   NA


	※ R에서의 null값 :
						   검색하는 방법
		1. NULL ( 아무것도 없다 )   ──▶   is.null()
		2. NA   ( 결손 값 ) 	    ──▶   is.na()
			    ↓
			어느 부분이 없거나 잘못되서 불완전한 상태
		3. NaN  ( 비수치 )          ──▶   is.na()
		    ↓
		  Not a Number

	※ NULL ( 아무것도 없다 ) 를 활용하는 때는 반복문으로 처리할 오브젝트의 초기값을 NULL 설정

		# 예제 :
			x <- NULL
			for (i in 1:10) x <- append(x, i*i)
			x
			
			 [1]   1   4   9  16  25  36  49  64  81 100





문제 10. 커미션이 NA가 아닌 사원들의 이름과 월급과 커미션을 출력하시오 !

	emp[!is.na(emp$comm), c("ename", 'sal', "comm")]
	
	    ename  sal comm
	2   ALLEN 1600  300
	3    WARD 1250  500
	5  MARTIN 1250 1400
	10 TURNER 1500    0




문제 11. 이름의 첫번째 글자가 A로 시작하는 사원들의 이름과 월급을 출력하시오 !

	emp[grep('^A.*', emp$ename), c("ename", "sal")]
	
	   ename  sal
	2  ALLEN 1600
	11 ADAMS 1100

		※ 설명 :
			^ : 첫번째
			$ : 마지막
			. : 한자리수
			* : wild card(%)





문제 12. 이름의 끝글자가 T로 끝나는 시원들의 이름과 월급을 출력하시오 !

	emp[grep('*.T$', emp$ename), c("ename", "sal")]
	
	  ename  sal
	8 SCOTT 3000




문제 13. (점심시간 문제) 이름의 두번째 철자가 M인 사원들의 이름과 월급을 출력하시오 !

	emp[grep('^.M', emp$ename), c("ename", "sal")]

	  ename sal
	1 SMITH 800





문제 14. 부서번호를 출력하는데 중복제거해서 출력하시오 !

unique(emp$deptno)
library(data.table)
data.table("부서번호"=unique(emp$deptno))





문제 15. 이름과 월급을 출력하는데 월급이 높은 사원부터 출력하시오 !

	emp[order(emp$sal, decreasing=T), c("ename", "sal")]
###	↑
###	Data Frame : emp[행, 열]

	    ename  sal
	9    KING 5000
	15   JACK 3200
	8   SCOTT 3000
	13   FORD 3000
	4   JONES 2975
	6   BLAKE 2850
	7   CLARK 2450
	2   ALLEN 1600
	10 TURNER 1500
	14 MILLER 1300
	3    WARD 1250
	5  MARTIN 1250
	11  ADAMS 1100
	12  JAMES  950
	1   SMITH  800




문제 16. 이름과 입사일을 출력하는데 먼저 입사한 사원부터 출력하시오 !

	emp[order(emp$hiredate, decreasing=F), c("ename", "hiredate")]
	
	    ename   hiredate
	1   SMITH 1980-12-17
	2   ALLEN 1981-02-20
	3    WARD 1981-02-22
	4   JONES 1981-04-02
	6   BLAKE 1981-05-01
	7   CLARK 1981-06-09
	10 TURNER 1981-09-08
	5  MARTIN 1981-09-28
	9    KING 1981-11-17
	12  JAMES 1981-12-03
	13   FORD 1981-12-03
	14 MILLER 1982-01-23
	15   JACK 1982-01-23
	8   SCOTT 1987-04-19
	11  ADAMS 1987-05-23






문제 17. 직업이 SALESMAN인 사원들의 이름과 월급과 직업을 출력하는데 월급이 높은 사원부터 출력하시오 !

	dummy <- emp[emp$job=="SALESMAN", c("sal", "job")]
	dummy[order(dummy$sal, decreasing = T),]
	
	    sal      job
	2  1600 SALESMAN
	10 1500 SALESMAN
	3  1250 SALESMAN
	5  1250 SALESMAN






** dummy라는 변수를 지워버리고 싶으면 ?
rm(dummy)
ls()
** 모든 변수 삭제
rm(list=ls())






문제 18. 이름과 월급을 출력하는데 월급이 높은 사원순으로 출력하는 것을 doBy패키지를 이용해서 출력하시오 !

	install.packages("doBy")
	library(doBy)
	orderBy( ~-sal, emp[, c("ename", "sal")])

	    ename  sal
	9    KING 5000
	15   JACK 3200
	8   SCOTT 3000
	13   FORD 3000
	4   JONES 2975
	6   BLAKE 2850
	7   CLARK 2450
	2   ALLEN 1600
	10 TURNER 1500
	14 MILLER 1300
	3    WARD 1250
	5  MARTIN 1250
	11  ADAMS 1100
	12  JAMES  950
	1   SMITH  800





문제 19. 직업이 ANALYST가 아닌 사원들의 이름과 월급과 직업을 출력하는데 월급이 높은 사원부터 출력하시오 !

	library(doBy)
	orderBy( ~-sal, emp[emp$job != "ANALYST", c("ename", "sal", "job")])
	
	    ename  sal       job
	9    KING 5000 PRESIDENT
	15   JACK 3200     CLERK
	4   JONES 2975   MANAGER
	6   BLAKE 2850   MANAGER
	7   CLARK 2450   MANAGER
	2   ALLEN 1600  SALESMAN
	10 TURNER 1500  SALESMAN
	14 MILLER 1300     CLERK
	3    WARD 1250  SALESMAN
	5  MARTIN 1250  SALESMAN
	11  ADAMS 1100     CLERK
	12  JAMES  950     CLERK
	1   SMITH  800     CLERK




문제 20. 카페에서 crime_loc.csv를 내려받고 R에 로드한 후에 살인이 일어나는 장소와 건수를 출력하는데
	 살인이 일어나는 건수가 높은것부터 출력하시오 !

	crime_loc <- read.csv("crime_loc.csv", header=T)
	crime_loc
	library(doBy)
	attach(crime_loc)
	orderBy( ~-건수, crime_loc[범죄=="살인", c("장소", "건수")])
	
	            장소 건수
	83            집  312
	85          노상  280
	82        아파트  242
	108         기타  131
	89          병원   87
	88      숙박업소   43
	90        사무실   40
	86          상점   23
	101     의료기관   19
	91          공장   15
	98        유원지   13
	96          교통    9
	94      역대합실    8
	99          학교    8
	103         산야    8
	87      시장노점    5
	92        공사장    4
	93          창고    4
	107         공지    3
	102     종교기관    2
	104         해상    2
	84      고속도로    1
	95        지하철    1
	97  유흥접객업소    1
	105         부대    1
	100     금융기관    0
	106     구금장소    0




문제 21. 범죄의 유형이 무엇이 있는지 중복제거해서 출력하시오 !

	library(data.table)
	data.table("범죄유형"=unique(crime_loc$범죄))
	
	                        범죄유형
	 1:                         절도
	 2:                         장물
	 3:                         손괴
	 4:                         살인
	 5:                         강도
	 6:                         방화
	 7:                         강간
	 8:                         폭행
	 9:                         상해
	10:                         협박
	11:                         공갈
	12:                   약취와유인
	13:                   체포와감금
	14: 폭력행위등처벌에관한법률위반
	15:                         간통
	16:                   도박과복표
	17:                   과실치사상
	18:             업무상과실치사상
	19:                         실화
	20:                     주거침입
	21:                         유기
	22:                 교통사고처리
	23:               도로교통법위반
	                        범죄유형




문제 22. 부서번호가 10번, 20번인 사원들의 이름과 월급과 부서번호를 출력하는데 월급이 높은 사원부터 출력하시오 !

	library(doBy)
	attach(emp)
	orderBy( ~-sal, emp[!emp$deptno==30, c("ename", "sal", "deptno")])
	
	    ename  sal deptno
	9    KING 5000     10
	15   JACK 3200     70
	8   SCOTT 3000     20
	13   FORD 3000     20
	4   JONES 2975     20
	7   CLARK 2450     10
	14 MILLER 1300     10
	11  ADAMS 1100     20
	1   SMITH  800     20





문제 23. 이름과 직업을 출력하는데 소문자로 출력하시오 !

	data.table("이름" = tolower(emp$ename), "직업" = tolower(emp$job))
	cbind(tolower(emp$ename), tolower(emp$job))
	
	      이름      직업
	 1:  smith     clerk
	 2:  allen  salesman
	 3:   ward  salesman
	 4:  jones   manager
	 5: martin  salesman
	 6:  blake   manager
	 7:  clark   manager
	 8:  scott   analyst
	 9:   king president
	10: turner  salesman
	11:  adams     clerk
	12:  james     clerk
	13:   ford   analyst
	14: miller     clerk
	15:   jack     clerk




문제 24. (R로 함수 생성) 아래와 같이 이름을 물어보게 하고 이름을 입력하면 해당 사원의 이름과 월급이
	 출력되는 R코드를 작성하시오 !

	find_sal <- function() {
	  response <- readline(prompt="이름을 입력하세요 !")
	  x <- emp[emp$ename==response, c("ename", "sal")]
	  print(x)
	}
	find_sal()
	
	이름을 입력하세요 !SCOTT
	  ename  sal
	8 SCOTT 3000




문제 25. 위의 문제를 다시 해결하는데 이름을 소문자로 입력해도 출력되게 하시오 !

	find_sal <- function() {
	  response <- readline(prompt="이름을 입력하세요 !")
	  x <- emp[emp$ename == toupper(response), c("ename", "sal")]
	  print(x)
	}
	find_sal()
	scott
	
	이름을 입력하세요 !scott
	  ename  sal
	8 SCOTT 3000




문제 26. (substr) 이름의 두번째 철자가 m인 사원들의 이름과 월급을 출력하는데 substr함수를 사용해서 출력하시오 !

	emp[substr(emp$ename, 2, 2) == "M", c("ename", "sal")]
##	## 이름의 두번째 자리부터 두번째 자리까지
	
	  ename sal
	1 SMITH 800





문제 27. 이름을 출력하고 이름 옆에 이름의 첫번재 철자부터 세번째 철자까지 출력하시오 !

	data.table(이름=emp$ename, 이름=substr(emp$ename, 1, 3))
	
	      이름 이름
	 1:  SMITH  SMI
	 2:  ALLEN  ALL
	 3:   WARD  WAR
	 4:  JONES  JON
	 5: MARTIN  MAR
	 6:  BLAKE  BLA
	 7:  CLARK  CLA
	 8:  SCOTT  SCO
	 9:   KING  KIN
	10: TURNER  TUR
	11:  ADAMS  ADA
	12:  JAMES  JAM
	13:   FORD  FOR
	14: MILLER  MIL
	15:   JACK  JAC




문제 28. 이름과 월급을 출력하는데 월급을 출력할 때 숫자 0을 * 로 출력하시오 !

	data.table(이름=emp$ename, 월급=gsub(0, '*', emp$sal))
	
	      이름 월급
	 1:  SMITH  8**
	 2:  ALLEN 16**
	 3:   WARD 125*
	 4:  JONES 2975
	 5: MARTIN 125*
	 6:  BLAKE 285*
	 7:  CLARK 245*
	 8:  SCOTT 3***
	 9:   KING 5***
	10: TURNER 15**
	11:  ADAMS 11**
	12:  JAMES  95*
	13:   FORD 3***
	14: MILLER 13**
	15:   JACK 32**


문제 29. 이름과 월급을 출력하는데 월급을 출력할 때에 숫자 0, 1, 2를 *로 출력하시오 !

	data.table(이름=emp$ename, 월급=gsub('[0-2]', '*', emp$sal))
	
	      이름 월급
	 1:  SMITH  8**
	 2:  ALLEN *6**
	 3:   WARD **5*
	 4:  JONES *975
	 5: MARTIN **5*
	 6:  BLAKE *85*
	 7:  CLARK *45*
	 8:  SCOTT 3***
	 9:   KING 5***
	10: TURNER *5**
	11:  ADAMS ****
	12:  JAMES  95*
	13:   FORD 3***
	14: MILLER *3**
	15:   JACK 3***




문제 30. 6의 9승을 출력하시오 !

	6^9
	
	[1] 10077696





문제 31. 10을 3으로 나눈 나머지값이 무엇인가?

	10%%3
	
	[1] 1






문제 32. 이름과 연봉을 출력하는데 연봉은 월급에 12를 곱해서 출력하고 컬럼명을 한글로 연봉으로 출력되게
	 하시오 !

	data.table(이름=emp$ename, 연봉=emp$sal*12)
	
	      이름  연봉
	 1:  SMITH  9600
	 2:  ALLEN 19200
	 3:   WARD 15000
	 4:  JONES 35700
	 5: MARTIN 15000
	 6:  BLAKE 34200
	 7:  CLARK 29400
	 8:  SCOTT 36000
	 9:   KING 60000
	10: TURNER 18000
	11:  ADAMS 13200
	12:  JAMES 11400
	13:   FORD 36000
	14: MILLER 15600
	15:   JACK 38400




문제 33. 이름과 연봉을 출력하는데 연봉이 높은것부터 출력하시오 !

	orderBy( ~-연봉, data.table(이름=emp$ename, 연봉=emp$sal*12))
	
	      이름  연봉
	 1:   KING 60000
	 2:   JACK 38400
	 3:  SCOTT 36000
	 4:   FORD 36000
	 5:  JONES 35700
	 6:  BLAKE 34200
	 7:  CLARK 29400
	 8:  ALLEN 19200
	 9: TURNER 18000
	10: MILLER 15600
	11:   WARD 15000
	12: MARTIN 15000
	13:  ADAMS 13200
	14:  JAMES 11400
	15:  SMITH  9600




문제 34. 위의 결과를 다시 출력하는데 round함수를 이용해서 아래와 같이 100단위에서 반올림되게 하시오 !

	orderBy( ~-연봉, data.table(이름=emp$ename, 연봉=round(emp$sal*12, digits=-3)))
	
	      이름  연봉
	 1:   KING 60000
	 2:   JACK 38000
	 3:  JONES 36000
	 4:  SCOTT 36000
	 5:   FORD 36000
	 6:  BLAKE 34000
	 7:  CLARK 29000
	 8:  ALLEN 19000
	 9: TURNER 18000
	10: MILLER 16000
	11:   WARD 15000
	12: MARTIN 15000
	13:  ADAMS 13000
	14:  JAMES 11000
	15:  SMITH 10000

		※ R의 round의 특징
			122 ───────123
				122.5
			round(122.5)  ──▶ 122선택

			123 ───────124
				123.5
			round(123.5)  ──▶ 124선택

				"R은 짝수를 좋아한다."





문제 35. 문제 34번 결과를 다시 출력하는데 100자리 이후를 다 버려서 출력하시오 !

	orderBy( ~-연봉, data.table(이름=emp$ename, 연봉=trunc(emp$sal*12, -3)))

	※ 설명 R에서 trunc는 소수점에서만 가능하다.





문제 36. 오늘 날짜를 출력하시오 !

	Sys.Date()
		
	[1] "2019-02-14"





문제 37. 이름, 입사한 날짜부터 오늘까지 총 몇일 근무했는지 출력하시오 !

	data.table(emp$ename, Sys.Date() - as.Date(emp$hiredate))

	        V1         V2
	 1:  SMITH 13938 days
	 2:  ALLEN 13873 days
	 3:   WARD 13871 days
	 4:  JONES 13832 days
	 5: MARTIN 13653 days
	 6:  BLAKE 13803 days
	 7:  CLARK 13764 days
	 8:  SCOTT 11624 days
	 9:   KING 13603 days
	10: TURNER 13673 days
	11:  ADAMS 11590 days
	12:  JAMES 13587 days
	13:   FORD 13587 days
	14: MILLER 13536 days
	15:   JACK 13536 days

		**날짜 - 날짜

		오라클 		vs 		R
		to_date 			as.Date





문제 38. 오늘날짜의 달에 마지막 날짜를 출력하시오 !

	SQL> select last_day(sysdate) from dual;
	
	install.packages("lubridate")
	library(lubridate)
	last_day <- function(x) {
	  ceiling_date(x, "month") - days(1)
	}
	last_day(Sys.Date())
	#ceiling_date(Sys.Date(), "month")

	[1] "2019-02-28"




문제 39. (오늘의 마지막 문제) last_day 함수 처럼 first_day함수도 생성하시오 !

	first_day <- function(x) {
	  floor_date(x, "month")
	}
	first_day(Sys.Date())
	[1] "2019-02-01"





문제 40. 오라클에 접속해서 오늘부터 돌아오는 월요일의 날짜를 SQL로 출력하시오 !

	SQL> select next_day(sysdate, '월요일') from dual;

	next_day <- function(x, day) {
	    for (y in 1:7 ) {
	        check_date = as.Date(x+days(y))
	        if (format(check_date, '%A') == day) {
	            print(check_date)
	            }
	        }
	    }
	next_day(Sys.Date(), '월요일')

	[1] "2019-02-18"




문제 41. 이름, 입사한 요일을 출력하시오 !

	data.table( emp$ename, format(as.Date(emp$hiredate), '%A'))
	
	        V1     V2
	 1:  SMITH 수요일
	 2:  ALLEN 금요일
	 3:   WARD 일요일
	 4:  JONES 목요일
	 5: MARTIN 월요일
	 6:  BLAKE 금요일
	 7:  CLARK 화요일
	 8:  SCOTT 일요일
	 9:   KING 화요일
	10: TURNER 화요일
	11:  ADAMS 토요일
	12:  JAMES 목요일
	13:   FORD 목요일
	14: MILLER 토요일
	15:   JACK 토요일




문제 42. 내가 무슨 요일에 태어났는지 출력하시오 !

	format(as.Date('1993-03-02'), "%A")
	
	[1] "화요일"






문제 43. add_months 함수를 R에서 생성하시오 !

	SQL> select add_months(syadate, 100)
		from dual;

	add_months <- function(x, mon) {
	    print(x + months(mon))
	}
	add_months(Sys.Date(), 100)

	[1] "2027-06-15"






문제 44. 이름, 월급, 등급을 출력하는데 월급이 1500 이상이면 등급을 A로 출력하고 아니면 B로 출력하시오 !

	data.table( emp$ename, emp$sal, ifelse(emp$sal>=1500, "A", "B"))







문제 45. 이름, 월급, 등급을 출력하는데 월급이 3000이상이면 A를 출력하고 월급이 1500이상이고 3000보다
	 작으면 B를 출력하고 나머지 사원들은 C를 출력하시오 !

	data.table( emp$ename, emp$sal, ifelse(emp$sal>=3000, "A",
	                                       ifelse(emp$sal>=1500, "b", "C")))





문제 47. 이름과 커미션을 출력하는데 커미션이 NA인 사원들은 no comm으로 출력되게 하시오 !

	SQL> select ename, nvl(to_char(comm), 'no comm') from emp;
	
	data.table(emp$ename, ifelse(is.na(emp$comm), "no comm", emp$comm))
	
	        V1      V2
	 1:  SMITH no comm
	 2:  ALLEN     300
	 3:   WARD     500
	 4:  JONES no comm
	 5: MARTIN    1400
	 6:  BLAKE no comm
	 7:  CLARK no comm
	 8:  SCOTT no comm
	 9:   KING no comm
	10: TURNER       0
	11:  ADAMS no comm
	12:  JAMES no comm
	13:   FORD no comm
	14: MILLER no comm
	15:   JACK no comm





문제 48. 최대 월급을 출력하시오 !

	max(emp$sal)
	
	[1] 5000






문제 49. 직업이 SALESMAN인 사원들 중에서 최대 월급을 출력하시오 !

	x <- emp[emp$job == "SALESMAN", c("sal")]
	max(x)

	[1] 1600






문제 50. 직업과 직업별 최대월급을 출력하시오 !

	SQL> select job, max(sal)
		from emp
		group by job;

	aggregate(sal~job, emp, max)
	
	        job  sal
	1   ANALYST 3000
	2     CLERK 3200
	3   MANAGER 2975
	4 PRESIDENT 5000
	5  SALESMAN 1600




문제 51. 부서번호, 부서번호별 최소 월급을 출력하시오 !

	aggregate(sal~deptno, emp, min)

	  deptno  sal
	1     10 1300
	2     20  800
	3     30  950
	4     70 3200




문제 52. 부서번호, 직업, 토탈월급을 출력하시오 !

	SQL> select deptno, job, sum(sal)
		from emp
		group by deptno, job;

	aggregate(sal~deptno+job, emp, sum)

	   deptno       job  sal
	1      20   ANALYST 6000
	2      10     CLERK 1300
	3      20     CLERK 1900
	4      30     CLERK  950
	5      70     CLERK 3200
	6      10   MANAGER 2450
	7      20   MANAGER 2975
	8      30   MANAGER 2850
	9      10 PRESIDENT 5000
	10     30  SALESMAN 5600





문제 53. 부서번호, 부서번호별 최대월급을 출력하는데 부서번호별 최대월급이 높은것부터 출력하시오 !

	orderBy(~-sal, aggregate(sal~deptno, emp, max))
	
	  deptno  sal
	1     10 5000
	4     70 3200
	2     20 3000
	3     30 2850





문제 54. 위의 컬럼명을 한글로 부서번호, 토탈월급으로 변경하시오 !

	x <- orderBy(~-sal, aggregate(sal~deptno, emp, max))
	names(x) <- c("부서번호", " 토탈월급")
	x
	
	  부서번호  토탈월급
	1       10      5000
	4       70      3200
	2       20      3000
	3       30      2850






문제 55. 직업과 직업별 인원수를 출력하시오 !

	#세로로 출력
	aggregate(empno~job, emp, length)
	
	        job empno
	1   ANALYST     2
	2     CLERK     5
	3   MANAGER     3
	4 PRESIDENT     1
	5  SALESMAN     4
	
	#가로로 출력
	table(emp$job)
	
	  ANALYST     CLERK   MANAGER PRESIDENT  SALESMAN
	        2         5         3         1         4




문제 56. 위의 결과를 막대 그래프로 그리시오 !

	x <- table(emp$job)
	barplot(x, main="직업별 인원수", col=rainbow(5), density=50)
	




문제 57. 직업, 직업별 평균월급을 출력하시오 !

	#세로:
	aggregate(sal~job, emp, mean)

	        job      sal
	1   ANALYST 3000.000
	2     CLERK 1470.000
	3   MANAGER 2758.333
	4 PRESIDENT 5000.000
	5  SALESMAN 1400.000
	
	#가로:
	tapply(emp$sal, emp$job, mean)

	  ANALYST     CLERK   MANAGER PRESIDENT  SALESMAN
	 3000.000  1470.000  2758.333  5000.000  1400.000




문제 58. 위의 결과를 다시 출력하는데 소숫점 이하는 안나오게 하시오 !

	#세로 :
	x <- aggregate(sal~job, emp, mean)
	data.table(직업 = x$job, 평균월급 = trunc(x$sal))
	
	        직업 평균월급
	1:   ANALYST     3000
	2:     CLERK     1470
	3:   MANAGER     2758
	4: PRESIDENT     5000
	5:  SALESMAN     1400
	
	#가로 :
	x2 <- tapply(emp$sal, emp$job, mean)
	
	trunc(x2)
	  ANALYST     CLERK   MANAGER PRESIDENT  SALESMAN
	     3000      1470      2758      5000      1400





문제 59. 입사한 년도, 입사한 년도별 평균월급을 가로로 출력하시오 !

	#답1 :
	x <- data.table(입사년도 = substr(emp$hiredate, 1, 4), 월급=emp$sal)
	tapply(x$월급, x$입사년도, mean)
	
	  1980   1981   1982   1987
	 800.0 2282.5 2250.0 2050.0
	
	#답2 :
	x <- data.table(입사년도 = year(emp$hiredate), 월급=emp$sal)
	tapply(x$월급, x$입사년도, mean)
	
	  1980   1981   1982   1987
	 800.0 2282.5 2250.0 2050.0





문제 60. 위의 결과를 막대 그래프로 그리시오 !

	x <- data.table(입사년도 = year(emp$hiredate), 월급=emp$sal)
	x1 <- tapply(x$월급, x$입사년도, mean)
	barplot(x1, main="년도별 평균월급", col=rainbow(5), density=50)





문제 61. 직업, 부서번호, 직업별 부서번호별 토탈월급을 출력하시오 !

	tapply(emp$sal, list(emp$job, emp$deptno), sum)
	
	            10   20   30   70
	ANALYST     NA 6000   NA   NA
	CLERK     1300 1900  950 3200
	MANAGER   2450 2975 2850   NA
	PRESIDENT 5000   NA   NA   NA
	SALESMAN    NA   NA 5600   NA




문제 62. 위의 결과중에 NA를 0으로 출력되게 하시오 !

	x <- tapply(emp$sal, list(emp$job, emp$deptno), sum)
	x[is.na(x)] <- 0
	x
	
	            10   20   30   70
	ANALYST      0 6000    0    0
	CLERK     1300 1900  950 3200
	MANAGER   2450 2975 2850    0
	PRESIDENT 5000    0    0    0
	SALESMAN     0    0 5600    0




문제63. 직업, 입사년도(4자리)

	t_a <- tapply(sal, list( year(hiredate), job), sum)
	t_a[is.na(t_a)] <- 0
	t_a

	     ANALYST CLERK MANAGER PRESIDENT SALESMAN
	1980       0   800       0         0        0
	1981    3000   950    8275      5000     5600
	1982       0  4500       0         0        0
	1987    3000  1100       0         0        0





문제64. 위의 결과에서 column name과 row name을 각각 출력

	colnames(t_a)
	[1] "ANALYST"   "CLERK"     "MANAGER"   "PRESIDENT" "SALESMAN"

	rownames(t_a)
	[1] "1980" "1981" "1982" "1987"





문제65. 문제64번의 결과를 막대그래프로 시각화

	barplot(t_a, col=rainbow(7), legend=rownames(x), beside=T)




문제 66. 직업, 직업별 토탈월급을 원형 ( pie )그래프로 그리시오 !

	t_a <- tapply(emp$sal, emp$job, sum)
	pie(x, col=rainbow(5), density=80)




문제 67. 위의 그래프를 3D로 출력하시오 !

	install.packages("plotrix")
	library(plotrix)
	pie3D(t_a, explode=0.1, labels=rownames(x))





문제 68. 문제 67번 시각화 결과 옆 즉 직업 옆에 비율도 같이 출력되게 하시오 !

	x <- tapply(emp$sal, emp$job, sum)
	x2 <- aggregate(sal~job, emp, sum)
	pct <- round(x2$sal/sum(emp$sal)*100,1)
	pct
	lbls <- x2$job
	lbls
	lbls2 <- paste(lbls, ":", pct, '%')
	lbls2
	pie3D(x, explode=0.1, labels=lbls2)




문제 69. crime_loc.csv를 가지고 범죄유형이 살인인 장소와 건수를 출력하시오 !

	crime_loc[crime_loc$범죄=="살인", c("장소", "건수")]
	
	            장소 건수
	82        아파트  242
	83            집  312
	84      고속도로    1
	85          노상  280
	86          상점   23
	87      시장노점    5
	88      숙박업소   43
	89          병원   87
	90        사무실   40
	91          공장   15
	92        공사장    4
	93          창고    4
	94      역대합실    8
	95        지하철    1
	96          교통    9
	97  유흥접객업소    1
	98        유원지   13
	99          학교    8
	100     금융기관    0
	101     의료기관   19
	102     종교기관    2
	103         산야    8
	104         해상    2
	105         부대    1
	106     구금장소    0
	107         공지    3
	108         기타  131





문제 70. 위의 결과를 x5변수에 담고 아래의 결과로 3D원형그래프를 그리시오 !

	x5 <- crime_loc[crime_loc$범죄=="살인", c("장소", "건수")]
	x6 <- tapply(x5$건수, x5$장소, sum)
	barplot(x6, col=rainbow(14))





문제 72. tapply함수를 이용해서 전통시장과 대형마트간의 물품별 가격 평균을 출력하시오 !

	x <- round(tapply(price$A_PRICE, list(price$A_NAME, price$M_TYPE_NAME), mean))
	x[is.na(x)] <- 0
	x

	                      대형마트 전통시장
	고등어                    3313     3000
	고등어(30cm,국산)         5020     3140
	고등어(30cm,수입산)       3980        0
	고등어(냉동,국산)         3873     3415
	고등어(냉동,수입산)       2430     2500





문제 73. 위의 결과를 다시 출력하는데 가격이 높은것부터 출력되게 하는데 대형마트를 기준으로 출력되게 하시오 !

	orderBy(~-대형마트, x)
	
	                      대형마트 전통시장
	쇠고기(육우,불고기)      23400    15142
	쇠고기(한우,불고기)      22338    17774
	쇠고기                   20280        0
	쇠고기(한우1등급)        19779    19800
	쇠고기(한우2등급)        18500    15640
	돼지고기(생삼겹살)       11331     9705




문제 74. dept.csv를 내려받아 dept라는 변수에 로드하고 이름과 월급과 부서위치를 출력하시오 !

	dept <- read.csv("dept.csv", header=T)
	x <- merge(emp, dept, by = "deptno")
	x[, c("ename", "sal", "loc")]
	
	    ename  sal      loc
	1    KING 5000 NEW YORK
	2  MILLER 1300 NEW YORK
	3   CLARK 2450 NEW YORK
	4   SMITH  800   DALLAS
	5   JONES 2975   DALLAS
	6    FORD 3000   DALLAS
	7   ADAMS 1100   DALLAS
	8   SCOTT 3000   DALLAS
	9   ALLEN 1600  CHICAGO
	10  BLAKE 2850  CHICAGO
	11 MARTIN 1250  CHICAGO
	12 TURNER 1500  CHICAGO
	13   WARD 1250  CHICAGO
	14  JAMES  950  CHICAGO





문제 75. 부서위치가 DALLAS인 사원들의 이름과 월급과 부서위치를 출력하시오 !

	x[x$loc=='DALLAS', c("ename", "sal", "loc")]
	  ename  sal    loc
	4 SMITH  800 DALLAS
	5 JONES 2975 DALLAS
	6  FORD 3000 DALLAS
	7 ADAMS 1100 DALLAS
	8 SCOTT 3000 DALLAS




문제 76. 커미션이 NA인 사원들의 이름과 부서위치와 커미션을 출력하시오 !

	x[is.na(x$comm), c("ename", "loc", "comm")]

	    ename      loc comm
	1    KING NEW YORK   NA
	2  MILLER NEW YORK   NA
	3   CLARK NEW YORK   NA
	4   SMITH   DALLAS   NA
	5   JONES   DALLAS   NA
	6    FORD   DALLAS   NA
	7   ADAMS   DALLAS   NA
	8   SCOTT   DALLAS   NA
	10  BLAKE  CHICAGO   NA
	14  JAMES  CHICAGO   NA




문제 77. 이름과 부서위치를 출력하는데 오라클의 outer join과 같은 결과를 출력하시오 !

	SQL> select e.ename, d.loc
		from emp e dept d
		where e.deptno (+) = d.deptno;
	
	x <- merge(emp, dept, by="deptno", all.y=T)
	x[, c("ename", "loc")]
	
	    ename      loc
	1    KING NEW YORK
	2  MILLER NEW YORK
	3   CLARK NEW YORK
	4   SMITH   DALLAS
	5   JONES   DALLAS
	6    FORD   DALLAS
	7   ADAMS   DALLAS
	8   SCOTT   DALLAS
	9   ALLEN  CHICAGO
	10  BLAKE  CHICAGO
	11 MARTIN  CHICAGO
	12 TURNER  CHICAGO
	13   WARD  CHICAGO
	14  JAMES  CHICAGO
	15   <NA>   BOSTON




문제 78. 아래의 SQL의 결과를 R로 구현하시오 !

	SQL> select e.ename, d.loc
		from emp e full outer join dept d
		on ( e.deptno = d.deptno );
	
	x <- merge(emp, dept, by="deptno", all=T)
	x[, c("ename", "loc")
	
	    ename      loc
	1    KING NEW YORK
	2  MILLER NEW YORK
	3   CLARK NEW YORK
	4   SMITH   DALLAS
	5   JONES   DALLAS
	6    FORD   DALLAS
	7   ADAMS   DALLAS
	8   SCOTT   DALLAS
	9   ALLEN  CHICAGO
	10  BLAKE  CHICAGO
	11 MARTIN  CHICAGO
	12 TURNER  CHICAGO
	13   WARD  CHICAGO
	14  JAMES  CHICAGO
	15   <NA>   BOSTON
	16   JACK     <NA>





문제 79. 이름 자기의 직속상사의 이름(관리자)을 출력하시오 !

	SQL> select e.ename, m,ename
		from emp e, emp m
		whrere e.mgr = m.empno;
	
	x <- merge(emp, emp, by.x='mgr', by.y='empno')
	x
	data.table(ename=x$ename.x, mgr=x$ename.y)
	
	     ename   mgr
	 1:  SCOTT JONES
	 2:   FORD JONES
	 3:  ALLEN BLAKE
	 4:   WARD BLAKE
	 5:  JAMES BLAKE
	 6: TURNER BLAKE
	 7: MARTIN BLAKE
	 8: MILLER CLARK
	 9:   JACK CLARK
	10:  ADAMS SCOTT
	11:  CLARK  KING
	12:  JONES  KING
	13:  BLAKE  KING
	14:  SMITH  FORD




문제 80. 위의 결과를 다시 출력하는데 관리자보다 더 많은 월급을 받는 사원들의 이름과 월급을 출력하시오 !

	x <- merge(emp, emp, by.x='mgr', by.y='empno')
	x[x$sal.x >= x$sal.y, c("ename.x", "sal.x")]
	
	  ename.x sal.x
	1   SCOTT  3000
	2    FORD  3000
	9    JACK  3200




문제 81. 위의 결과 데이터인 사원이름과 직속상사의 이름을 출력하는 데이터를 가지고 아래와 같이 시각화 하시오 !
	 (사원테이블의 조직도를 그리시오 !)

	install.packages("igraph")
	library(igraph)
	x <- merge(emp, emp, by.x='mgr', by.y='empno')
	a <- x[, c("ename.x", "ename.y")]
	b <- graph.data.frame(a,directed=F)
	plot(b)




문제 82. 위의 그래프를 구글의 googleVis를 이용해서 emp테이블의 관계도를 시각화 하시오 !

	install.packages("googleVis")
	library(googleVis)
	a <- merge(emp,emp, by.x="empno",by.y="mgr", all.y=T)
	org <- gvisOrgChart(a, idvar="ename.y",parentvar="ename.x",
	                    options=list(width=600, height=250, size='middle',allowCollapse=T))
	plot(org)





문제 83. 부서위치, 부서위치별 토탈월급을 출력하시오 !

	x <- merge(emp, dept, by="deptno")
	tapply(x$sal, x$loc, sum)

	  BOSTON  CHICAGO   DALLAS NEW YORK
	      NA     9400    10875     8750





문제 84. 위의 결과를 막대 그래프로 시각화 하시오 !

	x1[is.na(x1)] <- 0
	barplot(x1, col=rainbow(5))




문제 85. 이름과 월급과 부서위치를 출력하시오 !

	x <- merge(emp, dept, by='deptno')
	x[, c("ename", "sal", "loc")]
	
	    ename  sal      loc
	1    KING 5000 NEW YORK
	2  MILLER 1300 NEW YORK
	3   CLARK 2450 NEW YORK
	4   SMITH  800   DALLAS
	5   JONES 2975   DALLAS
	6    FORD 3000   DALLAS
	7   ADAMS 1100   DALLAS
	8   SCOTT 3000   DALLAS
	9   ALLEN 1600  CHICAGO
	10  BLAKE 2850  CHICAGO
	11 MARTIN 1250  CHICAGO
	12 TURNER 1500  CHICAGO
	13   WARD 1250  CHICAGO
	14  JAMES  950  CHICAGO





문제 86. 부서위치, 부서위치별 토탈월급을 출력하시오 !

	#세로
	# x <- merge(emp, dept, by='deptno', all.y=T)	# BOSTON을 출력하고 싶을 때
	# aggregate(sal~loc, x, sum, na.action=na.pass)	# BOSTON을 출력하고 싶을 때
	aggregate(sal~loc, x, sum)


	       loc   sal
	1  CHICAGO  9400
	2   DALLAS 10875
	3 NEW YORK  8750
	
	#가로
	x1 <- tapply(x$sal, x$loc, sum)
	x1
	
	  BOSTON  CHICAGO   DALLAS NEW YORK
	      NA     9400    10875     8750





문제 87. 위의 결과를 구글 막대 그래프로 그리시오 !

	x2 <- aggregate(sal~loc, x, sum, na.action=na.pass)
	x2
	x3 <- gvisBarChart(x2)
	plot(x3)






문제 88. 아래와 같이 결과를 출력하시오 !
	 (입사한 년도별 부서위치별 토탈월급을 출력하시오 !)

	x <- merge(emp, dept, by = "deptno")
	tapply(x$sal, list(x$loc, year(x$hiredate)), sum)
	
	         1980 1981 1982 1987
	BOSTON     NA   NA   NA   NA
	CHICAGO    NA 9400   NA   NA
	DALLAS    800 5975   NA 4100
	NEW YORK   NA 7450 1300   NA





문제 89. 위의 결과 데이터를 일반 막대 그래프로 그리시오 !

	x <- merge(emp, dept, by = "deptno")
	x1 <- tapply(x$sal, list(x$loc, year(x$hiredate)), sum)
	x1[is.na(x1)] <- 0
	barplot(x1, col=rainbow(4), beside=T, legend=rownames(x1))






문제 90. 지하철 1~4호선 승하차 승객수.csv를 R로 로드해서 line no 컬럼과 Time컬럼을 이용해서 구글
	 모션차트를 그리시오 !

	line <- read.csv("c:\\R\\1-4호선승하차승객수.csv")
	head(line)
	t1 <- gvisMotionChart(line, idvar="line_no", timevar="time")
	plot(t1)





문제 91. 지하철 5-8호선.csv파일을 내려받고 구글 모션 차트를 그리시오 !

	line58 <- read.csv("c:\\R\\서울지하철_5-8호선_이용현황_시간대별.csv")
	head(line58)
	t2 <- gvisMotionChart(line58, idvar="호선명", timevar="시간")





문제 91. 지하철 5-8호선.csv파일을 내려받고 구글 모션 차트를 그리시오 !

	line58 <- read.csv("c:\\R\\서울지하철_5-8호선_이용현황_시간대별.csv")
	head(line58)
	t2 <- gvisMotionChart(line58, idvar="호선명", timevar="시간")
	plot(t2)






문제92. 아래의 SQL의 결과를 R로 구현

	SQL> select ename, sal, deptno from emp
		where deptno in (10,20)
		union all
		select ename, sal, deptno from emp
		where deptno=10;

	rbind(emp[emp$deptno %in% c(10,20), c("ename", "sal", "deptno")],
	      emp[emp$deptno==10, c("ename","sal", "deptno")]
	      )

	     ename  sal deptno
	1    SMITH  800     20
	4    JONES 2975     20
	7    CLARK 2450     10
	8    SCOTT 3000     20
	9     KING 5000     10
	11   ADAMS 1100     20
	13    FORD 3000     20
	14  MILLER 1300     10
	71   CLARK 2450     10
	91    KING 5000     10
	141 MILLER 1300     10





문제 93. 부서번호, 부서번호별 토탈얼급을 아래와 같이 출력하는 SQL을 R로 구현하시오 !

	SQL> select deptno, sum(sal)
	        from emp
	        group by rollup(deptno);
	
	rbind(aggregate(sal~deptno, emp, sum), c( "토탈값 : ", sum(emp$sal)))
	
	     deptno   sal
	1        10  8750
	2        20 10875
	3        30  9400
	4        70  3200
	5 토탈값 :  32225





문제 94. 아래의 SQL의 결과를 R로 구현하시오 !

	SQL> select ename, sal, deptno
		from emp
		where deptno in (10,20)
	     union
	     select ename, sal, deptno
		from emp
		where deptno = 10;
	
	unique(rbind(emp[emp$deptno %in% c(10,20), c("ename", "sal", "deptno")],
	      emp[emp$deptno==10, c("ename","sal", "deptno")]))

	※ 설명 : union all과 union의 다른점은 union은 중복제거가 된다.

	    ename  sal deptno
	1   SMITH  800     20
	4   JONES 2975     20
	7   CLARK 2450     10
	8   SCOTT 3000     20
	9    KING 5000     10
	11  ADAMS 1100     20
	13   FORD 3000     20
	14 MILLER 1300     10




문제 95. 아래의 SQL의 결과를 R로 구현하시오 !

	SQL> select ename, sal, deptno
	        from emp
	        where deptno in (10, 20)
	     minus
	     select ename, sal, deptno
	        from emp
	        where deptno = 10;
	
	x <- setdiff(emp[emp$deptno %in% c(10, 20), "ename"], emp[emp$deptno == 10, "ename"])
	emp[emp$ename %in% x, c("ename", "sal", "deptno")]
	
	   ename  sal deptno
	1  SMITH  800     20
	4  JONES 2975     20
	8  SCOTT 3000     20
	11 ADAMS 1100     20
	13  FORD 3000     20





문제 96. 아래의 SQL의 결과를 R로 구현하시오 !

	SQL> select ename, sal, deptno
	        from emp
	        where deptno in (10, 20)
	     intersect
	     select ename, sal, deptno
	        from emp
	        where deptno = 10;
	
	x <- intersect(emp[emp$deptno %in% c(10, 20), "ename"], emp[emp$deptno == 10, "ename"])
	emp[emp$ename %in% x, c("ename", "sal", "deptno")]
	
	    ename  sal deptno
	7   CLARK 2450     10
	9    KING 5000     10
	14 MILLER 1300     10




문제 97. JONES의 월급보다 더 많은 월급을 받는 사원들의 이름과 월급을 출력하시오 !

	SQL> select ename, sal
	        from emp
	        where sal > (select sal from emp where ename = 'JONES');
	
	x <- emp[emp$ename =="JONES", c("sal")]
	x1 <- emp[emp$sal >= x, c("ename", "sal")]
	x1
	
	   ename  sal
	4  JONES 2975
	8  SCOTT 3000
	9   KING 5000
	13  FORD 3000
	15  JACK 3200





문제 98. 사원 테이블에서 가장 많은 월급을 받는 사원의 이름과 월급과 직업을 출력하시오 !

	x <- max(emp$sal)
	x1 <- emp[emp$sal >= x, c("ename", "sal")]
	x1
	
	  ename  sal
	9  KING 5000





문제 99. 전국에서 등록금이 가장 비싼 학교이름과 등록금을 출력하시오 !
	 (전국_대학별등록금통계_현황.csv)

	univ <- read.csv("전국_대학별등록금통계_현황.csv", header=T)
	head(univ)
	x <- max(univ$등록금.A.B.)
	univ[univ$등록금.A.B. >= x, c("학교명", "등록금.A.B.")]
	
	                  학교명 등록금.A.B.
	86 명지대학교 자연캠퍼스        9117





문제 100. KING에게 보고하는 사원들의 이름과 월급을 출력하시오 !

	SQL> select ename, sal
	        from emp
	        where mgr = (select empno from emp where ename = 'KING');
	
	king_empno <- emp[emp$ename =="KING", c("empno")]
	king_empno
	na.omit(emp[emp$mgr == king_empno, c("ename", "sal")])
	
	  ename  sal
	4 JONES 2975
	6 BLAKE 2850
	7 CLARK 2450





문제 101. 관리자인 사원들의 이름을 출력하시오 !

	emp[emp$empno %in% emp$mgr, c("ename")]
	
	[1] JONES BLAKE CLARK SCOTT KING  FORD




문제 102. 관리지가 아닌 사원들의 이름을 출력하시오 !

	SQL> select ename
	        from emp
	        where empno not in (select mgr from emp where mgr is not null);

	emp[!emp$empno %in% emp$mgr, c("ename")]
	
	[1] SMITH  ALLEN  WARD   MARTIN TURNER ADAMS  JAMES  MILLER JACK






문제 103. 작년에 아파트에서 가장 많이 발생한 범죄 유형이 무엇인지 출력하시오 !(crime_loc.csv 사용)

	head(crime_loc)
	x <- max(crime_loc[crime_loc$장소 == "아파트", c("건수")])
	crime_loc[crime_loc$건수 == x, c("범죄")]
	
	[1] 절도




문제 104. (점심시간 문제) 강력범죄가 가장 많이 발생하는 요일은 언제인가? (crime_day.csv를 로드받고 하세요)

	crime_day <- read.csv("crime_day.csv", header = T)
	head(crime_day)
	x <- max(crime_day[crime_day$C_C == "강력범죄 ", c("CNT")])
	crime_day[crime_day$CNT == x & crime_day$C_C == "강력범죄 ", c("DAY")]
	
	[1] SAT




문제 104. (점심시간 문제) 강력범죄가 가장 많이 발생하는 요일은 언제인가? (crime_day.csv를 로드받고 하세요)

	crime_day <- read.csv("crime_day.csv", header = T)
	head(crime_day)
	x <-crime_day[crime_day$C_C == "강력범죄 ",]
	x1 <- aggregate(CNT~DAY, x, sum)
	x1[x1$CNT == max(x1$CNT), c("DAY")]




문제 105. 이름, 월급, 월급에 대한 순위를 출력하시오 !

	data.table(emp$ename, emp$sal, rank(-emp$sal, ties.method="min"))

	※ min : 오라클의 rank와 같다.
	   first : 오라클의 rank와 같은데 순위가 같은 데이터가 있으면 인덱스 순서가 먼저 나온 데이터를
		   높은 순위로 부여한다.

	        V1   V2 V3
	 1:  SMITH  800 15
	 2:  ALLEN 1600  8
	 3:   WARD 1250 11
	 4:  JONES 2975  5
	 5: MARTIN 1250 11
	 6:  BLAKE 2850  6
	 7:  CLARK 2450  7
	 8:  SCOTT 3000  3
	 9:   KING 5000  1
	10: TURNER 1500  9
	11:  ADAMS 1100 13
	12:  JAMES  950 14
	13:   FORD 3000  3
	14: MILLER 1300 10
	15:   JACK 3200  2





문제 106. 위의 결과를 다시 출력하는데 순위를 1위부터 정렬해서 출력하시오 !

	x <- data.table(ename=emp$ename, sal=emp$sal, rank=rank(-emp$sal, ties.method="min"))
	orderBy( ~rank, x)
	
	     ename  sal rank
	 1:   KING 5000    1
	 2:   JACK 3200    2
	 3:  SCOTT 3000    3
	 4:   FORD 3000    3
	 5:  JONES 2975    5
	 6:  BLAKE 2850    6
	 7:  CLARK 2450    7
	 8:  ALLEN 1600    8
	 9: TURNER 1500    9
	10: MILLER 1300   10
	11:   WARD 1250   11
	12: MARTIN 1250   11
	13:  ADAMS 1100   13
	14:  JAMES  950   14
	15:  SMITH  800   15




문제 107. 여자들이 많이 걸리는 암과 건수와 순위를 출력하시오 !
	cancer <- read.csv("cancer.csv", header = T)
	head(cancer)
	cancer2 <- cancer[cancer$성별 == "여자" & cancer$암종 != "모든암", ]
	cancer2
	x <- data.table(암종=cancer2$암종, 환자수=cancer2$환자수, \
			  순위=rank(-cancer2$환자수,  ties.method="min"))
	orderBy(~순위, x)

	                암종 환자수 순위
	 1:           갑상선 217874    1
	 2:             유방 131581    2
	 3:             대장  69971    3
	 4:               위  69490    4
	 5:         자궁경부  43523    5
	 6:          기타 암  37312    6
	 7:               폐  19058    7
	 8:         자궁체부  15191    8
	 9:             난소  14171    9
	10:               간  12968   10
	11:   비호지킨림프종  12127   11
	12:             신장   8464   12
	13: 담낭 및 기타담도   7246   13
	14:           백혈병   6674   14
	15:       구강및인두   5523   15
	16:             방광   4743   16
	17: 뇌 및 중추신경계   4118   17
	18:             췌장   3229   18
	19:    다발성 골수종   1800   19
	20:             식도    730   20
	21:     호지킨림프종    725   21
	22:             후두    524   22
	23:           전립선     NA   23
	24:             고환     NA   24
	                암종 환자수 순위






문제 108. 2009년도에 서울시에서 교통사고가 일어난 장소와 건수와 순위를 출력하시오 !(car_accident.csv를 이용)
	car_accident <- read.csv("car_accident.csv", header = T)
	head(car_accident)
	car_accident2 <- car_accident[car_accident$loc == "서울" & car_accident$year2 == 2009, ]
	car_accident2
	x <- data.table(loc_desc=car_accident2$loc_desc, cnt=car_accident2$cnt, \
			  rank=rank(-car_accident2$cnt, ties.method = "min"))
	orderBy(~rank, x)

	                                                         loc_desc cnt rank
	   1:                                           박내과옆 먹자골목  66    1
	   2:                                                        서울  60    2
	   3:                                                역삼역교차로  56    3
	   4:                                              교보생명사거리  54    4
	   5:                                      남부순환도로 신림4거리  50    5
	  ---                                                                     
	3541:                                   GS칼텍스 앞 횡단보도 부근   2 2948
	3542:                                          지디리얼에스테이트   2 2948
	3543:                                 훼미리마트편의점앞 횡단보도   2 2948
	3544:                                  강동가톨릭병원 앞 횡단보도   2 2948
	3545: 한강시민공원 만남의 광장 자전거대여점 앞 한강시민공원 내 자   2 2948





문제 109. 샤이니 기본 화면을 실행하시오 !

	# Define UI ----
        ui <- fluidPage(
            
        )
        
        # Define server logic ----
        server <- function(input, output) {
            
        }
        
        # Run the app ----
        shinyApp(ui = ui, server = server)




문제110.  ui 에  아래의 내용을 추가하시오 !

	# Define UI ----
        ui <- fluidPage(
            titlePanel("title panel"),
            
            sidebarLayout(
                sidebarPanel("sidebar panel"),
                mainPanel("main panel")
            )
        )
        
        # Define server logic ----
        server <- function(input, output) {
            
        }
        
        # Run the app ----
        shinyApp(ui = ui, server = server)





문제111. sidebarLayout이 오른쪽에 나오게 하시오 !

	# Define UI ----
        ui <- fluidPage(
            titlePanel("title panel"),
            
            sidebarLayout(position = "right",
                          sidebarPanel("sidebar panel"),
                          mainPanel("main panel")
            )
        )
        
        # Define server logic ----
        server <- function(input, output) {
            
        }
        
        # Run the app ----
        shinyApp(ui = ui, server = server)





문제112. 사용자 인터페이스의 글씨를  아래와 같이 출력하시오 !

	# Define UI ----
        ui <- fluidPage(
            titlePanel("My Shiny App"),
            sidebarLayout(
                sidebarPanel(),
                mainPanel(
                    h1("First level title"),
                    h2("Second level title"),
                    h3("Third level title"),
                    h4("Fourth level title"),
                    h5("Fifth level title"),
                    h6("Sixth level title")
                )
            )
        )
        
        # Define server logic ----
        server <- function(input, output) {
            
        }
        
        # Run the app ----
        shinyApp(ui = ui, server = server)





문제113.  아래의 필요한 전체 기능을 출력하시오 !

	# Define UI ----
        ui <- fluidPage(
            titlePanel("Basic widgets"),
            
            fluidRow(
                
                column(3,
                       h3("Buttons"),
                       actionButton("action", "Action"),
                       br(),
                       br(),
                       submitButton("Submit")),
                
                column(3,
                       h3("Single checkbox"),
                       checkboxInput("checkbox", "Choice A", value = TRUE)),
                
                column(3,
                       checkboxGroupInput("checkGroup",
                                          h3("Checkbox group"),
                                          choices = list("Choice 1" = 1,
                                                         "Choice 2" = 2,
                                                         "Choice 3" = 3),
                                          selected = 1)),
                
                column(3,
                       dateInput("date",
                                 h3("Date input"),
                                 value = "2014-01-01"))   
            ),
            
            fluidRow(
                
                column(3,
                       dateRangeInput("dates", h3("Date range"))),
                
                column(3,
                       fileInput("file", h3("File input"))),
                
                column(3,
                       h3("Help text"),
                       helpText("Note: help text isn't a true widget,",
                                "but it provides an easy way to add text to",
                                "accompany other widgets.")),
                
                column(3,
                       numericInput("num",
                                    h3("Numeric input"),
                                    value = 1))   
            ),
            
            fluidRow(
                
                column(3,
                       radioButtons("radio", h3("Radio buttons"),
                                    choices = list("Choice 1" = 1, "Choice 2" = 2,
                                                   "Choice 3" = 3),selected = 1)),
                
                column(3,
                       selectInput("select", h3("Select box"),
                                   choices = list("Choice 1" = 1, "Choice 2" = 2,
                                                  "Choice 3" = 3), selected = 1)),
                
                column(3,
                       sliderInput("slider1", h3("Sliders"),
                                   min = 0, max = 100, value = 50),
                       sliderInput("slider2", "",
                                   min = 0, max = 100, value = c(25, 75))
                ),
                
                column(3,
                       textInput("text", h3("Text input"),
                                 value = "Enter text..."))   
            )
            
        )
        
        # Define server logic ----
        server <- function(input, output) {
            
        }
        
        # Run the app ----
        shinyApp(ui = ui, server = server)




문제 114. emp테이블의 월급으로 기본적인 막대그래프를 그리시오 !

	barplot(emp$sal)





문제 115. 위의 그래프의 제목을 Salary Bar Chart라고 이름을 붙이시오 !

	barplot(emp$sal, main = "Salary Bar Chart")





문제 116. 막대 그래프의 x축에 사원이름을 붙이시오 !

	barplot(emp$sal, main = "Salary Bar Chart", names.arg = emp$ename, ylab = "Salary")





문제 117. 막대그래프의 색깔을 입히시오 !

	barplot(emp$sal, main = "Salary Bar Chart", names.arg = emp$ename, \
	        ylab = "Salary", col=('blue'))





문제 118. 아래와 같이 치킨집 년도별 창업 건수를 막대 그래프로 시각화 하시오 !

	x <- read.csv("창업건수.csv", header = T)
	head(x)
	barplot(x$치킨집, main = "치킨집 창업 건수", names.arg = x$X,
	        ylab = "건수", col = ("green"))






문제 119. 치킨집 년도별 창업건수, 폐업건수를 아래와 같이 같이 막대그래프로 시각화 하시오 !

	x <- read.csv("창업건수.csv", header = T)
	head(x)
	y <- read.csv("폐업건수.csv", header = T)
	head(y)
	z <- rbind(x$치킨집, y$치킨집)
	z
	barplot(z, main = "년도별 치킨집 창업, 폐업 건수", names.arg = x$X,
	        ylab = "건수", ylim = c(0, 3600), col = c("blue", "green"), beside=T,
	        legend=c("창업", "폐업"))





문제 120. 카페(커피음료)가 얼마나 창업하고 얼마나 폐업하는지 막대그래프로 시각화 하시오 !

	x <- read.csv("창업건수.csv", header = T)
	head(x)
	y <- read.csv("폐업건수.csv", header = T)
	head(y)
	z <- rbind(x$커피음료, y$커피음료)
	z
	barplot(z, main = "년도별 카페 창업, 폐업 건수", names.arg = x$X,
	        ylab = "건수", ylim = c(0, 3600), col = c("blue", "green"), beside=T,
	        legend=c("창업", "폐업"))





문제 121. R shiny로 막대그래프 시각화를 자동화 시키는 기본 코드를 돌려보시오 !


	library(shiny)
	library(datasets)
	
	setwd("c:/R")
	x <- read.csv("창업건수.csv", header = T)
	y <- read.csv("폐업건수.csv", header = T)
	
	# Define UI ----
	ui <- fluidPage(    
	    
	    # Give the page a title
	    titlePanel("년도별 업종별 창업 현황"),
	    
	    # Generate a row with a sidebar
	    sidebarLayout(      
	        
	        # Define the sidebar with one input
	        sidebarPanel(
	            selectInput("region", "업종:",
	                        choices=colnames(x)[-1]),
	            hr(),
	            helpText("업종을 선택하세요!")
	        ),
	        
	        # Create a spot for the barplot
	        mainPanel(
	            plotOutput("phonePlot")  
	        )
	        
	    )
	)
	
	# Define server logic ----
	server <-function(input, output) {
	    
	    # Fill in the spot we created for a plot
	    output$phonePlot <- renderPlot({
	        
	        # Render a barplot
	        barplot(x[, input$region], main = "창업 건수", names.arg = x$X,
	                ylab = "건수", ylim = c(0, max(x[, input$region])+100), col = ("green"))
	    })
	}
	
	# Run the app ----
	shinyApp(ui = ui, server = server)









문제 123. 샤이니로 아래와 같이 창업과 폐업을 같이 출력되게 하는 자동화 화면을 구현하시오 !

	library(shiny)
        library(datasets)
        
        setwd("c:/R")
        x <- read.csv("창업건수.csv", header = T)
        y <- read.csv("폐업건수.csv", header = T)
        
        # Define UI ----
        ui <- fluidPage(    
            
            # Give the page a title
            titlePanel("년도별 업종별 창업 현황"),
            
            # Generate a row with a sidebar
            sidebarLayout(      
                
                # Define the sidebar with one input
                sidebarPanel(
                    selectInput("region", "업종:",
                                choices=colnames(x)[-1]),
                    hr(),
                    helpText("업종을 선택하세요!")
                ),
                
                # Create a spot for the barplot
                mainPanel(
                    plotOutput("phonePlot")  
                )
                
            )
        )
        
        # Define server logic ----
        server <-function(input, output) {
            # Fill in the spot we created for a plot
            output$phonePlot <- renderPlot({
                
                # Render a barplot
                barplot(rbind(x[, input$region], y[, input$region]),
                        main = "년도별 카페 창업, 폐업 건수",
                        names.arg = x$X,
                        ylab = "건수",
                        ylim = c(0, max(x[, input$region], y[, input$region])+100),
                        col = c("blue", "green"),
                        beside=T,
                        legend=c("창업", "폐업"))
            })
        }
        
        # Run the app ----
        shinyApp(ui = ui, server = server)





문제 124. 사원 테이블의 월급을 원형 그래프로 그리시오 !

	pie(emp$sal)





문제 125. 위의 그래프를 다시 출력하는데 누구의 월급인지 명시되게 하시오 !

	pie( emp$sal, main = "Salary Pie Chart",
	     labels= emp$ename, col = rainbow(15))






문제 126. 위의 그래프에 월급에 비율을 붙여서 출력하시오 !

	sal_labels <- round(emp$sal/sum(emp$sal) * 100, 1)
	sal_labels
	
	[1]  2.5  5.0  3.9  9.2  3.9  8.8  7.6  9.3 15.5  4.7  3.4  2.9  9.3  4.0  9.9
	
	sal_labels2 <- paste(emp$ename, sal_labels, "%")
	sal_labels2
	
	[1] "SMITH 2.5 %"  "ALLEN 5 %"    "WARD 3.9 %"   "JONES 9.2 %"  "MARTIN 3.9 %" "BLAKE 8.8 %"  
	    "CLARK 7.6 %"  "SCOTT 9.3 %"  "KING 15.5 %"
	[10] "TURNER 4.7 %" "ADAMS 3.4 %"  "JAMES 2.9 %"  "FORD 9.3 %"   "MILLER 4 %"   "JACK 9.9 %"


	pie(emp$sal, main = "Salary Pie Chart",
	    labels=sal_labels2, col=rainbow(15))







문제 127. 2014년도 업종별 창업 비율을 아래와 같이 원형 그래프로 그리시오 !

	create_cnt <- read.csv("창업건수.csv", header=T)
	head(create_cnt)
	
	x <- create_cnt[create_cnt$X == 2014, (2:8)] 또는
	x <- create_cnt[create_cnt$X == 2014, -1]
	
	cnt_labels <- round(x/sum(x) * 100, 1)
	cnt_labels
	t(cnt_labels)
	
	cnt_labels2 <- paste(colnames(cnt_labels), t(cnt_labels), '%')
	pie(t(cnt_labels), col=rainbow(7), labels=cnt_labels2)






문제 128. 2013년도 업종별 창업 비율을 아래와 같이 원형 그래프로 그리시오 !

	x <- create_cnt[create_cnt$X == 2013, (2:8)] 또는
	x <- create_cnt[create_cnt$X == 2013, -1]
	
	cnt_labels <- round(x/sum(x) * 100, 1)
	cnt_labels
	t(cnt_labels)
	
	cnt_labels2 <- paste(colnames(cnt_labels), t(cnt_labels), '%')
	pie(t(cnt_labels), col=rainbow(7), labels=cnt_labels2)






문제 129. 위의 스크립트를 편하게 사용할 수 있도록 샤이니로 구현하시오 !

	library(shiny)
        library(datasets)
        
        setwd("d:\\R_data")
        create_cnt <- read.csv("창업건수.csv", header=T)
        
        # 합친 상태로 함수에 넣을 수 없다.
        
        # Define UI ----
        ui <- fluidPage(    
            
            # Give the page a title
            titlePanel("년도별 업종별 창업 현황"),
            
            # Generate a row with a sidebar
            sidebarLayout(      
                
                # Define the sidebar with one input
                sidebarPanel(
                    selectInput("region", "업종:",
                                choices=create_cnt$X),
                    hr(),
                    helpText("Data from AT&T (1961) The World's Telephones.")
                ),
                
                # Create a spot for the barplot
                mainPanel(
                    plotOutput("phonePlot")  
                )
                
            )
        )
        
        # Define server logic ----
        server <-function(input, output) {
            
            # Fill in the spot we created for a plot
            output$phonePlot <- renderPlot({
                
                # Render a barplot
                x <- create_cnt[create_cnt$X == input$region, -1]
                
                cnt_labels <- round(x/sum(x) * 100, 1)
                cnt_labels2 <- paste(colnames(cnt_labels), t(cnt_labels), '%')
                pie(t(cnt_labels), col=rainbow(7), labels=cnt_labels2)
            })
        }
        
        # Run the app ----
        shinyApp(ui = ui, server = server)





문제 130. 아래의 점(plot) 그래프를 그리시오 !

	graphics.off()
	
	cars <- c(1,3,6,4,9)
	cars
	
	plot(cars)






문제 131. 위의 그래프에 파란색 선을 그리시오 !

	graphics.off()
	
	cars <- c(1,3,6,4,9)
	cars
	
	plot(cars, type="o", col="blue")






문제 132. 차와 트럭의 판매된 대수를 라인 그래프로 시각화 하시오 !

	graphics.off()
	
	cars <- c(1,3,6,4,9)
	trucks <- c(2,5,4,5,12)
	
	plot(cars, type="o", col="blue", ylim =c(0,12))
	
	# 그래프 창을 닫지 말고 바로 이어서
	
	lines(trucks, type="o", pch = 22, lty = 2, col = "red")
	
		※ 설명 : pch = 21 : 동그라미,  lty=1 : 직선
			  pch = 22 : 네모	lty=2 : 점선







문제 133. 다시 위의 2개의 그래프를 아래의 순서대로 시각화 하시오 !

	graphics.off()
	
	cars <- c(1,3,6,4,9)
	trucks <- c(2,5,4,5,12)
	
	g_range <- range(0, cars, trucks)
	g_range
	
	[1] 0 12
	
	plot( cars, type="o", col="blue", ylim = g_range,
	      axes=FALSE, ann=FALSE)
	axis(1, at=1:5, lab=c("mon","tue","wed","thu","fri"))
	
	axis(2)
	box()
	
	lines(trucks, type="o", pch = 22, lty = 2, col = "red" )
	
	legend(1,12, c("cars","trucks"), col = c("blue","red"),
	       cex=0.8, pch = 21:22, lty= 1:2)
	
		※ 설명 : cex = 0.8 : 글씨 크기








문제134. 위의 코드를 활용해서 치킨집의 창업/폐업 현황을 라인 그래프로 시각화 하시오 !

	g <- create_cnt$치킨집
	m <- drop_cnt$치킨집
	g_range <- range(0, g, m)
	plot(g, type="o", col="blue", ylim=g_range,
	     axes=FALSE, ann=FALSE)
	axis(1, at=1:10, lab=create_cnt$X)
	axis(2)
	box()
	lines(m, type="o", pch=22, lty=2, col="red")
	title(main="치킨집 창업/폐업현황", col.main="red", font.main=4)
	title(xlab="Days", col.lab=rgb(0,0.5,0))
	title(ylab="Total", col.lab=rgb(0,0.5,0))
	legend(5, g_range[2], c("창업","폐업"), cex=0.8,
	       col=c("blue","red"), pch=21:22, lty=1:2);







문제 135. 위의 업종별 창업/폐업 현황을 샤이니로 자동화 하시오 !


	library(shiny)
        library(datasets)
        
        setwd("d:\\data")
        create_cnt <- read.csv("창업건수.csv", header=T)
        drop_cnt <- read.csv("폐업건수.csv", header=T)
        
        # Define UI ----
        ui <- fluidPage(    
            
            # Give the page a title
            titlePanel("업종별 창업/폐업 현황"),
            
            # Generate a row with a sidebar
            sidebarLayout(      
                
                # Define the sidebar with one input
                sidebarPanel(
                    selectInput("region", "업종:",
                                choices=colnames(create_cnt)[-1]),
                    hr(),
                    helpText("Data from AT&T (1961) The World's Telephones.")
                ),
                
                # Create a spot for the barplot
                mainPanel(
                    plotOutput("phonePlot")  
                )
                
            )
        )
        
        # Define server logic ----
        server <-function(input, output) {
            
            # Fill in the spot we created for a plot
            output$phonePlot <- renderPlot({
                
                # Render a line graph
                
                
                g <- create_cnt[,input$region]
                m <- drop_cnt[,input$region]
                g_range <- range(0, g, m)
                plot(g, type="o", col="blue", ylim=g_range,
                     axes=FALSE, ann=FALSE)
                axis(1, at=1:10, lab=create_cnt$X)
                axis(2)
                box()
                lines(m, type="o", pch=22, lty=2, col="red")
                title(main= input$region, col.main="red", font.main=4)
                title(xlab="Days", col.lab=rgb(0,0.5,0))
                title(ylab="Total", col.lab=rgb(0,0.5,0))
                legend(5, g_range[2], c("창업","폐업"), cex=0.8,
                       col=c("blue","red"), pch=21:22, lty=1:2);
                
                
            })
        }
        
        # Run the app ----
        shinyApp(ui = ui, server = server)





문제 136. csv 파일을 불러와서 x 축과 y 축을 정해서 위의 ggplot 막대 그래프를 그리는 샤이니
	  코드를 작성하시오 !

#lesson_17 참고
############## set this file location to working directory ##########################
packages <- 'rstudioapi'
if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
  install.packages(setdiff(packages, rownames(installed.packages())))
}
library('rstudioapi')
current_dir<-dirname(rstudioapi::getSourceEditorContext()$path)
setwd(current_dir)

package_in<-function(p_name,option=1){
  packages <- p_name
  if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
    install.packages(setdiff(packages, rownames(installed.packages())))
  }
  if (option==1){
    library(p_name,character.only = TRUE)
  }
}

###########################1. 패키지 설치##########################################

package_in('shinydashboard')
package_in('shiny')
package_in('ggplot2')


######################### 2. 화면 개발 ###########################################

sidebar <- dashboardSidebar(
  sidebarMenu(
    fileInput("file1", "Choose CSV File",
              multiple = FALSE,
              accept = c("text/csv",".xlsx",".txt",
                         "text/comma-separated-values,text/plain",
                         ".csv")),
    
    menuItem("Barplot",
             menuSubItem('normal',tabName='barplot')
    )
    
    
  )
)


body <- dashboardBody(
  
  tabItems(
    
    ##### bar plot
    tabItem(tabName = "barplot",
            sidebarPanel(
              selectInput("in_sel_bar_xVar","x Variable:", choices = NULL),
              selectInput("in_sel_bar_yVar","y Variable:", choices = NULL)
            ),
            mainPanel(
              plotOutput('plot_bar')
            )
    )
  )
)



ui<-dashboardPage(
  dashboardHeader(title='my graph'),
  sidebar,
  body
  
)




######################3. 서버단 개발 ########################################


server <- function(input, output,session) {
  options(warn = -1)
  options(shiny.maxRequestSize = 30*1024^2)
  
  
  
  
  dataload<-reactive({
    
    req(input$file1)
    
    file1 = input$file1
    data1 = read.csv(file1$datapath)
    
    updateSelectInput(session, "in_sel_bar_xVar", choices = colnames(data1))
    updateSelectInput(session, "in_sel_bar_yVar", choices = colnames(data1))
    
    return(data1)
  })
  
  ####nomal_bar
  output$plot_bar <- renderPlot({
    table_in<-dataload()
    
    xdata<-as.factor(table_in[,input$in_sel_bar_xVar])
    ydata<-as.factor(table_in[,input$in_sel_bar_yVar])
    fdata=data.frame(x=xdata,y=ydata)
    
    
    ggplot(fdata) +
      geom_bar(aes_string(x='x',y='y',fill='x'),stat = "identity",show.legend=F)
    
  })
}

######################### 4. 샤이니 실행 ###############################

shinyApp(ui = ui, server = server)






문제 137. (점심시간 문제) 문제 136 번은 ggplot 으로 막대 그래프를 그리는 코드였는데 이번에는 plotly 로
	  원형 그래프가 출력되는 샤이니 코드를 작성하시오 !

	  년도 선택하는 select input box 하나만 나오게

	library(shiny)
        library(datasets)
        
        opn <- read.csv('창업건수.csv',header=T)
        cls <- read.csv('폐업건수.csv',header=T)
        
        # Define UI ----
        ui <- fluidPage(    
            
            # Give the page a title
            titlePanel("Opened Store By Year"),
            
            # Generate a row with a sidebar
            sidebarLayout(      
                
                # Define the sidebar with one input
                sidebarPanel(
                    selectInput("year", "Year:",
                                choices=opn$X),
                    hr(),
                    helpText("Data from Oracle Yu.")
                ),
                
                # Create a spot for the barplot
                mainPanel(
                    plotlyOutput("storePlot")  
                )
                
            )
        )
        
        # Define server logic ----
        server <-function(input, output) {
            
            # Fill in the spot we created for a plot
            output$storePlot <- renderPlotly({
                
                plot_ly(opn, labels=~colnames(opn)[-1],
                        values=~as.factor(opn[opn$X == input$year,-1]),type='pie')
                
            })
        }
        
        # Run the app ----
        shinyApp(ui = ui, server = server)





문제 138. 원더걸스의 so hot 을 시각화 하시오 !

	audio1 <- readWave("sohot.wav")
	
	play(audio1)
	
	head(audio1@left, 1000)
	
	plot(head(audio1@left, 1000))






문제 139. 정상적인 심장박동 소리를 포함해서 비정상적인 심장 박동 소리를 각각 시각화 하시오 !

	normal.wav <- 정상 심장 박동 소리
	
	문제가 있는 심장박동 소리들
	
	ar.wav
	mr.wav
	ps.wav


graphics.off()
par(mfrow=c(2,2))
par(mar=c(1,1,1,1))

audio1 <- readWave("normal.wav")
audio2 <- readWave("ps.wav")
audio3 <- readWave("mr.wav")
audio4 <- readWave("ar.wav")

plot(audio1)
plot(audio2)
plot(audio3)
plot(audio4)






문제 140. 치킨집의 년도별 창업 현황을 plotly의 라인그래프로 그리시오 !

	library(plotly)
	plot_ly(data = create_cnt, x = ~create_cnt[ ,"X"], y = ~create_cnt[ , "치킨집"],
	        type = "scatter", mode = "dot")







문제 141. 샤이니의 사이드 메뉴에 linechart를 추가하고 linechart를 클릭하면 업종을 물어보게 해서 해당
	  업종의 년도별 창업 현황이 출력되게 하시오 !

	############## set this file location to working directory ##########################
        packages <- 'rstudioapi'
        if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
            install.packages(setdiff(packages, rownames(installed.packages())))
        }
        library('rstudioapi')
        current_dir<-dirname(rstudioapi::getSourceEditorContext()$path)
        setwd(current_dir)
        
        package_in<-function(p_name,option=1){
            packages <- p_name
            if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
                install.packages(setdiff(packages, rownames(installed.packages())))
            }
            if (option==1){
                library(p_name,character.only = TRUE)
            }
        }
        
        ###########################1. 패키지 설치##########################################
        
        package_in('shinydashboard')
        package_in('shiny')
        package_in('ggplot2')
        package_in('plotly')
        
        ######################### 2. 화면 개발 ###########################################
        
        sidebar <- dashboardSidebar(
            sidebarMenu(
                fileInput("file1", "Choose CSV File",
                          multiple = FALSE,
                          accept = c("text/csv",".xlsx",".txt",
                                     "text/comma-separated-values,text/plain",
                                     ".csv")),
                
                menuItem("Plot",
                         menuSubItem('Barplot',tabName='barplot'),
                         menuSubItem('Piechart',tabName='piechart'),
                         menuSubItem('linechart',tabName='linechart')
                )
                
                
            )
        )
        
        
        body <- dashboardBody(
            
            tabItems(
                
                ##### bar plot
                tabItem(tabName = "barplot",
                        sidebarPanel(
                            selectInput("in_sel_bar_xVar","x Variable:", choices = NULL),
                            selectInput("in_sel_bar_yVar","y Variable:", choices = NULL)
                        ),
                        mainPanel(
                            plotOutput('plot_bar')
                        )
                ),
                ##### piechart
                tabItem(tabName = "piechart",
                        sidebarPanel(
                            selectInput("in_sel_pie_xVar","x Variable:", choices = NULL)
                        ),
                        mainPanel(
                            plotlyOutput('plot_pie')
                        )
                ),
                ##### linechart
                tabItem(tabName = "linechart",
                        sidebarPanel(
                            selectInput("in_sel_line_xVar","x Variable:", choices = NULL),
                            selectInput("in_sel_line_yVar","y Variable:", choices = NULL)
                        ),
                        mainPanel(
                            plotlyOutput('plot_line')
                        )
                )
            )
        )
        
        
        
        ui<-dashboardPage(
            dashboardHeader(title='my graph'),
            sidebar,
            body
            
        )
        
        
        
        
        ######################3. 서버단 개발 ########################################
        
        
        server <- function(input, output,session) {
            options(warn = -1)
            options(shiny.maxRequestSize = 30*1024^2)
            
            
            
            
            dataload<-reactive({
                req(input$file1)
                
                file1 = input$file1
                data1 = read.csv(file1$datapath)
                
                
                updateSelectInput(session, "in_sel_bar_xVar", choices = colnames(data1))
                updateSelectInput(session, "in_sel_bar_yVar", choices = colnames(data1))
                
                updateSelectInput(session, "in_sel_pie_xVar", choices = data1[,1])
                
                updateSelectInput(session, "in_sel_line_xVar", choices = colnames(data1))
                updateSelectInput(session, "in_sel_line_yVar", choices = colnames(data1))
                return(data1)
                
            })
            
            ####nomal_bar
            output$plot_bar <- renderPlot({
                table_in<-dataload()
                
                xdata<-as.factor(table_in[,input$in_sel_bar_xVar])
                ydata<-as.factor(table_in[,input$in_sel_bar_yVar])
                fdata=data.frame(x=xdata,y=ydata)
                
                
                ggplot(fdata) +
                    geom_bar(aes_string(x='x',y='y',fill='x'),stat = "identity",show.legend=F)
                
                
            })
            ####nomal_pie
            output$plot_pie <- renderPlotly({
                table_in<-dataload()
                
                plot_ly(table_in, labels = ~colnames(table_in)[-1],
			values=~as.factor( table_in[table_in[,1] == input$in_sel_pie_xVar,-1] ),
			type='pie')
                
                
            })
            ####nomal_line
            output$plot_line <- renderPlotly({
                table_in<-dataload()
                
                x <- list(title = input$in_sel_line_xVar)
                y <- list(title = input$in_sel_line_yVar)
        
                plot_ly(data = table_in,
                        x = ~table_in[,input$in_sel_line_xVar],  
		        y = ~table_in[, input$in_sel_line_yVar],type='scatter',mode='dot')%>%
                    layout(xaxis = x, yaxis = y)
            })
        }
        
        ######################### 4. 샤이니 실행 ###############################
        
        shinyApp(ui = ui, server = server)






문제 142. plotly 패키지를 이용해서 나이와 소득의 산포도 그래프를 그리시오 !

	plotly(age_income)
	plot_ly(data = age_income, x = ~age_income[ ,"age"], y = ~age_income[ , "month_income"],
	       	type = "scatter", mode = "markers", color = I("#FA58AC"))






문제 143. 샤이니의 사이드 메뉴 아래쪽에 Plotchart를 추가해서 X축과 y 축을 입력받아 산포도 그래프가
	  출력되게 하시오 !
          (그래프 아래쪽에 상관계수도 같이 출력되게 하시오 !)
        
        ############## set this file location to working directory ##########################
        packages <- 'rstudioapi'
        if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
            install.packages(setdiff(packages, rownames(installed.packages())))
        }
        library('rstudioapi')
        current_dir<-dirname(rstudioapi::getSourceEditorContext()$path)
        setwd(current_dir)
        
        package_in<-function(p_name,option=1){
            packages <- p_name
            if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
                install.packages(setdiff(packages, rownames(installed.packages())))
            }
            if (option==1){
                library(p_name,character.only = TRUE)
            }
        }
        
        ###########################1. 패키지 설치##########################################
        
        package_in('shinydashboard')
        package_in('shiny')
        package_in('ggplot2')
        package_in('plotly')
        package_in('lattice')
        
        ######################### 2. 화면 개발 ###########################################
        
        sidebar <- dashboardSidebar(
            sidebarMenu(
                fileInput("file1", "Choose CSV File",
                          multiple = FALSE,
                          accept = c("text/csv",".xlsx",".txt",
                                     "text/comma-separated-values,text/plain",
                                     ".csv")),
                
                menuItem("Plot",
                         menuSubItem('Barplot',tabName='barplot'),
                         menuSubItem('Piechart',tabName='piechart'),
                         menuSubItem('linechart',tabName='linechart'),
                         menuSubItem('markerchart',tabName='markerchart')
                )
                
                
            )
        )
        
        
        body <- dashboardBody(
            
            tabItems(
                
                ##### bar plot
                tabItem(tabName = "barplot",
                        sidebarPanel(
                            selectInput("in_sel_bar_xVar","x Variable:", choices = NULL),
                            selectInput("in_sel_bar_yVar","y Variable:", choices = NULL)
                        ),
                        mainPanel(
                            plotOutput('plot_bar')
                        )
                ),
                ##### piechart
                tabItem(tabName = "piechart",
                        sidebarPanel(
                            selectInput("in_sel_pie_xVar","x Variable:", choices = NULL)
                        ),
                        mainPanel(
                            plotlyOutput('plot_pie')
                        )
                ),
                ##### linechart
                tabItem(tabName = "linechart",
                        sidebarPanel(
                            selectInput("in_sel_line_xVar","x Variable:", choices = NULL),
                            selectInput("in_sel_line_yVar","y Variable:", choices = NULL)
                        ),
                        mainPanel(
                            plotlyOutput('plot_line')
                        )
                ),
                ##### markerchart
                tabItem(tabName = "markerchart",
                        sidebarPanel(
                            selectInput("in_sel_marker_xVar","x Variable:", choices = NULL),
                            selectInput("in_sel_marker_yVar","y Variable:", choices = NULL)
                        ),
                        mainPanel(
                            plotOutput('plot_marker'),
                            textOutput('text_scatter')
                        )
                )
            )
        )
        
        
        
        ui<-dashboardPage(
            dashboardHeader(title='my graph'),
            sidebar,
            body
            
        )
        
        
        
        
        ######################3. 서버단 개발 ########################################
        
        
        server <- function(input, output,session) {
            options(warn = -1)
            options(shiny.maxRequestSize = 30*1024^2)
            
            
            
            
            dataload<-reactive({
                req(input$file1)
                
                file1 = input$file1
                data1 = read.csv(file1$datapath)
                
                
                updateSelectInput(session, "in_sel_bar_xVar", choices = colnames(data1))
                updateSelectInput(session, "in_sel_bar_yVar", choices = colnames(data1))
                
                updateSelectInput(session, "in_sel_pie_xVar", choices = data1[,1])
                
                updateSelectInput(session, "in_sel_line_xVar", choices = colnames(data1))
                updateSelectInput(session, "in_sel_line_yVar", choices = colnames(data1))
                
                updateSelectInput(session, "in_sel_marker_xVar", choices = colnames(data1))
                updateSelectInput(session, "in_sel_marker_yVar", choices = colnames(data1))
                return(data1)
                
            })
            
            ####nomal_bar
            output$plot_bar <- renderPlot({
                table_in<-dataload()
                
                xdata<-as.factor(table_in[,input$in_sel_bar_xVar])
                ydata<-as.factor(table_in[,input$in_sel_bar_yVar])
                fdata=data.frame(x=xdata,y=ydata)
                
                
                ggplot(fdata) +
                    geom_bar(aes_string(x='x',y='y',fill='x'),stat = "identity",show.legend=F)
                
                
            })
            ####nomal_pie
            output$plot_pie <- renderPlotly({
                table_in<-dataload()
                
                plot_ly(table_in, labels = ~colnames(table_in)[-1],
		        values=~as.factor( table_in[table_in[,1] == input$in_sel_pie_xVar,-1] ),
			type='pie')
                
                
            })
            
            ####nomal_line
            output$plot_line <- renderPlotly({
                table_in<-dataload()
                
                x <- list(title = input$in_sel_line_xVar)
                y <- list(title = input$in_sel_line_yVar)
                
                plot_ly(data = table_in,
                        x = ~table_in[,input$in_sel_line_xVar],  
			y = ~table_in[, input$in_sel_line_yVar],type='scatter',mode='dot')%>%
                    layout(xaxis = x, yaxis = y)
            })
            
            ####nomal_marker
            output$plot_marker <- renderPlot({
                table_in<-dataload()
        
                xyplot(table_in[,input$in_sel_marker_yVar]~table_in[,input$in_sel_marker_xVar],
                       grid=T,type=c('p','smooth'),col.line='darkorange',lwd=2,
                       xlab=input$in_sel_marker_xVar,ylab=input$in_sel_marker_yVar)
            })
            output$text_scatter <- renderText({
                table_in<-dataload()
                paste("The correlation between the two is: ", cor(table_in[,input$in_sel_marker_yVar],
                                                                  table_in[,input$in_sel_marker_xVar]))
            })
            
        }
        
        ######################### 4. 샤이니 실행 ###############################
        
        shinyApp(ui = ui, server = server)




문제 144. 우리반 나이 데이터를 가지고 사분위수 그래프를 그리시오 !

	emp8 <- read.csv("emp8.csv", header = T)
	bwplot(emp8$age)






문제 145. 우리 기존의 완성한 샤이니 코드에 csv파일을
        
        
        emp <- read.csv("c:\\R\\emp.csv",header=T)
        
        ############## set this file location to working directory ##########################
        packages <- 'rstudioapi'
        if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
            install.packages(setdiff(packages, rownames(installed.packages())))
        }
        library('rstudioapi')
        current_dir<-dirname(rstudioapi::getSourceEditorContext()$path)
        setwd(current_dir)
        
        package_in<-function(p_name,option=1){
            packages <- p_name
            if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
                install.packages(setdiff(packages, rownames(installed.packages())))
            }
            if (option==1){
                library(p_name,character.only = TRUE)
            }
        }
        
        ###########################1. 패키지 설치##########################################
        
        package_in('shinydashboard')
        package_in('shiny')
        package_in('ggplot2')
        package_in('plotly')
        package_in('lattice')
        
        ######################### 2. 화면 개발 ###########################################
        
        sidebar <- dashboardSidebar(
            sidebarMenu(
                fileInput("file1", "Choose CSV File",
                          multiple = FALSE,
                          accept = c("text/csv",".xlsx",".txt",
                                     "text/comma-separated-values,text/plain",
                                     ".csv")),
                
                menuItem("Plot",
                         menuSubItem('Barplot',tabName='barplot'),
                         menuSubItem('Piechart',tabName='piechart'),
                         menuSubItem('linechart',tabName='linechart'),
                         menuSubItem('markerchart',tabName='markerchart')
                ),
                menuItem("Data_table",
                         menuSubItem('table_format',tabName='table_format')
        
                )
                
                
            )
        )
        
        
        body <- dashboardBody(
            
            tabItems(
                
                ##### bar plot
                tabItem(tabName = "barplot",
                        sidebarPanel(
                            selectInput("in_sel_bar_xVar","x Variable:", choices = NULL),
                            selectInput("in_sel_bar_yVar","y Variable:", choices = NULL)
                        ),
                        mainPanel(
                            plotOutput('plot_bar')
                        )
                ),
                ##### piechart
                tabItem(tabName = "piechart",
                        sidebarPanel(
                            selectInput("in_sel_pie_xVar","x Variable:", choices = NULL)
                        ),
                        mainPanel(
                            plotlyOutput('plot_pie')
                        )
                ),
                ##### linechart
                tabItem(tabName = "linechart",
                        sidebarPanel(
                            selectInput("in_sel_line_xVar","x Variable:", choices = NULL),
                            selectInput("in_sel_line_yVar","y Variable:", choices = NULL)
                        ),
                        mainPanel(
                            plotlyOutput('plot_line')
                        )
                ),
                ##### markerchart
                tabItem(tabName = "markerchart",
                        sidebarPanel(
                            selectInput("in_sel_marker_xVar","x Variable:", choices = NULL),
                            selectInput("in_sel_marker_yVar","y Variable:", choices = NULL)
                        ),
                        mainPanel(
                            plotOutput('plot_marker'),
                            textOutput('text_scatter')
                        )
                ),
                ##### table
                tabItem(tabName = "table_format",
                        mainPanel(
                            DT::dataTableOutput("table")
                        )
                )
            )
        )
        
        
        
        ui<-dashboardPage(
            dashboardHeader(title='my graph'),
            sidebar,
            body
            
        )
        
        
        
        
        ######################3. 서버단 개발 ########################################
        
        
        server <- function(input, output,session) {
            options(warn = -1)
            options(shiny.maxRequestSize = 30*1024^2)
            
            
            
            
            dataload<-reactive({
                req(input$file1)
                
                file1 = input$file1
                data1 = read.csv(file1$datapath)
                
                
                updateSelectInput(session, "in_sel_bar_xVar", choices = colnames(data1))
                updateSelectInput(session, "in_sel_bar_yVar", choices = colnames(data1))
                
                updateSelectInput(session, "in_sel_pie_xVar", choices = data1[,1])
                
                updateSelectInput(session, "in_sel_line_xVar", choices = colnames(data1))
                updateSelectInput(session, "in_sel_line_yVar", choices = colnames(data1))
                
                updateSelectInput(session, "in_sel_marker_xVar", choices = colnames(data1))
                updateSelectInput(session, "in_sel_marker_yVar", choices = colnames(data1))
                return(data1)
                
            })
            
            ####nomal_bar
            output$plot_bar <- renderPlot({
                table_in<-dataload()
                
                xdata<-as.factor(table_in[,input$in_sel_bar_xVar])
                ydata<-as.factor(table_in[,input$in_sel_bar_yVar])
                fdata=data.frame(x=xdata,y=ydata)
                
                
                ggplot(fdata) +
                    geom_bar(aes_string(x='x',y='y',fill='x'),stat = "identity",show.legend=F)
                
                
            })
            ####nomal_pie
            output$plot_pie <- renderPlotly({
                table_in<-dataload()
                
                plot_ly(table_in, labels = ~colnames(table_in)[-1],
			values=~as.factor( table_in[table_in[,1] == input$in_sel_pie_xVar,-1] ),
			type='pie')
                
                
            })
            
            ####nomal_line
            output$plot_line <- renderPlotly({
                table_in<-dataload()
                
                x <- list(title = input$in_sel_line_xVar)
                y <- list(title = input$in_sel_line_yVar)
                
                plot_ly(data = table_in,
                        x = ~table_in[,input$in_sel_line_xVar],  
			y = ~table_in[, input$in_sel_line_yVar],type='scatter',mode='dot')%>%
                    layout(xaxis = x, yaxis = y)
            })
            
            ####nomal_marker
            output$plot_marker <- renderPlot({
                table_in<-dataload()
                
                xyplot(table_in[,input$in_sel_marker_yVar]~table_in[,input$in_sel_marker_xVar],
                       grid=T,type=c('p','smooth'),col.line='darkorange',lwd=2,
                       xlab=input$in_sel_marker_xVar,ylab=input$in_sel_marker_yVar)
            })
            ####nomal_correlation
            output$text_scatter <- renderText({
                table_in<-dataload()
                paste("The correlation between the two is: ", cor(table_in[,input$in_sel_marker_yVar],
                                                                  table_in[,input$in_sel_marker_xVar]))
            })
            ####table_format
            output$table <- DT::renderDataTable(DT::datatable({
                req(input$file1)
                
                file1 = input$file1
                data1 = read.csv(file1$datapath)
                
                
            }))
        }
        
        ######################### 4. 샤이니 실행 ###############################
        
        shinyApp(ui = ui, server = server)





문제 146. 부서번호가 10번인 사원들의 이름과 월급을 오라클 데이터베이스에서 불러와서 R에서 출력하시오 !

	emp_query <- 'select ename, sal from emp
	                where deptno = 10'
	emp_data <- dbGetQuery(oracle_db, emp_query)
	emp_data

	   ENAME  SAL
	1   KING 5000
	2  CLARK 2450
	3 MILLER 1300






문제 147. 이름과 부서위치를 오라클 데이터베이스에서 불러와서 R에서 출력하시오 ! ( 1999 ansi 문법)

	emp_query <- 'select e.ename, d.loc from emp e join dept d
	                on(e.deptno = d.deptno)'
	emp_data <- dbGetQuery(oracle_db, emp_query)
	emp_data
	
	    ENAME      LOC
	1    KING NEW YORK
	2   BLAKE  CHICAGO
	3   CLARK NEW YORK
	4   JONES   DALLAS
	5  MARTIN  CHICAGO
	6   ALLEN  CHICAGO
	7  TURNER  CHICAGO
	8   JAMES  CHICAGO
	9    WARD  CHICAGO
	10   FORD   DALLAS
	11  SMITH   DALLAS
	12  SCOTT   DALLAS
	13  ADAMS   DALLAS
	14 MILLER NEW YORK






문제 148. scott 유저가 가지고 있는 테이블이 무엇이 있는지 확인하시오 !

	emp_query <- 'select table_name from user_tables'
	emp_data <- dbGetQuery(oracle_db, emp_query)
	emp_data
	                   TABLE_NAME
	1                       EMP09
	2                       EMP10
	3                       EMP20
			:
			:
	78                    EXT_POL
	79                    EMP2_LG
	80                    EMP2_KT
	81                    EMP2_SK




문제 149. R 샤이니에서 오라클 데이터 베이스의 테이블의 데이터를 쉽게 볼 수 있도록 구현하시오 !

	############## set this file location to working directory ##########################
        packages <- 'rstudioapi'
        if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
            install.packages(setdiff(packages, rownames(installed.packages())))
        }
        library('rstudioapi')
        current_dir<-dirname(rstudioapi::getSourceEditorContext()$path)
        setwd(current_dir)
        
        package_in<-function(p_name,option=1){
            packages <- p_name
            if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
                install.packages(setdiff(packages, rownames(installed.packages())))
            }
            if (option==1){
                library(p_name,character.only = TRUE)
            }
        }
        
        ###########################1. 패키지 설치##########################################
        
        package_in('shinydashboard')
        package_in('shiny')
        package_in('ggplot2')
        package_in('plotly')
        package_in('lattice')
        package_in('RJDBC')
        package_in('DBI')
        
        ######################### 2. 화면 개발 ###########################################
        
        sidebar <- dashboardSidebar(
            sidebarMenu(
                fileInput("file1", "Choose CSV File",
                          multiple = FALSE,
                          accept = c("text/csv",".xlsx",".txt",
                                     "text/comma-separated-values,text/plain",
                                     ".csv")),
                
                menuItem("Plot",
                         menuSubItem('Barplot',tabName='barplot'),
                         menuSubItem('Piechart',tabName='piechart'),
                         menuSubItem('linechart',tabName='linechart'),
                         menuSubItem('markerchart',tabName='markerchart')
                ),
                menuItem("Data_table",
                         menuSubItem('table_format',tabName='table_format'),
                         menuSubItem('db_connection',tabName='db_connection')
                )
                
                
            )
        )
        
        
        body <- dashboardBody(
            
            tabItems(
                
                ##### bar plot
                tabItem(tabName = "barplot",
                        sidebarPanel(
                            selectInput("in_sel_bar_xVar","x Variable:", choices = NULL),
                            selectInput("in_sel_bar_yVar","y Variable:", choices = NULL)
                        ),
                        mainPanel(
                            plotOutput('plot_bar')
                        )
                ),
                ##### piechart
                tabItem(tabName = "piechart",
                        sidebarPanel(
                            selectInput("in_sel_pie_xVar","x Variable:", choices = NULL)
                        ),
                        mainPanel(
                            plotlyOutput('plot_pie')
                        )
                ),
                ##### linechart
                tabItem(tabName = "linechart",
                        sidebarPanel(
                            selectInput("in_sel_line_xVar","x Variable:", choices = NULL),
                            selectInput("in_sel_line_yVar","y Variable:", choices = NULL)
                        ),
                        mainPanel(
                            plotlyOutput('plot_line')
                        )
                ),
                ##### markerchart
                tabItem(tabName = "markerchart",
                        sidebarPanel(
                            selectInput("in_sel_marker_xVar","x Variable:", choices = NULL),
                            selectInput("in_sel_marker_yVar","y Variable:", choices = NULL)
                        ),
                        mainPanel(
                            plotOutput('plot_marker'),
                            textOutput('text_scatter')
                        )
                ),
                ##### table
                tabItem(tabName = "table_format",
                        mainPanel(
                            DT::dataTableOutput("table")
                        )
                ),
                ##### dbconnect_format
                tabItem(tabName = "db_connection",
                        sidebarPanel(
                            selectInput("in_sel_table_xVar","x Variable:", choices = NULL)
                        ),         
                        mainPanel(
                            DT::dataTableOutput("table1")
                        )        
                )
            )
        )
        
        
        
        ui<-dashboardPage(
            dashboardHeader(title='my graph'),
            sidebar,
            body
            
        )
        
        
        
        
        ######################3. 서버단 개발 ########################################
        
        
        server <- function(input, output, session) {
            options(warn = -1)
            options(shiny.maxRequestSize = 30*1024^2)
            
            # 오라클 DB연동을 위한 코드
            driver <- JDBC('oracle.jdbc.driver.OracleDriver', 'ojdbc6.jar')
            oracle_db <- dbConnect(driver, 'jdbc:oracle:thin:@//127.0.0.1:1521/xe', 'heaven', 'heaven')
            table_query <- 'select table_name from user_tables'
            table_list <- dbGetQuery(oracle_db, table_query)
            updateSelectInput(session, "in_sel_table_xVar", choices = table_list$TABLE_NAME)
            
            dataload<-reactive({
                req(input$file1)
                
                file1 = input$file1
                data1 = read.csv(file1$datapath)
                
                ## 선택박스 화면 구현
                updateSelectInput(session, "in_sel_bar_xVar", choices = colnames(data1))
                updateSelectInput(session, "in_sel_bar_yVar", choices = colnames(data1))
                
                updateSelectInput(session, "in_sel_pie_xVar", choices = data1[,1])
                
                updateSelectInput(session, "in_sel_line_xVar", choices = colnames(data1))
                updateSelectInput(session, "in_sel_line_yVar", choices = colnames(data1))
                
                updateSelectInput(session, "in_sel_marker_xVar", choices = colnames(data1))
                updateSelectInput(session, "in_sel_marker_yVar", choices = colnames(data1))
                
                return(data1)
                
            })
            
            ####nomal_bar
            output$plot_bar <- renderPlot({
                table_in<-dataload()
                
                xdata<-as.factor(table_in[,input$in_sel_bar_xVar])
                ydata<-as.factor(table_in[,input$in_sel_bar_yVar])
                fdata=data.frame(x=xdata,y=ydata)
                
                
                ggplot(fdata) +
                    geom_bar(aes_string(x='x',y='y',fill='x'),stat = "identity",show.legend=F)
                
                
            })
            
            ####nomal_pie
            output$plot_pie <- renderPlotly({
                table_in<-dataload()
                
                plot_ly(table_in, labels = ~colnames(table_in)[-1],
			values=~as.factor( table_in[table_in[,1] == input$in_sel_pie_xVar,-1] ),
			type='pie')
                
                
            })
            
            ####nomal_line
            output$plot_line <- renderPlotly({
                table_in<-dataload()
                
                x <- list(title = input$in_sel_line_xVar)
                y <- list(title = input$in_sel_line_yVar)
                
                plot_ly(data = table_in,
                        x = ~table_in[,input$in_sel_line_xVar],  
                        y = ~table_in[, input$in_sel_line_yVar],type='scatter',mode='dot')%>%
                    layout(xaxis = x, yaxis = y)
            })
            
            ####nomal_marker
            output$plot_marker <- renderPlot({
                table_in<-dataload()
                
                xyplot(table_in[,input$in_sel_marker_yVar]~table_in[,input$in_sel_marker_xVar],
                       grid=T,type=c('p','smooth'),col.line='darkorange',lwd=2,
                       xlab=input$in_sel_marker_xVar,ylab=input$in_sel_marker_yVar)
            })
            
            ####nomal_correlation
            output$text_scatter <- renderText({
                table_in<-dataload()
                paste("The correlation between the two is: ", cor(table_in[,input$in_sel_marker_yVar],
                                                                  table_in[,input$in_sel_marker_xVar]))
            })
            
            ####table_format
            output$table <- DT::renderDataTable(DT::datatable({
                req(input$file1)
                
                file1 = input$file1
                data1 = read.csv(file1$datapath)
            }))
            
            ####dbconnect_format
            output$table1 <- DT::renderDataTable(DT::datatable({
        
                ttt <- input$in_sel_table_xVar
                
                emp_query2 <- paste('select * from ', ttt)
                
                table_list2 <- dbGetQuery(oracle_db,emp_query2 )
                
            }))
        }
        
        ######################### 4. 샤이니 실행 ###############################
        shinyApp(ui = ui, server = server)









문제 150. (점심시간 문제) 오라클 데이터베이스에 있는 테이블의 차트를 볼 수 있게 수정하시오 !

	############## set this file location to working directory ##########################
        packages <- 'rstudioapi'
        if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
            install.packages(setdiff(packages, rownames(installed.packages())))
        }
        library('rstudioapi')
        current_dir<-dirname(rstudioapi::getSourceEditorContext()$path)
        setwd(current_dir)
        
        package_in<-function(p_name,option=1){
            packages <- p_name
            if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
                install.packages(setdiff(packages, rownames(installed.packages())))
            }
            if (option==1){
                library(p_name,character.only = TRUE)
            }
        }
        
        ###########################1. 패키지 설치##########################################
        
        package_in('shinydashboard')
        package_in('shiny')
        package_in('ggplot2')
        package_in('plotly')
        package_in('lattice')
        package_in('RJDBC')
        package_in('DBI')
        
        ######################### 2. 화면 개발 ###########################################
        
        sidebar <- dashboardSidebar(
            sidebarMenu(
                fileInput("file1", "Choose CSV File",
                          multiple = FALSE,
                          accept = c("text/csv",".xlsx",".txt",
                                     "text/comma-separated-values,text/plain",
                                     ".csv")),
                menuItem("테이블",
                         menuSubItem('Tableformat',tabName='tableformat'),
                         menuSubItem('Dbconnect',tabName='dbconnect') ),
                
                menuItem("그래프",
                         menuSubItem('Barplot',tabName='barplot'),
                         menuSubItem('Piechart',tabName='piechart'),
                         menuSubItem('Lineplot',tabName='lineplot'),
                         menuSubItem('Scatterplot',tabName='scatterplot')
                )
                
                
            )
        )
        
        
        body <- dashboardBody(
            
            
            tabItems(
                
                ##### table_format
                tabItem(tabName = "tableformat",
                        
                        mainPanel(
                            DT::dataTableOutput("table")
                        )
                ),
                
                ##### dbconnect_format
                tabItem(tabName = "dbconnect",
                        sidebarPanel(
                            selectInput("in_sel_table_xVar","x Variable:", choices = NULL)
                        ),         
                        mainPanel(
                            DT::dataTableOutput("table1")
                        )        
                ),
                
                ##### bar plot
                tabItem(tabName = "barplot",
                        sidebarPanel(
                            selectInput("in_sel_bar_yVar","y Variable:", choices = NULL),
                            selectInput("in_sel_bar_xVar","x Variable:", choices = NULL)
                        ),
                        mainPanel(
                            plotOutput('plot_bar')
                        )
                ),
                ##### piechart
                tabItem(tabName = "piechart",
                        sidebarPanel(
                            selectInput("in_sel_pie_xVar","x Variable:", choices = NULL)
                        ),
                        mainPanel(
                            plotlyOutput('plot_pie')
                        )
                ),
                ##### line plot
                tabItem(tabName = "lineplot",
                        sidebarPanel(
                            selectInput("in_sel_line_yVar","y Variable:", choices = NULL),
                            selectInput("in_sel_line_xVar","x Variable:", choices = NULL)
                            
                        ),
                        mainPanel(
                            plotlyOutput('plot_line')
                        )
                ),
                ##### scatter plot
                tabItem(tabName = "scatterplot",
                        sidebarPanel(
                            selectInput("in_sel_scatter_yVar","y Variable:", choices = NULL),
                            selectInput("in_sel_scatter_xVar","x Variable:", choices = NULL)
                            
                        ),
                        mainPanel(
                            plotOutput('plot_scatter'),
                            textOutput('text_scatter')
                        )
                )
            )
        )
        
        
        ui<-dashboardPage(
            dashboardHeader(title='Data Analistic Tool'),
            sidebar,
            body
        )
        
        
        
        
        ######################3. 서버단 개발 ########################################
        
        
        server <- function(input, output,session) {
            
            options(warn = -1)
            options(shiny.maxRequestSize = 30*1024^2)
            
            # 오라클 디비와 연동을 위한 코드
            driver <- JDBC('oracle.jdbc.driver.OracleDriver', 'ojdbc6.jar')
            oracle_db <- dbConnect(driver, 'jdbc:oracle:thin:@//127.0.0.1:1521/xe', 'heaven', 'heaven')
            table_query <- 'select table_name from  user_tables'
            table_list <- dbGetQuery(oracle_db,table_query )
            updateSelectInput(session, "in_sel_table_xVar", choices = table_list$TABLE_NAME)
            
            dataload<-reactive({
                
                if(length(table_list)>0)
                    
                { driver <- JDBC('oracle.jdbc.driver.OracleDriver', 'ojdbc6.jar')
                
                oracle_db <- dbConnect(driver, 'jdbc:oracle:thin:@//127.0.0.1:1521/xe', 'heaven', 'heaven')
                
                ttt <- input$in_sel_table_xVar
                
                emp_query2 <- paste('select * from ', ttt)
                
                data1 <- dbGetQuery(oracle_db,emp_query2 ) }
                
                else
                { req(input$file1)
                    file1 = input$file1
                    data1 = read.csv(file1$datapath)  }
                
                # 선택박스 화면 구현
                
                updateSelectInput(session, "in_sel_bar_xVar", choices = colnames(data1))
                updateSelectInput(session, "in_sel_bar_yVar", choices = colnames(data1))
                
                updateSelectInput(session, "in_sel_pie_xVar", choices = data1[,1])
                
                updateSelectInput(session, "in_sel_line_xVar", choices = colnames(data1))
                updateSelectInput(session, "in_sel_line_yVar", choices = colnames(data1))
                
                updateSelectInput(session, "in_sel_scatter_xVar", choices = colnames(data1))
                updateSelectInput(session, "in_sel_scatter_yVar", choices = colnames(data1))
                
                return(data1)
                
            })
            
            ####table_format
            output$table <- DT::renderDataTable(DT::datatable({
                req(input$file1)
                
                file1 = input$file1
                data1 = read.csv(file1$datapath)
                
                
            }))
            
            ####dbconnect_format
            output$table1 <- DT::renderDataTable(DT::datatable({
                
                driver <- JDBC('oracle.jdbc.driver.OracleDriver', 'ojdbc6.jar')
                
                oracle_db <- dbConnect(driver, 'jdbc:oracle:thin:@//127.0.0.1:1521/xe', 'heaven', 'heaven')
                
                ttt <- input$in_sel_table_xVar
                
                emp_query2 <- paste('select * from ', ttt)
                
                table_list2 <- dbGetQuery(oracle_db,emp_query2 )
                
            }))
            
            
            ####nomal_bar
            output$plot_bar <- renderPlot({
                table_in<-dataload()
                
                xdata<-as.factor(table_in[,input$in_sel_bar_xVar])
                ydata<-as.factor(table_in[,input$in_sel_bar_yVar])
                fdata=data.frame(x=xdata,y=ydata)
                
                
                ggplot(fdata) +
                    geom_bar(aes_string(x='x',y='y',fill='x'),stat = "identity",show.legend=F)
                
                
            })
            
            output$plot_pie <- renderPlotly({
                table_in<-dataload()
                
                plot_ly(table_in, labels = ~colnames(table_in)[-1],
			values=~as.factor( table_in[table_in[,1] == input$in_sel_pie_xVar,-1] ),
			type='pie')
                
                
            })
            
            output$plot_line <- renderPlotly({
                table_in<-dataload()
                
                x <- list(title = input$in_sel_line_xVar)
                y <- list(title = input$in_sel_line_yVar)
                
                plot_ly(data = table_in,x=~table_in[,input$in_sel_line_xVar],
			y=~table_in[,input$in_sel_line_yVar],type='scatter',mode='dot')%>%
                    layout(xaxis = x, yaxis = y)
                
                
            })
            
            output$plot_scatter <- renderPlot({
                table_in<-dataload()
                
                xyplot(table_in[,input$in_sel_scatter_yVar]~table_in[,input$in_sel_scatter_xVar],
			grid=T,type=c('p','smooth'),col.line='darkorange',lwd=2,
			xlab=input$in_sel_scatter_xVar,ylab=input$in_sel_scatter_yVar)
                
            })
            
            output$text_scatter <- renderText({
                table_in<-dataload()
                paste("The correlation between the two is: ",
			cor(table_in[,input$in_sel_scatter_yVar],table_in[,input$in_sel_scatter_xVar]))
            })
            
        }
        
        ######################### 4. 샤이니 실행 ###############################
        shinyApp(ui = ui, server = server)






문제 151. maps패키지를 설치하고 중국지도만 확대해서 출력하시오 !

	install.packages("maps")
	install.packages("mapproj")
	
	library(maps)
	library(mapproj)
	map("world", "china")







문제 152. 우리나라 지도를 출력하시오

	map("world", "south korea")






문제 153. 프랑스 지도를 출력하시오 !

	map("world", "france")






문제 154. 구글 지도 그래프를 이용해서 서울 지역의 지하철 2호선의 그래프를 시각화 하시오 !

	install.packages("ggplot2")
	install.packages("ggmap")
	
	library(ggplot2)
	library(ggmap)
	register_google(key = "AIzaSyDGRHkkUQsgzw4G0dKGj1TFaHqcO7uT8_w")
	
	loc <- read.csv("서울지하철2호선위경도정보.csv", header =T)
	loc
	center <- c(mean(loc$LON), mean(loc$LAT))
	center
	
	kor <- get_map(center,zoom=11, maptype="roadmap")
	kor.map <- ggmap(kor) + geom_point(data=loc,aes(x=LON,y=LAT),size=3, alpha=0.7)
	kor.map + geom_text(data=loc, aes(x=LON,y=LAT+0.005,label=역명),size=3)






문제155. 지역별 인구수에 대한 지도 그래프를 그리시오

	library(ggmap)
	library(ggplot2)
	
	register_google(key = "AIzaSyDGRHkkUQsgzw4G0dKGj1TFaHqcO7uT8_w")
	
	population <- read.csv("c:\\R\\지역별인구.csv",header=T)
	
	cen <- c(mean(population$LON),mean(population$LAT))
	
	map <- get_googlemap(center=cen, maptyp="roadmap",zoom=7)
	ggmap(map)
	
	ggmap(map)+
	    geom_point(data=population,aes(x=LON,y=LAT,colour=지역,size=총인구수))+
	    xlab("longitude(경도)") +
	    ylab("latitude(위도)")
	ggmap(map)+
	    geom_text(data=population,aes(x=LON,y=LAT,color=factor(지역),size=10,label=seq_along(지역)))





문제156. 겨울왕국 대본을 워드 클라우드로 그리시오 !

        install.packages("KoNLP")
        install.packages("wordcloud")
        install.packages("plyr")
        
        library(KoNLP)
        library(wordcloud)
        library(plyr)
        
        useSejongDic()
        winter <- readLines('winter.txt')
        
        nouns <- extractNoun(winter)   #겨울왕국 대본에서 명사만 추출
        nouns <- unlist(nouns)
        nouns <- nouns[nchar(nouns)>=2]    # 명사중에 2철자 이상만 추출
        cnouns <- count(nouns)          #단어별 건수 출력
        
        # 색깔 추가
        pal <- brewer.pal(6,"Dark2")
        pal <- pal[-(1)]
        
        # 글씨체 추가
        windowsFonts(malgun=windowsFont("맑은 고딕"))
        
        data.table(words=cnouns$x, freq=cnouns$freq)
        
        wordcloud(words=cnouns$x,     # 단어
                  freq=cnouns$freq,   # 건수
                  colors=pal,         # 색깔
                  min.freq=3,         # 빈도수가 3단어 이상인것만 시각화
                  random.order=F,     # F로 하면 가장 많은것부터 중앙에서 퍼지게 한다.
                  family="malgun")    # 맑음 글씨체로 시각화






문제 157. 영어 성경을 워드클라우드로 시각화 하시오 !

	install.packages("stringi")
	library(KoNLP)
	library(wordcloud)
	library(plyr)
	
	useSejongDic()
	winter <- readLines('NIV.txt')
	
	nouns <- extractNoun(winter)   #겨울왕국 대본에서 명사만 추출
	nouns <- unlist(nouns)
	nouns <- nouns[nchar(nouns)>=2]    # 명사중에 2철자 이상만 추출
	cnouns <- count(nouns)          #단어별 건수 출력
	
	# 색깔 추가
	pal <- brewer.pal(6,"Dark2")
	pal <- pal[-(1)]
	
	# 글씨체 추가
	windowsFonts(malgun=windowsFont("맑은 고딕"))
	
	data.table(words=cnouns$x, freq=cnouns$freq)
	
	wordcloud(words=cnouns$x,     # 단어
	          freq=cnouns$freq,   # 건수
	          colors=pal,         # 색깔
	          min.freq=3,         # 빈도수가 3단어 이상인것만 시각화
	          random.order=F,     # F로 하면 가장 많은것부터 중앙에서 퍼지게 한다.
	          family="malgun")    # 맑음 글씨체로 시각화







        ahn <- "안녕하십니까 안철수입니다.
         
        저는 지난 7월말에 말씀 드린 대로 국민들의 의견을 듣고자 많은 분들을 만났습니다.
        
        그 동안 저는 재미있는 별명도 얻었고.
        또 최근에는 저를 소재로 한 유머도 유행하더군요.
        
        그동안 제 답을 기다려오신 여러 분들의 애정이라고 생각하고
        그 또한 무겁게 받아들이겠습니다.
        
        기업인과 교수의 삶을 살아온 저로서는,
        국가경영의 막중한 책임을 지는 결심에 이르기까지
        정말 많은 생각을 하지 않을 수 없었습니다.
        
        저는 그동안 춘천에서 만난 어르신, 명예퇴직을 앞둔 중년의 가장,
        30대의 쌍둥이 엄마와 같은 많은 이웃들을 만나 뵈었고,
        각 분야에서 경륜과 전문성을 가진 분들도 만났습니다.
        
        가능하면 조용하게 경청하고 귀를 기울였습니다.
        
        어느 한분 힘들지 않은 분들이 없었습니다.
        
        중산층이 무너지고 저소득층이 너무 고통 받고 있었습니다.
        
        하지만 그렇게 힘들고 고단한 삶의 과정에서도
        그분들은 끊임없이 희망을 만들고 계셨습니다.
        
        나 자신보다는 우리 아이들의 미래를 위해
        참고 견디고 희생하고 헌신할 준비가 되어 있습니다.
        
        제가 희망을 드린 것이 아니라 제가 오히려 그분들께 힘과 용기를 얻었습니다.
        모두 고맙습니다.
        여러분이 제게는 스승입니다.
        
        그 분들이 저를 한걸음 더 나아가게 했습니다.
        
        그 분들이 제게 한결 같이 하신 말씀이 있습니다.
        
        '정치가 이래서는 안 된다'는 겁니다.
        '문제를 풀어야 할 정치가 문제를 만들고 있다'고 하셨습니다.
        '국민들의 삶을 외면하고 국민을 분열시키고, 국민을 무시하고,
        서로 싸우기만 하는 정치에 실망하고 절망했다' 하셨습니다.
        
        또 한 번도 정치에 발 딛지 않은 제가 '잘 할 수 있을까' 고민할 때
        많은 분들이 왜 제게 지지를 보내는지 설명해 주셨습니다.
        
        '이제 좀 정치를 다르게 해보자, 새롭게 출발해보자'는 뜻이라는 겁니다.
        
        하지만 저는 제 역량에 대해 고민했습니다.
        국가의 리더라는 자리는 절대 한 개인이 영광으로 탐할 자리가 될 수도 없고,
        되어서도 안 된다고 생각합니다.
        
        저에게는 당선 여부보다는 잘 해낼 수 있느냐가 중요했습니다.
        
        그래서 스스로에게 거듭 질문을 던지고 대화를 통해 답을 찾고자 노력했습니다.
        저는 이제 제 자신 스스로에게 질문했던 답을 내어놓으려 합니다.
        
        지금까지 국민들은 저를 통해 정치쇄신에 대한 열망을 표현해주셨습니다.
        
        저는 이제
        이번 18대 대통령 선거에 출마함으로써
        그 열망을 실천해내는 사람이 되려 합니다.
        
        저에게 주어진 시대의 숙제를 감당하려고 합니다.
        
        저는 먼저 정치개혁은 선거과정에서부터 시작해야한다고 생각합니다.
        국민의 반을 적으로 돌리면서 통합을 외치는 것은 위선입니다.
        선거과정에서 부당하고 저급한 흑색선전과 이전투구를 계속하면,
        서로를 증오하고 지지자들을 분열시키며, 나아가서는 국민을 분열시킵니다.
        그렇게 선거가 끝나고 나면 선거에서 이겨도 국민의 절반 밖에 마음을 얻지 못합니다.
        
        앞으로도 이런 일이 계속 된다면 다음 5년도
        분열과 증오의 시간을 보낼 수밖에 없을 겁니다.
        누가 대통령이 되더라도 통합과 사회문제 해결은 요원한 일일 것입니다.
        
        그래서 저는 저부터 선거과정에서의 쇄신을 약속드리겠습니다.
        
        저는 선거과정에서 어떤 어려움과 유혹이 있더라도
        흑색선전과 같은 낡은 정치는 하지 않겠습니다.
        
        그리고 어떤 결과가 나오더라도
        저를 지지하는 분들이 그 결과를 존중하고 같이 축하할수 있도록 노력하겠습니다.
        
        박근혜 후보와 문재인 후보께 제안합니다.
        
        모두 한자리에 모여,
        국민들을 증인으로 선의의 정책 경쟁을 할 것을 약속하면 어떻겠습니까?
        
        그리고 선거후에도 승리한 사람은 다른 후보들의 이야기에 귀를 기울이며,
        패배한 사람은 깨끗이 결과에 승복하여
        더 나은 우리의 미래를 만들기 위해 협력할 것도 같이 약속하면 어떨까요?
        
        그래야 분열과 증오의 정치를 넘어서
        우리의 미래를 위한 에너지로 바꿔 놓을 수 있을 겁니다.
        
        누가 당선 되더라도 국민을 위해서라면
        서로 도울 수 있고 또 함께 할 수 있는
        통합의 시작점이 될 수 있습니다.
        
        그러한 정책 대결 속에서 제가 만약 당선된다면
        다른 후보들의 더 나은 정책이 있다면 받아들이고 또 경청할 겁니다.
        
        이것이 바로 국민들이 원하는 덧셈의 정치, 통합의 정치라고 저는 생각합니다.
        
        많은 분들이 정치 경험도 없는데
        막상 대통령이 되면 어떻게 할 것이냐고 걱정을 하셨습니다.
        정치라는 험한 곳에 들어가 괜히 만신창이가 되지 말라고도 하셨습니다.
        지금 이 자리에도 그런 생각을 가진 분들이 계실 겁니다.
        
        저는 정치경험뿐 아니라 조직도 없고, 세력도 없지만, 그만큼 빚진 것도 없습니다.
        정치경험 대신 국민들께 들은 이야기를 소중하게 가지고 가겠습니다.
        조직과 세력 대신 나라를 위해 애쓰시는 모든 분들과 함께 나아가겠습니다.
        빚진 게 없는 대신, 공직을 전리품으로 배분하는 일만큼은 결코 하지 않을 것입니다.
        
        사실 대통령 한 사람의 힘으로 5년 만에 모든 문제를 해결 할 수는 없습니다.
        그렇지만 대한민국은 이미 현명한 국민들과 많은 전문가들이
        요소요소에서 각자가 역할을 하는 커다란 시스템을 이루고 있습니다.
        
        그 속에 이미 답이 있습니다.
        
        지금 대한민국은 낡은 체제와 미래가치가 충돌하고 있습니다.
        이제 낡은 물줄기를 새로운 미래를 향해 바꿔야 합니다.
        국민들의 민의를 반영하지 못하는 정치 시스템,
        빈부격차가 심해지고 일자리를 창출하지 못하는 경제 시스템,
        계층 간의 이동이 차단된 사회시스템,
        공정한 기회가 부여되지 않는 기득권 과보호구조,
        지식산업시대에 역행하는 옛날 방식의 의사결정구조,
        
        이와 같은 것들로는 미래를 열어갈 수 없습니다.
        더 이상 이대로는 안 됩니다.
        
        국민들은 이제 정치부터 바꿔야 한다고 이야기하십니다.
        앞으로 5년은 누가 대통령이 되더라도 매우 힘든 상황이 전개될 것입니다.
        
        국내의 가계부채와 부동산 문제가 정말 심각합니다. 세계적인 장기불황까지 겹쳐 한꺼번에
        위기적 상황이 닥쳐올 가능성이 많습니다.
        
        이러한 상황 하에서 제가 혼자서 모든 문제를 해결하고
        세상을 바꿀 수 있다고 생각하지 않습니다.
        
        저도 열심히 살려고 노력했지만 부족하고 실수도 하고 결점이 많은 사람이기 때문입니다.
        
        하지만, 현명한 국민들과 전문가들 속에서 답을 구하고, 지혜를 모으면
        그래도 최소한 물줄기는 돌려놓을 수 있을 거라고 생각합니다.
        
        위기의 시대에 힘을 합쳐 함께 어려움을 헤쳐나갈 수 있다고 생각합니다.
        
        정치가 바뀌어야 우리 삶이 바뀔 수 있습니다.
        새로운 정치가 들어서야 민생경제 중심 경제가 들어섭니다.
        
        대한민국은 새로운 경제모델이 필요합니다.
        지금 논의되고 있는 경제민주화와 복지는 성장동력과 결합하는 경제혁신을 만들어야 합니다.
        
        평화체제는 역시 안보와 균형을 맞출 때 실현가능합니다.
        
        제 정책비전과 구상의 구체적 내용은 앞으로 선거과정에서 말씀드리겠습니다.
        
        저는 이번 선거 과정부터
        국민의 생각이 하나로 모아지는 첫걸음을 시작했으면 좋겠습니다.
        
        이번 선거를 통해 새로운 변화를 원하는 국민의 마음이 하나로 모아지면 좋겠습니다.
        
        저는 세상을 움직이는 것은 진심이라고 생각합니다.
        진심의 정치를 하겠습니다.
        
        그 과정에서 저를 향한 공격이나 비난은 두렵지 않습니다. 극복하겠습니다.
        더 나은 미래를 만들기 위해 싸워야 한다면 정정당당하게 싸울 것입니다.
        사람의 선의가 가장 강력한 힘이 될 수 있다는 것을
        국민여러분과 함께 증명하려고 합니다.
        
        저에게 많은 이야기를 들려주신
        그리고 많은 지지를 보내주신 국민여러분
        저와 함께 해주십시오.
        
        그래야 정치가 바뀌고 정치가 바뀌어야 우리의 삶이 바뀝니다.
        변화의 열쇠는 바로 국민 여러분께 있습니다.
        국민이 선택하는 새로운 변화가 시작됩니다.
        
        마지막으로
        제가 좋아하는 작가, 윌리엄 깁슨의 말을 하나 소개하고 싶습니다.
        
        '미래는 이미 와 있다. 단지 널리 퍼져있지 않을 뿐이다'
        그렇습니다. 미래는 지금 우리 앞에 있습니다.
        
        고맙습니다."
        
        
        library(KoNLP)
        library(wordcloud)
        library(plyr)
        
        useSejongDic()
        
        mergeUserDic(data.frame(c('안철수', '박근혜', '문제인'), c('nqpc')))  #  추가 시키고 싶은
        
        nouns <- extractNoun(ahn)   
        
        nouns <- nouns[nchar(nouns)>=2]
        
        cnouns <- count(nouns)
        
        
        pal <- brewer.pal(6,"Dark2")
        pal <- pal[-(1)]
        
        windowsFonts(malgun=windowsFont("맑은 고딕"))
        
        data.table(words=cnouns$x, freq=cnouns$freq)
        
        wordcloud(words=cnouns$x, freq=cnouns$freq, colors=pal, min.freq=1,
                  random.order=F, family="malgun")
        ###############
        

문제 159.

	##########
        #install.packages("tm")
        
        library(shiny)
        
        library(tm)
        library(wordcloud)
        library(memoise)
        
        # The list of valid books
        books <<- list("A Mid Summer Night's Dream" = "summer",
                       "The Merchant of Venice" = "merchant",
                       "Romeo and Juliet" = "romeo")
        
        # Using "memoise" to automatically cache the results
        getTermMatrix <- memoise(function(book) {
            # Careful not to let just any name slip in here; a
            # malicious user could manipulate this value.
            if (!(book %in% books))
                stop("Unknown book")
            
            text <- readLines(sprintf("c://R//%s.txt.gz", book),
                              encoding="UTF-8")
            
            myCorpus = Corpus(VectorSource(text))
            myCorpus = tm_map(myCorpus, content_transformer(tolower))
            myCorpus = tm_map(myCorpus, removePunctuation)
            myCorpus = tm_map(myCorpus, removeNumbers)
            myCorpus = tm_map(myCorpus, removeWords,
                              c(stopwords("SMART"), "thy", "thou", "thee", "the", "and", "but"))
            
            myDTM = TermDocumentMatrix(myCorpus,
                                       control = list(minWordLength = 1))
            
            m = as.matrix(myDTM)
            
            sort(rowSums(m), decreasing = TRUE)
        })
        
        # Define UI ----
        ui <- fluidPage(
            # Application title
            titlePanel("Word Cloud"),
            
            sidebarLayout(
                # Sidebar with a slider and selection inputs
                sidebarPanel(
                    selectInput("selection", "Choose a book:",
                                choices = books),
                    actionButton("update", "Change"),
                    hr(),
                    sliderInput("freq",
                                "Minimum Frequency:",
                                min = 1,  max = 50, value = 15),
                    sliderInput("max",
                                "Maximum Number of Words:",
                                min = 1,  max = 300,  value = 100)
                ),
                
                # Show Word Cloud
                mainPanel(
                    plotOutput("plot")
                )
            )
        )
        
        # Define server logic ----
        server <- function(input, output, session) {
            # Define a reactive expression for the document term matrix
            terms <- reactive({
                # Change when the "update" button is pressed...
                input$update
                # ...but not for anything else
                isolate({
                    withProgress({
                        setProgress(message = "Processing corpus...")
                        getTermMatrix(input$selection)
                    })
                })
            })
            
            # Make the wordcloud drawing predictable during a session
            wordcloud_rep <- repeatable(wordcloud)
            
            output$plot <- renderPlot({
                v <- terms()
                wordcloud_rep(names(v), v, scale=c(4,0.5),
                              min.freq = input$freq, max.words=input$max,
                              colors=brewer.pal(8, "Dark2"))
            })
        }
        
        # Run the app ----
        shinyApp(ui = ui, server = server)
        
        ##########






문제 160. 사원테이블에 대하여 박스 그래프와 산포도 그래프를 겹쳐서 보이게 출력하시오 !
        
        graphics.off()
        boxplot(emp$sal)
        par(new=T)
        plot(emp$sal, col="blue")
        
        
        
        
        




문제 161. 사분위수 그래프를 샤이니에 추가하시오 !
        
        ############## set this file location to working directory ##########################
        packages <- 'rstudioapi'
        if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
            install.packages(setdiff(packages, rownames(installed.packages())))
        }
        library('rstudioapi')
        current_dir<-dirname(rstudioapi::getSourceEditorContext()$path)
        setwd(current_dir)
        
        package_in<-function(p_name,option=1){
            packages <- p_name
            if (length(setdiff(packages, rownames(installed.packages()))) > 0) {
                install.packages(setdiff(packages, rownames(installed.packages())))
            }
            if (option==1){
                library(p_name,character.only = TRUE)
            }
        }
        
        ###########################1. 패키지 설치##########################################
        
        package_in('shinydashboard')
        package_in('shiny')
        package_in('ggplot2')
        package_in('plotly')
        package_in('lattice')
        
        ######################### 2. 화면 개발 ###########################################
        
        sidebar <- dashboardSidebar(
            sidebarMenu(
                fileInput("file1", "Choose CSV File",
                          multiple = FALSE,
                          accept = c("text/csv",".xlsx",".txt",
                                     "text/comma-separated-values,text/plain",
                                     ".csv")),
                menuItem("테이블",
                         menuSubItem('Tableformat',tabName='tableformat') ),
                
                menuItem("그래프",
                         menuSubItem('Barplot',tabName='barplot'),
                         menuSubItem('Piechart',tabName='piechart'),
                         menuSubItem('Lineplot',tabName='lineplot'),
                         menuSubItem('Scatterplot',tabName='scatterplot'),
                         menuSubItem('boxplot',tabName='boxplot')
                )
                
                
            )
        )
        
        
        body <- dashboardBody(
            
            
            
            tabItems(
                
                ##### table_format
                tabItem(tabName = "tableformat",
                        
                        mainPanel(
                            DT::dataTableOutput("table")
                        )
                ),
                
                ##### bar plot
                tabItem(tabName = "barplot",
                        sidebarPanel(
                            selectInput("in_sel_bar_yVar","y Variable:", choices = NULL),
                            selectInput("in_sel_bar_xVar","x Variable:", choices = NULL)
                        ),
                        mainPanel(
                            plotOutput('plot_bar')
                        )
                ),
                ##### piechart
                tabItem(tabName = "piechart",
                        sidebarPanel(
                            selectInput("in_sel_pie_xVar","x Variable:", choices = NULL)
                        ),
                        mainPanel(
                            plotlyOutput('plot_pie')
                        )
                ),
                ##### line plot
                tabItem(tabName = "lineplot",
                        sidebarPanel(
                            selectInput("in_sel_line_yVar","y Variable:", choices = NULL),
                            selectInput("in_sel_line_xVar","x Variable:", choices = NULL)
                            
                        ),
                        mainPanel(
                            plotlyOutput('plot_line')
                        )
                ),
                ##### scatter plot
                tabItem(tabName = "scatterplot",
                        sidebarPanel(
                            selectInput("in_sel_scatter_yVar","y Variable:", choices = NULL),
                            selectInput("in_sel_scatter_xVar","x Variable:", choices = NULL)
                            
                        ),
                        mainPanel(
                            plotOutput('plot_scatter'),
                            textOutput('text_scatter')
                        )
                ),
                ##### scatter plot
                tabItem(tabName = "boxplot",
                        sidebarPanel(
                            selectInput("in_sel_box_xVar","x Variable:", choices = NULL)
                            
                        ),
                        mainPanel(
                            plotOutput('plot_box')
                        )
                )
            )
        )
        
        
        ui<-dashboardPage(
            dashboardHeader(title='my graph'),
            sidebar,
            body
        )
        
        
        
        
        ######################3. 서버단 개발 ########################################
        
        
        server <- function(input, output,session) {
            options(warn = -1)
            options(shiny.maxRequestSize = 30*1024^2)
            
            
            
            
            dataload<-reactive({
                req(input$file1)
                
                file1 = input$file1
                data1 = read.csv(file1$datapath)
                
                
                updateSelectInput(session, "in_sel_bar_xVar", choices = colnames(data1))
                updateSelectInput(session, "in_sel_bar_yVar", choices = colnames(data1))
                
                updateSelectInput(session, "in_sel_pie_xVar", choices = data1[,1])
                
                updateSelectInput(session, "in_sel_line_xVar", choices = colnames(data1))
                updateSelectInput(session, "in_sel_line_yVar", choices = colnames(data1))
                
                updateSelectInput(session, "in_sel_scatter_xVar", choices = colnames(data1))
                updateSelectInput(session, "in_sel_scatter_yVar", choices = colnames(data1))
                
                updateSelectInput(session, "in_sel_box_xVar", choices = colnames(data1))
                
                return(data1)
                
            })
            
            ####table_format
            output$table <- DT::renderDataTable(DT::datatable({
                req(input$file1)
                
                file1 = input$file1
                data1 = read.csv(file1$datapath)
                
                
            }))
            
            
            ####nomal_bar
            output$plot_bar <- renderPlot({
                table_in<-dataload()
                
                xdata<-as.factor(table_in[,input$in_sel_bar_xVar])
                ydata<-as.factor(table_in[,input$in_sel_bar_yVar])
                fdata=data.frame(x=xdata,y=ydata)
                
                
                ggplot(fdata) +
                    geom_bar(aes_string(x='x',y='y',fill='x'),stat = "identity",show.legend=F)
                
                
            })
            
            output$plot_pie <- renderPlotly({
                table_in<-dataload()
                
                plot_ly(table_in, labels = ~colnames(table_in)[-1], values=~as.factor( table_in[table_in[,1] ==
input$in_sel_pie_xVar,-1] ),type='pie')
                
                
            })
            
            output$plot_line <- renderPlotly({
                table_in<-dataload()
                
                x <- list(title = input$in_sel_line_xVar)
                y <- list(title = input$in_sel_line_yVar)
                
                plot_ly(data = table_in,x=~table_in[,input$in_sel_line_xVar],y=~table_in[,input
$in_sel_line_yVar],type='scatter',mode='dot')%>%
                    layout(xaxis = x, yaxis = y)
                
                
            })
            
            output$plot_scatter <- renderPlot({
                table_in<-dataload()
                
                xyplot(table_in[,input$in_sel_scatter_yVar]~table_in[,input$in_sel_scatter_xVar], grid=T,type=c
('p','smooth'),col.line='darkorange',lwd=2, xlab=input$in_sel_scatter_xVar,ylab=input$in_sel_scatter_yVar)
                
            })
            
            output$text_scatter <- renderText({
                table_in<-dataload()
                paste("The correlation between the two is: ", cor(table_in[,input$in_sel_scatter_yVar],table_in
[,input$in_sel_scatter_xVar]))
            })
            
            output$plot_box <- renderPlot({
                table_in<-dataload()
                
                bwplot(~table_in[,input$in_sel_box_xVar], data=table_in,xlab=input$in_sel_box_xVar)
                
            })
            
            
        }
        
        ######################### 4. 샤이니 실행 ###############################
        shinyApp(ui = ui, server = server)







문제 162. 위의 표를 R로 구현하고 나이의 평균값을 출력하시오 !

	class1 <- c(rep(19, 3), rep(20, 6), rep(21, 3), 145, 147)
	class1
	
	mean(class1)
	
	[1] 38
			쿵푸 교실
		나이  19  20  21  145  147
		도수   3   6   3    1    1
				   ↑   ↑
				  고수 고수

		※ 이상치 때문에 평균이 높아졌다

		※ 이상치 ?  다른 데이터에 비해 눈에 뜨일 정도로 지나치게 높거나 낮은 값

		※ 편향이란 ?  이상치에 의해서 평균값이 상승 되었다. 이런 현상을 보이면 데이터가 편향
			       되었다고 한다.




문제 163. 위의 class1의 이상치를 출력하시오 !

	install.packages("outliers")
	library(outliers)
	outlier(class1)

	[1] 147

	x2 <- boxplot(class1)
	x2
	
	$out
	[1] 145 147

	



문제 164. 데이터 분석을 잘못해서 이런일이 벌어졌다. 이 문제를 해결하기 위해 알아야하는 값이 무엇인가?

	median(class1)

	[1] 20

	summary(class1)

	   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
	     19      20      20      38      21     147 	

		평균값이 갖는 위험은 실제로 데이터 집합에 존재하지 않는 수라는 것이다.
		그런데 중앙값은 그 반의 임의 학생을 선택한 것이라 다른 학생들도 20대일 가능성이 높다.






문제 165. 위의 두개의 그래프를 R로 직접 그려서 편향 여부를 확인하시오 !

	class1 <- c(rep(1, 4), rep(2, 6), rep(3, 4),  rep(4, 4),  rep(5, 3),  rep(6, 2), 7, 8)
	
	class2 <- c(1, 4, rep(6, 2),  rep(8, 3),  rep(9, 4),  rep(10, 4),  rep(11, 5),  rep(12, 5))
	mean(class1)    # 38
        mean(class2)    # 9.28
        median(class1)  # 20
        median(class2)  # 10

	plot(class1, dnorm(class1, mean=mean(class1), sd=sd(class1)), type="l", main="정규분포 그래프")
	plot(class2, dnorm(class2, mean=mean(class2), sd=sd(class2)), type="l", main="정규분포 그래프")

		※ class1 = 왼쪽 편향
		   class2 = 오른쪽 편향





문제 166. class1과 class2의 왜도값을 확인하시오!

	install.packages("fBasics")
	library(fBasics)
	skewness(class1)   # 0.5805801  <---- 왜도값이 0보다 크다는 것은 오른쪽으로 꼬리가 긴
					      그래프이므로 대부분의 데이터들이 작은쪽에 있다.
	skewness(class2)   # -1.326201  <---- 왜도값이 0보다 작다는 것은 왼쪽으로 꼬리가 긴
					      그래프이므로 대부분의 데이터들이 큰쪽에 있다.

			"오른쪽 편향"
		높은 이상치가 평균값을 왜곡 할 수 있다.
		이상치가 어디에 있을 가능성이 높은가 ?  높은쪽에 있다.

			"왼쪽 편향"
		이상치가 어디에 있을 가능성이 높은가 ?  낮은쪽에 있다.




문제 167. 우리반 나이 데이터를 가지고 정규분포 그래프를 그리시오 !
	  그리고 왜도값이 양수인지 음수인지 확인하시오 !

	class <- read.csv("emp8.csv", header= T)
        class_age <- sort(class$age)
        class_age
        
        plot(class_age, dnorm(class_age, mean=mean(class_age), sd=sd(class_age)),
             type="l", main="정규분포 그래프")
        skewness(class$age)   # 1.808622

		※ 설명 : 이상적인 경우는 데이터가 좌우대칭을 형성하는 것이다.
			  데이터가 좌우 대칭이면 평균값은 가운데 위치한다.
			  평균값을 한쪽 방향으로 잡아끄는 이상치가 없으며 좌우에 형성되는 차트의 모양이
			  중앙을 중심으로 했을 때 동일하다.




문제 168. (점심시간 문제) 위에서 말하는 좌우 대칭의 정규분포 그래프를 그리시오 !

	data <- seq(-3, 3, 0.01)
	data_norm <- dnorm(data, 0, 1)
	plot(data, data_norm, type="l", main="정규분포 그래프")
	kurtosis(data_norm)    # -1.374235
	skewness(data_norm)    # 0.3921449







문제 169. swim_class1 데이터에서 최빈값을 출력하시오 !

	swim_class <- c(rep(1, 3), rep(2, 4), rep(3, 2), rep(31, 2), rep(32, 4), rep(33, 3))
	
	getmode <- function(v) {
	    uniqv <- unique(v)
	    uniqv[which.max(tabulate(match(v, uniqv)))]
	}
	getmode(swim_class)

		"최빈값은 반드시 데이터 안에 존재하는 값이다"
		평균값도 그렇고 중앙값도 그렇게 데이터 안에 반드시 있는 값이 나오는게 아니다.







문제 170. 아래의 데이터에서 하한 사분위수, 중앙값, 상한 사분위수가 무엇인지 선택하시오 !

	x <- c(3, 3, 6, 7, 7, 10, 10, 10, 11, 13, 30)
	quantile(x)
	
	  0%  25%  50%  75% 100%
	 3.0  6.5 10.0 10.5 30.0

	x1 <- boxplot(x)
	x1
	
	     [,1]
	[1,]  3.0	하한
	[2,]  6.5	하한 사분위수
	[3,] 10.0	중앙
	[4,] 10.5	상한 사분위수
	[5,] 13.0	상한






문제 171. 다음 데이터에서 하한값, 하한 사분위수, 중앙값, 상한 사분위수, 상한값을 출력하시오 !

	 1  1  1  2  2  □  2  2  3  3  3  □  3  3  4  4  4  □  4  5  5  5 10
	↑	     ↑			↑		   ↑		   ↑
       하한	 하한 사분위수 	      중앙값 	     상한 사분위수 	  상한

	x <- c(rep(1, 3), rep(2, 4), rep(3, 5), rep(4, 4), rep(5, 3), 10)
	x1 <- boxplot(x)
	x1
	
	     [,1]
	[1,]    1
	[2,]    2
	[3,]    3
	[4,]    4
	[5,]    5

		※ 이런 값들을 구하는 이유가 무엇인가?
			답 : 이상치 때문이다. 이상치를 제거하고 가운데 50%의 데이터에만 집중함으로써
			     문제를 우회할 수 있는 것이다.






문제 172. 아래의 3명의 농구선수들의 점수를 가지고 사분위수 그래프를 그리는데 2번 선수와 3번 선수 두명의
	  그래프를 하나의 그래프로 출력하시오 !

	x1 <- c(7   ,8   ,9   ,9   ,10   ,10   ,11   ,11   ,12   ,13)
	x2 <- c (7   ,9   ,9   ,10   ,10   ,10   ,10   ,11   ,11   ,13,13 )
	x3 <- c(3   ,3   ,6   ,7   ,7   ,10   ,10   ,10   ,11   ,13   ,30 )

	cbind(x2,x3)
	zz <- cbind(x2, x3)
	boxplot(zz,horizontal = TRUE)

	※ 설명 : 2번 선수가 3번선수보다 상대적으로 좁은 범위를 가지고 있다.

	3번 선수는 넓은 범위를 가지고 있고 이 선수는 2번 선수에 비해 훨씬 높은 점수로 득점을 했지만
	다른 경우에는 훨씬 낮은 점수를 기록했다.

	2번 선수가 더 일관성이 있고, 대부분의 경우에 3번 선수보다 더 높은 점수를 기록을 했다.

     	따라서 2번 선수를 고를 것이다.






문제 173. x2 선수와 x3 선수의 슈팅 성공율이 둘다 70% 라고 할때 Z score(표준점수) 를 구하시오 !

	x2 <- c (7   ,9   ,9   ,10   ,10   ,10   ,10   ,11   ,11   ,13, 13 )
	x3 <- c(3   ,3   ,6   ,7   ,7   ,10   ,10   ,10   ,11   ,13   ,30 )


	답 :
		(70 - mean(x2)) / sd(x2)

		[1] 34.37953

		(70 - mean(x3)) / sd(x3)

		[1] 8.149887

		※ 설명 : 70 이라는 것은 %(퍼센트) 가 아니라 점수로 봐야 맞다. 기존에 가지고 있는
			  x2 와 x3 가 점수로 구성되어 있기 때문이다.






문제 174. 중고차의 색깔과 색깔별 비율이 어떻게 되는지 출력하시오 ! (usedcars.csv)

	usedcars <- read.csv("usedcars.csv",header=T)
	color_pct <- table(usedcars$color)
	color_pct
	color_pct <- prop.table(color_pct) * 100
	round(color_pct, digit=1)

	 Black   Blue   Gold   Gray  Green    Red Silver  White Yellow
	  23.3   11.3    0.7   10.7    3.3   16.7   21.3   10.7    2.0

		※ 설명 : 검정색이 전체 차중에 23% 로 가장 많은 비율을 차지한다. 그리고 대부분
			  보수적인 색깔이 주를 이루고 있다.







문제 175. 커미션을 받는 사원들의 월급의 분포도가 어떻게 되는지 산포도 그래프로 확인하시오 !



문제 176. (마지막 문제) 중고차의 주행거리가 높으면 중고차의 가격이 낮아진다는 것을 plot 그래프로
	  확인하시오 !







문제 177.  직업(가로), 부서번호(세로), 직업별 부서번호별 인원수를 출력하시오 !   (tapply 함수 사용)

	     ANALYST CLERK MANAGER PRESIDENT SALESMAN
	10       0     1       1         1        0
	20       2     2       1         0        0
	30       0     1       1         0        4

	tapply( emp$empno, list(emp$deptno, emp$job), length, default=0)

		* 이원 교차표란 ?  

			  두 명목 변수간의 관계를 관찰하기 위해 이원 교차표를 사용한다







문제178. 위의 결과를 이원 교차표를 출력하는 CrossTable 함수를 이용해서 위의 결과를 출력하시오 !

	install.packages("gmodels")
	library(gmodels)
	CrossTable(x=emp$deptno, y=emp$job)

	   Cell Contents
	|-------------------------|
	|                       N |
	| Chi-square contribution |
	|           N / Row Total |
	|           N / Col Total |
	|         N / Table Total |
	|-------------------------|
	
	
	Total Observations in Table:  15
	
	
	             | emp$job
	  emp$deptno |   ANALYST |     CLERK |   MANAGER | PRESIDENT |  SALESMAN | Row Total |
	-------------|-----------|-----------|-----------|-----------|-----------|-----------|
	          10 |         0 |         1 |         1 |         1 |         0 |         3 |
	             |     0.400 |     0.000 |     0.267 |     3.200 |     0.800 |           |
	             |     0.000 |     0.333 |     0.333 |     0.333 |     0.000 |     0.200 |
	             |     0.000 |     0.200 |     0.333 |     1.000 |     0.000 |           |
	             |     0.000 |     0.067 |     0.067 |     0.067 |     0.000 |           |
	-------------|-----------|-----------|-----------|-----------|-----------|-----------|
	          20 |         2 |         2 |         1 |         0 |         0 |         5 |
	             |     2.667 |     0.067 |     0.000 |     0.333 |     1.333 |           |
	             |     0.400 |     0.400 |     0.200 |     0.000 |     0.000 |     0.333 |
	             |     1.000 |     0.400 |     0.333 |     0.000 |     0.000 |           |
	             |     0.133 |     0.133 |     0.067 |     0.000 |     0.000 |           |
	-------------|-----------|-----------|-----------|-----------|-----------|-----------|
	          30 |         0 |         1 |         1 |         0 |         4 |         6 |
	             |     0.800 |     0.500 |     0.033 |     0.400 |     3.600 |           |
	             |     0.000 |     0.167 |     0.167 |     0.000 |     0.667 |     0.400 |
	             |     0.000 |     0.200 |     0.333 |     0.000 |     1.000 |           |
	             |     0.000 |     0.067 |     0.067 |     0.000 |     0.267 |           |
	-------------|-----------|-----------|-----------|-----------|-----------|-----------|
	          70 |         0 |         1 |         0 |         0 |         0 |         1 |
	             |     0.133 |     1.333 |     0.200 |     0.067 |     0.267 |           |
	             |     0.000 |     1.000 |     0.000 |     0.000 |     0.000 |     0.067 |
	             |     0.000 |     0.200 |     0.000 |     0.000 |     0.000 |           |
	             |     0.000 |     0.067 |     0.000 |     0.000 |     0.000 |           |
	-------------|-----------|-----------|-----------|-----------|-----------|-----------|
	Column Total |         2 |         5 |         3 |         1 |         4 |        15 |
	             |     0.133 |     0.333 |     0.200 |     0.067 |     0.267 |           |
	-------------|-----------|-----------|-----------|-----------|-----------|-----------|





문제179. 직업별로 월급의 차이가 존재하는지 이원교차표로 확인하시오
         월급 2500 을 기준으로 직업별로 각각 월급이 2500 이상인 사원과 2500 보다 적은 사원들의
	 어떻게 분포가 되어있는지 확인하시오 !

	library(data.table)
	data.table(emp$sal, emp$sal >= 2500)
	
	      V1    V2
	 1: 5000  TRUE
	 2: 2850  TRUE
	 3: 2450 FALSE
	 4: 2975  TRUE
	 5: 1250 FALSE
	 6: 1600 FALSE
	 7: 1500 FALSE
	 8:  950 FALSE
	 9: 1250 FALSE
	10: 3000  TRUE
	11:  800 FALSE
	12: 3000  TRUE
	13: 1100 FALSE
	14: 1300 FALSE
	
	CrossTable( emp$job, emp$sal>= 2500)  
	
	     emp$job |     FALSE |      TRUE | Row Total |
	-------------|-----------|-----------|-----------|
	     ANALYST |         0 |         2 |         2 |
	             |     1.286 |     2.314 |           |
	             |     0.000 |     1.000 |     0.143 |
	             |     0.000 |     0.400 |           |
	             |     0.000 |     0.143 |           |
	-------------|-----------|-----------|-----------|
	       CLERK |         4 |         0 |         4 |
	             |     0.794 |     1.429 |           |
	             |     1.000 |     0.000 |     0.286 |
	             |     0.444 |     0.000 |           |
	             |     0.286 |     0.000 |           |
	-------------|-----------|-----------|-----------|
	     MANAGER |         1 |         2 |         3 |
	             |     0.447 |     0.805 |           |
	             |     0.333 |     0.667 |     0.214 |
	             |     0.111 |     0.400 |           |
	             |     0.071 |     0.143 |           |
	-------------|-----------|-----------|-----------|
	   PRESIDENT |         0 |         1 |         1 |
	             |     0.643 |     1.157 |           |
	             |     0.000 |     1.000 |     0.071 |
	             |     0.000 |     0.200 |           |
	             |     0.000 |     0.071 |           |
	-------------|-----------|-----------|-----------|
	    SALESMAN |         4 |         0 |         4 |
	             |     0.794 |     1.429 |           |
	             |     1.000 |     0.000 |     0.286 |
	             |     0.444 |     0.000 |           |
	             |     0.286 |     0.000 |           |
	-------------|-----------|-----------|-----------|
	Column Total |         9 |         5 |        14 |
	             |     0.643 |     0.357 |           |
	-------------|-----------|-----------|-----------|






문제 180. 통계 표준화  함수 생성를 생성하시오 !

	                        x   -  μ   
	      표준화 (Z) = ---------------------
	                         표준편차
	
	 평균이 0 이고 표준편차가 1인 정규분포의 데이터로 변환

	z_standard <-  function(x) {
	    return   ((x - mean(x) ) / ( sd(x) ))
	}

	z_standard( c(55,64,77,81,90) )  # 몸무게

	[1] -1.3234328 -0.6761015  0.2589325  0.5466353  1.1939666

	scale(c(55,64,77,81,90))

	           [,1]
	[1,] -1.3234328
	[2,] -0.6761015
	[3,]  0.2589325
	[4,]  0.5466353
	[5,]  1.1939666
	attr(,"scaled:center")
	[1] 73.4
	attr(,"scaled:scale")
	[1] 13.90324

	z_standard( c(165,172,177,181,186) )  # 키

	[1] -1.38176866 -0.51816325  0.09869776  0.59218657  1.20904758








문제181. knn 알고리즘 이해하기 위해 아래의 거리를 구하는 함수를 생성하시오 !

	  knn 알고리즘이 data 와 data 사이의 거리를 구하는 알고리즘
	  거리를 구해서 가장 인접한 데이터가 나와 유사한 데이터이다.

	distance <- function(a, b) {
	    return  ( sqrt(sum((a-b)^2)) )
	}
	a=c(0,3,2)
	b=c(2,0,0)
	distance(a,b)
	
	[1] 4.123106





문제182. 아래의 파이썬 코드를 R 로 코드로 변환하시오 !
	"""
	import  csv
	file = open("d:\\emp2.csv",'r')
	emp_csv = csv.reader(file)
	a = []
	for  emp_list in emp_csv:
	    a.append(emp_list[5])
	print(a)
	"""
	
	x <- c()
	for (i in 1:length(emp$sal)) {
	    x[i] <- emp$sal[i]
	}
	x
	 [1]  800 1600 1250 2975 1250 2850 2450 3000 5000 1500 1100  950 3000
	[14] 1300 3200







문제183. 아래의 data frame 을 생성하시오 !

	  그림

	a <- data.frame('데이터'=c('A','B','C','D','E','F'),
	                'x좌표'=c(1,2,4,5,6,7),
        	        'y좌표'=c(5,6,5,2,3,1),
	                '그룹'=c(rep('A',3),rep('P',3)))
	a






문제184. 아래의 그림에서 N 과 가장 거리가 가까운 과일은 무엇인가 ?
	 점심시간 문제 카페에 R 수업 게시판에 올리세요
	
	n <- c(4,4)
	a <- data.frame('데이터'=c('A','B','C','D','E','F'),
	                'x좌표'=c(1,2,4,5,6,7),
	                'y좌표'=c(5,6,5,2,3,1),
	                '그룹'=c(rep('A',3),rep('P',3)))
	distance <- function(a, b) {
	    return  ( sqrt(sum((a-b)^2)) )
	}
	temp <- c()
	for (i in 1:nrow(a)) {
	    temp[i] <- distance(n, a[i, 2:3])
	}
	temp
	a[which.min(temp), 1]





문제 185. N 과 거리가 가까운 과일을 3개를 출력하시오 !

	n <- c(4,4)
	a <- data.frame('데이터'=c('A','B','C','D','E','F'),
	                'x좌표'=c(1,2,4,5,6,7),
	                'y좌표'=c(5,6,5,2,3,1),
	                '그룹'=c(rep('A',3),rep('P',3)))
	distance <- function(a, b) {
	    return  ( sqrt(sum((a-b)^2)) )
	}
	temp <- c()
	for (i in 1:nrow(a)) {
	    temp[i] <- distance(n, a[i, 2:3])
	}
	temp
	a[which(rank(temp)<=3), 1]






문제 186. 위에 요소 A P P 중에 가장 많은 요소인 P 를 출력하시오 !

	A A P --> A
	A P P --> P
	
	n <- c(4,4)
	a <- data.frame('데이터'=c('A','B','C','D','E','F'),
	                'x좌표'=c(1,2,4,5,6,7),
	                'y좌표'=c(5,6,5,2,3,1),
	                '그룹'=c(rep('A',3),rep('P',3)))
	distance <- function(a, b) {
	    return  ( sqrt(sum((a-b)^2)) )
	}
	temp <- c()
	for (i in 1:nrow(a)) {
	    temp[i] <- distance(n, a[i, 2:3])
	}
	a1 <- a[which(rank(temp)<=3), 4]
	a2 <- table(a1)
	names(which.max(a2))





문제 187. 유방암 데이터의 건수와 컬럼의 갯수를 확인하시오 !

	   유방암 데이터 : wisc_bc_data.csv

	wbcd <- read.csv("wisc_bc_data.csv", header = T)
	nrow(wbcd)	# 569
	ncol(wbcd)	# 32







문제 188. 유방암 데이터의 양성(B)와 악성(M)의 건수가 각각 어떻게 되는지 확인하시오 !

	wbcd <- read.csv("wisc_bc_data.csv", header = T)
	table(wbcd$diagnosis)

	  B   M
	357 212






문제 189. 유방암 데이터의 양성(B)과 악성(W)의 건수의 비율이 어떻게 되는지 확인하시오 !

	prop.table(table(wbcd$diagnosis))*100
	
	       B        M
	62.74165 37.25835






문제191. knn 알고리즘을 R 샤이니에 구현하시오 !

문제192.  위에 샤이니 코드에는 k 값을 21을 직접 셋팅했지만 다른 데이터를 넣으면 21이 아니라 달라져야
	  하므로 k 값이 책에 나온데로 입력 데이터 전체 건수의 제곱근이 들어가겠금 코드를 수정하시오 !  
	  (책 121페이지)


1. 지난시간까지 완성했던 샤이니 코드 : 그래프 + 테이블 포멧


샤이니 그래프와 테이블까지 완성한 코드_20190225.txt

2. 머신러닝 텝을 샤이니에 붙이기 위한 기본 골격 코드

0. knn 패키지 추가

#Knn
package_in("class")

1. 사이드 메뉴에 아래의 내용 추가

sidebar <-    dashboardSidebar(


    menuItem("머신러닝",
             menuSubItem('Knn',tabName = 'knn')

                                                )


2. 바디에 아래의 내용 추가


body <- dashboardBody(
  
    tabItem(tabName = "knn",
            sidebarPanel(
              uiOutput("dependents_delcol_knn"),    컬럼 삭제하는 화면
              uiOutput("dependents_selcol_knn"),    라벨 컬럼 선택하는 화면
              uiOutput("dependents_button_knn")     knn 알고리즘 수행하는
              #uiOutput("check_view_plot_knn"),    버튼 화면
              
            ),                                 컬럼삭제하면 나머지 컬럼들 표시
            mainPanel(verbatimTextOutput("submit_input_sample_knn")),
            mainPanel(verbatimTextOutput("TestTableRender_knn"),
                      style = "color:red;  font-size:12px;  font-style:italic;
                      overflow-y:scroll;  max-height: 400px;  background: ghostwhite;")
            )
                                이원 교차표 표시  
    )

3. 서버에 아래의 내용 추가


server <- function(input, output,session) {


  ## knn UI input

  output$dependents_delcol_knn <- renderUI({
    data <- dataload()
    if (is.null(data)) return(NULL)
    checkboxGroupInput(inputId  = 'in_che_delcol_knn',
                       label    = "delete colmun:",       필요없는 컬럼을
                       choices  = colnames(data),         삭제하는 코드
                       selected = 'null',
                       inline   = FALSE
    )
  })
  output$dependents_button_knn <- renderUI({
    data <- dataload()                                  knn 모델을 돌리겠금
    if (is.null(data)) return(NULL)                  action 버튼을 누르는 코드
    actionButton("in_btn_submit_knn","Submit")
  })
  output$dependents_selcol_knn <- renderUI({
    data <- dataload()                                   라벨이 어떤 컬럼인지
    if (is.null(data)) return(NULL)                      선택하는 코드
    selectInput("in_sel_label_knn","Submit",choices = colnames(data))
  })



#4. 서버에 UI output 에 아래의 내용추가


  normalize <- function(x) {
    return (( x - min(x)) / (max(x) -min(x)))
  }	
  
  
  ###############knn show, reactive
  subinput_table_knn <- eventReactive(input$in_btn_submit_knn, {
    req(input$file1)
    file1 = input$file1
    data = read.csv(file1$datapath,stringsAsFactors =FALSE)
    
    data1<-as.data.frame(lapply(data[,-which(colnames(data)==input$in_sel_label_knn)], normalize))
    
    train_index = as.integer(trunc(nrow(data1) *0.8))

    train <- data1[1:as.integer(train_index), ]
    
    test <- data1[as.integer(train_index+1):as.integer(nrow(data1)), ]
    
    train_label <-data[1:as.integer(train_index),which(colnames(data)==input$in_sel_label_knn)]

    test_label <- data[as.integer(train_index+1):as.integer(nrow(data1)),which(colnames(data)==input
$in_sel_label_knn) ]
    
    train_label <- factor(train_label )
    
    #test_label <- factor(test_label)
   
    k_val = ceiling(sqrt(length(train)))

    result <-  knn(train=train , test=test , cl=train_label, k= k_val )
  
    cross_table <- CrossTable(test_label , result, prop.chisq=FALSE )
    
    return(cross_table)
    
  })
  output$TestTableRender_knn <- renderPrint({
    subinput_table_knn()
  })
  output$submit_input_sample_knn <- renderPrint({
    req(input$file1)
    file1 = input$file1
    data <- read.csv(file1$datapath)
    data1 <- data[,!(colnames(data) %in% input$in_che_delcol_knn )]
    return(head(data1,5))
  })
  
  
}

######################### 4. 샤이니 실행 ###############################

shinyApp(ui = ui, server = server)














문제 193. 우리가 지금 만든 knn 샤이니 화면에
	  붓꽃 데이터로 knn 분류를 잘하는지 확인하시오 !

생각해야할 문제 : k 값 출력하기

                | result
     test_label |     Iris-setosa | Iris-versicolor |  Iris-virginica |       Row Total |
----------------|-----------------|-----------------|-----------------|-----------------|
    Iris-setosa |               8 |               0 |               0 |               8 |
                |           1.000 |           0.000 |           0.000 |           0.267 |
                |           1.000 |           0.000 |           0.000 |                 |
                |           0.267 |           0.000 |           0.000 |                 |
----------------|-----------------|-----------------|-----------------|-----------------|
Iris-versicolor |               0 |              11 |               1 |              12 |
                |           0.000 |           0.917 |           0.083 |           0.400 |
                |           0.000 |           1.000 |           0.091 |                 |
                |           0.000 |           0.367 |           0.033 |                 |
----------------|-----------------|-----------------|-----------------|-----------------|
 Iris-virginica |               0 |               0 |              10 |              10 |
                |           0.000 |           0.000 |           1.000 |           0.333 |
                |           0.000 |           0.000 |           0.909 |                 |
                |           0.000 |           0.000 |           0.333 |                 |
----------------|-----------------|-----------------|-----------------|-----------------|







문제194. 나이, 성별, 직업, 결혼여부, 이성친구의 여부에 따라서
         선호하는 영화 장르가 어떻게 되는지 예측하는 모델을 생성하시오!

	install.packages("e1071")
	
	library(e1071)
	
	movie <- read.csv("movie.csv", header=T)
	
	model <- naiveBayes(movie[ ,1:5], movie$장르, laplace=0)
	                       ↑           ↑
	                   훈련 데이터   훈련 데이터 라벨
	model
	
	test_data <- read.csv("n_test1.csv", header=TRUE)
	
	result <- predict(model, test_data[1:5])
	
	
	result
	
	로맨틱





문제195. 나이가 20대이고 성별이 남자이고 직업이 학생이고
         결혼 아직 안했고 이성친구가 없는 재혁이가 선호하는 영화는
         무엇이겠는지 나이브 베이즈로 예측 하시오 !







문제196. 독버섯과 정상 버섯을 예측하는 나이브 베이즈 모델을 생성하시오

	1. 버섯 데이터를 R 로 로드한다.
	
	 mushroom <- read.csv("mushrooms.csv", header=T, stringsAsFactors=TRUE)
	
	 View(mushroom)
	
	2. 8124 독버섯 데이터만 따로 빼서 mush_test.csv 로 저장한다.
	
	 mush_test <- mushroom[8123, ]
	
	 mush_test
	
	 write.csv( mush_test, "mush_test.csv",row.names=FALSE )
	
	3. 8124 독버섯 데이터를 훈련 데이터에서 제외 시키시오 !
	
	 nrow(mushroom)
	 mushrooms <- mushroom[ -8123,  ]
	 nrow(mushrooms)
	
	4. mushrooms 데이터를 훈련 데이터와 테스트 데이터로 나눈다
	    ( 훈련 데이터는 75%,  테스트 데이터는 25% )

	set.seed(1)
	dim(mushrooms)
	
	train_cnt <- round( 0.75*dim(mushrooms)[1] )
	train_cnt
	
	train_index <- sample( 1:dim(mushrooms)[1], train_cnt, replace=F)
	
	mushrooms_train <- mushrooms[ train_index,  ]
	mushrooms_test <- mushrooms[- train_index,  ]
	
	nrow(mushrooms_train)  #  6092
	nrow(mushrooms_test)    #  2031
	
	str(mushrooms_train)
	
	5. 나이브 베이즈 알고리즘으로 독버섯과 일반 버섯을 분류하는 모델을
	   생성한다.
	
	library(e1071)         모든 컬럼들
	                          ↓
	model1 <- naiveBayes(type~ . ,  data=mushrooms_train)
	                      ↑
	                   라벨 컬럼명
	
	model1
	
	6. 위에서 만든 모델과 테스트 데이터를 가지고 독버섯과 일반버섯을
	   잘 분류하는지 예측해 본다.
	
	result1 <- predict( model1, mushrooms_test[  , -1] )
	
	result1
	
	7. 이원 교차표를 그려서 최종 분류 결과를 확인한다.
	
	library(gmodels)
	
	CrossTable( mushrooms_test[  ,1], result1)
	                   ↑                ↑
	                  실제              예측
	
	
	                    | result1
	mushrooms_test[, 1] |    edible | poisonous | Row Total |
	--------------------|-----------|-----------|-----------|
	             edible |      1049 |         7 |      1056 |
	                    |   347.908 |   447.814 |           |
	                    |     0.993 |     0.007 |     0.520 |
	                    |     0.918 |     0.008 |           |
	                    |     0.516 |     0.003 |           |
	--------------------|-----------|-----------|-----------|
	          poisonous |        94 |       881 |       975 |
	                    |   376.811 |   485.017 |           |
	                    |     0.096 |     0.904 |     0.480 |
	                    |     0.082 |     0.992 |           |
	                    |     0.046 |     0.434 |           |
	--------------------|-----------|-----------|-----------|
	       Column Total |      1143 |       888 |      2031 |
	                    |     0.563 |     0.437 |           |
	--------------------|-----------|-----------|-----------|
	
	8. 위의 모델의 성능을 올리시오 !
	
	model2 <- naiveBayes(type~ . ,  data=mushrooms_train, laplace=0.0004)
	
	result2 <- predict( model2, mushrooms_test[ , -1] )
	
	CrossTable( mushrooms_test[ ,1], result2)
	
	mushrooms_test[, 1] |    edible | poisonous | Row Total |
	--------------------|-----------|-----------|-----------|
	             edible |      1050 |         6 |      1056 |
	                    |   459.814 |   496.053 |           |
	                    |     0.994 |     0.006 |     0.520 |
	                    |     0.996 |     0.006 |           |
	                    |     0.517 |     0.003 |           |
	--------------------|-----------|-----------|-----------|
	          poisonous |         4 |       971 |       975 |
	                    |   498.014 |   537.264 |           |
	                    |     0.004 |     0.996 |     0.480 |
	                    |     0.004 |     0.994 |           |
	                    |     0.002 |     0.478 |           |
	--------------------|-----------|-----------|-----------|
	       Column Total |      1054 |       977 |      2031 |
	                    |     0.519 |     0.481 |           |
	--------------------|-----------|-----------|-----------|






문제197.  위의 모델에  별도로 구분해 놓은 테스트 데이터 한개(독버섯)
          8123 번 데이터를 넣어서 독버섯인지 정상인지 확인하시오 !

	result3 <- predict( model2, mush_test )







문제198. (점심시간 문제)  set.seed(1) 을 정확히 다시 설정하고
         laplace 값을 0.0001 ~  0.0017 까지 주고 FN 값을 확인하시오 !

	   laplace     FN
	    0.0001      0
	     :         :
	     :         :






문제199. 나이브 베이즈의 알고리즘을 R 샤이니로 구현하시오 !







문제200. knn 과 나이브 베이즈 두개를 R 샤이니에 추가 시키시오 !  

그래프_테이블_KNN까지 구현한 샤이니 코드_수정본_20190225.txt
      ↑
 위의 코드에 나이브 베이즈 코드를 추가한다.  







문제201. 구매여부 데이터의 변수들 중에 정보획득량이 가장 높은게
         무엇인지 알아내시오 ! (buy2.csv)

	buy <- read.csv("buy2.csv", header=T)
	
	install.packages("FSelector")
	library(FSelector)
	
	weights <-  information.gain(buy_yn~. , buy)
	
	print(weights)
	
	cust_name          0.50040242
	card_yn            0.50040242
	review_yn          0.22314355
	before_buy_yn      0.05053431







문제202. 백화점 화장품 고객 데이터(skin.csv) 를 R 로 로드하고
         skin 데이터셋 변수들의 정보 획득량을 구하시오 !

	skin <- read.csv("skin.csv", header=T)
	skin <- skin[, -1]
	
	x <- information.gain( cupon_react ~ ., skin)
	
	x
	
	gender     0.080610238
	age        0.000000000
	job        0.013737789
	marry      0.224337222
	car    	   0.006023806
	





문제203. skin 데이터를 의사 결정 트리로 시각화 하시오 !

	install.pacakges("rpart")
	library(rpart)
	
	tree1 <- rpart( cupon_react ~ ., data=skin[ , -1],
	                 control=rpart.control(minsplit=2) )  
	
	plot( tree1, compress=T, uniform=T, margin=0.1)
	text( tree1, use.n = T, col="blue")
	





문제204. 지방간 환자들 데이터의 정보획득량을 구해서
         지방간을 일으키는데 가장 영향력이 큰 변수가 무엇인지 알아내시오 !

	fatliver <- read.csv("fatliver2.csv", header=T)
	
	library(FSelector)
	
	x <-  information.gain(FATLIVER~. , fatliver )
	
	print(x)
	
	      attr_importance
	AGE         0.022358781
	GENDER      0.019859086
	DRINK       0.008449112
	SMOKING     0.006801213





문제205. 심장질환 데이터를 내려받고 심장질환에 있어 가장 영향력이 큰
         변수가 무엇인지 정보 획득량을 구해서 알아내시오 !






문제206. (오늘의 마지막 문제)  기업이 부도가 나는데 가장 크게 영향을
         미치는 요소가 무엇인지 부도 예측 데이터의 정보 획득량을 구해서
         알아내시오 !  ( 카페에 뎃글로 올리세요 ~)

	bankrupt <- read.csv("부도예측데이터3.csv", header=F)
	
	x <- information.gain(V1~., bankrupt)
	
	 0 : 부도
	 1 : 건전

	colnames(bankrupt) <- c("class","매출액","자기자본","총자본투자효율","부가가치율","매출액증가율","재고자산
증가율","총자산증가율","금융비용대매출액비율","대출효율성계수","매출액순이익률","매출원가율","손익분기점율","순금융
비용대매출액비율","이자보상배율","자기자본순이익률","총자본경상이익률","총자본순이익률","고정장기적합율의역","단기
부채대총차입금","당좌비율","매출채권대매입채무","순운전자본비율","유동비율","유동부채대총자본","유보액대총자산비율"
,"자기자본비율","차입금의존도","총차입금대매출액","금융비용부담율증가분","매입채무회전율","순운전자본대매출액","운
전자금대매출액","재고자산회전율","총자본회전율","현금흐름지표(1)","현금흐름지표(2)","현금흐름지표(3)","현금흐름지표
(4)","현금흐름지표(5)","현금흐름지표(6)","현금흐름지표(7)","현금흐름지표(8)","현금흐름지표(9)" )






문제 207. 위 의사결정 트리의 성능을 높이시오 !

	library(C50)
	skin_model <- C5.0(skin2_train[, -6], skin2_train$cupon_react, trials = 6)
	skin2_result <- predict(skin_model, skin2_test[ , -6])
	
	library(gmodels)
	CrossTable(skin2_test[, 6], skin2_result)





문제 208. 아까 위에서 한건 뺀 고객 데이터 (skin_real_test_cust)이 쿠폰 반응이 있는 고객인지 아닌지 잘
	  맞추는지 확인하시오 !

	predict(skin_model, skin_real_test_cust)
	
	[1] YES
	Levels: NO YES






문제 209. 부스팅 기법을 이용해서 위의 의사결정트리 모델의 정확도를 올리시오 !

	credit_model <- C5.0(credit_train[, -17], credit_train[, 17], trial = 63)
	credit_result <- predict(credit_model, credit_test[, -17])
	library(gmodels)
	CrossTable(credit_test[, 17], credit_result)




문제 210. 의사 결정 트리 알고리즘을 R 샤이니에 붙이시오 !





문제 211. 근무하고 있는 사원중에 퇴사가 예상되는 사원이 누구인지 알아내는 의사결정 트리 모델을
	  생성하시오 !  (hr.csv 데이터를 활용)






문제 213. 챌린져호의 폭파원인 데이터를 R로 로드하고 x축을 온도로 하고 y축을 o형링 파손수로 해서
	  R샤이니에 plot그래프를 그리시오 !





문제 214. 챌린저 호의 폭파 원인을 분석하기 위한 회귀 직선의 기울기를 R로 알아내시오 !

	x축 : temprature, y축 : distress_ct
	  cov(x, y)
	= ───── = 기울기
	    var(x)

	기울기 : -0.04753968

	공분산의 뜻 ? 서로 다른 변수들 사이에 얼마나 의존하는지를 수치적으로 표현한 것





	y = αx + β
	
	#수동으로 a(기울기)를 추정
	
	a <- cov(launch$temprature, launch$distress_ct) / var(launch$temprature)
	
	#수동으로 b(절편)을 추정
	
	y = ax + b
	    ↓
	b = y - ax
	
	b <- mean( launch$distress_ct) - a*mean(launch$temprature)
	b = 3.698414
	
		y = -0.04754 x + 3.698414  <--- 회귀직선 식






문제 215. 위의 손으로 구한 기울기와 절편을 R에서 제공하는 회귀함수인 lm을 이용해서 구해보시오 !

	launch <- read.csv("challenger.csv")
	
	attach(launch)
	
	lm(distress_ct ~ temperature, launch)
	       ↑	      ↑
	       y축            x축



문제 216. 책 251 페이지에 나오는 plot그래프를 그리시오

	x축 : 온도
	y축 : o형링 파손수
	
	공식 : plot( y축 ~ x축 , data = 데이터셋 이름 )
	
	답 : plot( distress_ct ~ temperature, data=launch, col='blue')



문제 217. 위의 plot그래프의 data에 맞는 회귀직선을 그리시오

	m <- lm( distress_ct ~ temperature, launch)
	
	abline(m, col="red")




문제 218. 위의 그래프에 제목에 회귀직선의 방정식이 출력되게 하시오!

	힌트 : a = c(1, 5, 9, 2, 6, 10, 3, 7, 11, 4, 8, 12)

	y <- a+-0.04754 + 3.69841
	y

	plot( distress_ct ~ temperature, data=launch, col='blue')
	m <- lm( distress_ct ~ temperature, launch)
	abline(m, col="red")
	title(paste('파손수=', m$coefficients[1], "* tannin + ", m$coefficients[2]))




문제 219. 애벌레의 성장 추이와 탄닌과의 관계가 어떻게 되는지 탄닌 포함량이 많을 수록 애벌레의 성장이
	  증가하는지 감소하는지를 나타내는 회귀방정식을 구하고 시각화 하시오 ! (데이터 : regression.txt)

	reg <- read.table("regression.txt", header = T)
	plot( growth ~ tannin, data=reg, col='blue')
	m <- lm(growth ~ tannin, reg)
	abline(m, col="red")
	title(paste('growth=', round(m$coefficients[1], 4), "* tannin + ",
	      round(m$coefficients[2], 4)))





문제 220. 위의 그래프에 잔차를 그리시오 !

	reg <- read.table("regression.txt", header = T)
	attach(reg)
	plot( growth ~ tannin, data=reg, col='blue')
	m <- lm(growth ~ tannin, reg)
	abline(m, col="red")
	title(paste('growth=', round(m$coefficients[1], 4), "* tannin + ", round(m$coefficients[2], 4)))
	join <- function(i){
	    lines(c(tannin[i], tannin[i]), c(growth[i], m$coefficients[2]*tannin[i]+m$coefficients[1]),
		  col = "green")}
	sapply(1:9, join)






문제 221. 코스피 지수 수익율과 삼성전자와 현대자동차 수익율을 가지고 plot그래프를 그리시오 !

	k_index <- read.csv("K_index.csv", header = T)
	h_stock <- read.csv("h_stock.csv", header = T)
	s_stock <- read.csv("s_stock.csv", header = T)
	head(k_index)
	head(h_stock)
	head(s_stock)
	all_data <- merge(merge(k_index,s_stock), h_stock)
	head(all_data)
	attach(all_data)
	plot(k_rate, s_rate, col = "blue")
	plot(k_rate, h_rate, col = "red")




문제 222. 코스피 등락 비율과 삼성 수익율 등락 비율을 plot그래프로 그리고 그 그래프에 회귀직선을 그으시오 !

	plot(k_rate, s_rate, col = "blue")
	models <-lm(s_rate~k_rate, all_data)
	abline(models, col = "red")





문제 223. 현대자동차도 마찬가지로 회귀그래프를 만드시오 !

	plot(k_rate, h_rate, col = "blue")
	models <-lm(h_rate~k_rate, all_data)
	abline(models, col = "red")




문제 224. 현대자동차와 삼성전자 그래프를 하나의 화면으로 출력되게 하시오 !

	graphics.off()
	par(mfrow = c(1,2), new = T)
	par(mar = c(2,2,2,2))
	plot(k_rate, s_rate, col = "blue")
	models <-lm(s_rate~k_rate, all_data)
	abline(models, col = "red")
	title("삼성")
	plot(k_rate, h_rate, col = "blue")
	modelh <-lm(h_rate~k_rate, all_data)
	abline(modelh, col = "red")
	title("현대")

		회귀 모수중 기울기가 1보다 크면 공격적 주식이고 1보다 작으면 방어적 주식이다.




문제 225. 아래의 두개의 그래프에 회귀 기울기가 각각 제목으로 출력되게 하시오 !

	graphics.off()
	par(mfrow = c(1,2), new = T)
	par(mar = c(2,2,2,2))
	plot(k_rate, s_rate, col = "blue")
	models <-lm(s_rate~k_rate, all_data)
	abline(models, col = "red")
	title(paste("y = ",round(models$coefficients[2], 3), "x +", round(models$coefficients[1],3)))
	plot(k_rate, h_rate, col = "blue")
	modelh <-lm(h_rate~k_rate, all_data)
	abline(modelh, col = "red")
	title(paste("y = ",round(modelh$coefficients[2], 4), "x +", round(modelh$coefficients[1],4)))




문제 226. 삼성전자와 현대전자의 삼성 수익율 등락비울이 각각 코스피 등락율과 상관관계가 어떻게 되는지
	  출력하시오 즉 둘중에 코스피 등락율과 더 상관관계가 높은 주식이 어떤건지 알아내시오 !

	attach(all_data)
	cor(na.omit(k_rate), na.omit(s_rate))   # [1] 0.5142455
	cor(na.omit(k_rate), na.omit(h_rate))   # [1] 0.3262777

		주식 시장에서의 상관계수는 시장과 해당 종목이 얼마나 비슷하게 움직이고 있느냐를 찾는
		것이다.
		현업에서는 0.65 ~ 0.70 위부터 가치가 있다고 판단하고 투자분석을 한다.






문제 227. 아래의 행렬을 R로 만드시오 !

	a <- matrix(c(1:9), nrow=3, ncol=3, byrow = T)
	a




문제 228. 아래의 행렬을 만드시오 !

	b <- matrix(c(1:9), nrow=3, ncol=3, byrow = F)
	b




문제 229. a 행렬과 b 행렬의 곱을 출력하시오 !

	a%*%b




문제 230. a 행렬의 전치행렬을 구하시오 !

	a
	t(a)




문제 231. 아래의 c행렬을 만들고 c행렬의 역행렬을 구하시오 !

	c <- matrix(c(1:4), nrow = 2, ncol = 2, byrow = T)
	solve(c)




문제 232. 위의 회귀모수인 α와 β를 구하는 함수를 생성하시오 ! (책 260페이지의 reg라는 함수)

	reg <- function(y, x) {
	    x <- as.matrix(x)
	    x<- cbind(intercept = 1, x)
	    b <- solve(t(x)%*%x)%*%t(x)%*%y
	    colnames(b) <- "estimate"
	    return(b)
	}
	reg(y = launch$distress_ct, x=launch$temperature)






문제 235. 의료비 데이터(insurance.csv)에서 다중공선성을 보이는 변수가 있는지 조사하시오 !
	  (팽창계수가 10보다 큰 변수가 있는지 확인하시오 !)

	insurance <- read.csv("insurance.csv", header=T)
	summary(insurance)
	lmfit <- lm(expenses~., data = insurance)
	summary(lmfit)
	vif(lmfit)
	vif(lmfit) > 10

	          GVIF    Df GVIF^(1/(2*Df))
	age      FALSE FALSE           FALSE
	sex      FALSE FALSE           FALSE
	bmi      FALSE FALSE           FALSE
	children FALSE FALSE           FALSE
	smoker   FALSE FALSE           FALSE
	region   FALSE FALSE           FALSE

		설명 : 의료비 데이터에서는 다중공선성을 보이는 변수는 없는것으로 확인이 되었다.






	6. 회귀 함수인 lm을 이용해서 위의 독립변수들의 회귀모수를 확인한다 (기울기)

		ins_model <- lm(expenses~., data=insurance)
		ins_model
	
		Call:
		lm(formula = expenses ~ ., data = insurance)
		
		Coefficients:
		    (Intercept)              age          sexmale  
		       -11941.6            256.8           -131.4  
		            bmi         children        smokeryes  
		          339.3            475.7          23847.5  
		regionnorthwest  regionsoutheast  regionsouthwest  
		         -352.8          -1035.6           -959.3
		북동	   북서		    남동	     남서
		(기준)
		북동 지역의 평균 비용이 가장 높은 경향이 있음을 의미한다.

		설명 :
		  1. 모델 수식에는 특징을 여섯개만 명시했지만 보고된 계수는 절편이외에 여덣개를 보고
		     하고 있다.
		     이렇게 된 이유는 lm() 함수가 더미코딩 기법을 모델팩터 타입 변수에 자동으로
		     적용했기 때문이다.
	
		  2. 나이가 일년씩 더해질 때마다 평균적으로 의료비가 256.80 달러 정도 높아질 것으로
	 	     예상한다.

		  3. 부양 가족수가 한명 늘어날 때 마다 의료비가 평균적으로 475.7 달러 정도 추가되는
		     것을 예상하고 있다.

		  4. BMI 단위가 증가할 때 마다 연간 의료비가 평균 339.30 달러 증가될 것으로 예상하고
		     있다.

		  5. 흡연자는 비흡연자보다 매년 평균 23847.50 달러의 비용이 더 들것으로 예상하고 있다.

		  6. 남성은 여성에 비해 매년 의료비가 131.40 달러 적게 들것으로 예상하고 있다.




문제 236. 비만인 사람이 흡연까지 했을 때 좀더 높은 패널티를 부여하려면, 즉 보험료를 인상시키려면 어떻게
	  모델을 만들어야 하는가?

	insurance$bmi30 <- ifelse(insurance$bmi>=30, 1, 0)
	ins_model <- lm(expenses~ age+sex+bmi+children+bmi30*smoker, data = insurance)
	ins_model

	Call:
	lm(formula = expenses ~ age + sex + bmi + children + bmi30 *
	    smoker + region, data = insurance)
	
	Coefficients:
	    (Intercept)              age          sexmale  
	        -4740.7            263.2           -491.1  
	            bmi         children            bmi30  
	          114.8            520.5           -863.3  
	      smokeryes  regionnorthwest  regionsoutheast  
	        13402.3           -266.8           -824.6  
	regionsouthwest  bmi30:smokeryes  
	        -1223.9          19794.3

	설명 :
	    smokeryes는 13402로 예상하는데 bmi30:smokeryes는 19794달러로 예상하고 있어서 비만이면서
	    흡연을 하는 사람이 더 많은 의료비가 예상이 되고 있다.
	    따라서 흡연이 비만과 관련된 질병을 더 악화시킨다는 것을 말한다.






문제 237. 스마트폰 만족감(종속변수)에 영향을 미치는 요소들(독립변수) 중에서 가장 영향도가 높은 것이
	  무엇인지 알아내시오 !

	multi_hg <- read.csv("multi_hg.csv", header = T)
	head(multi_hg)
	model <- lm(만족감~., data = multi_hg)
	model





문제 237. 스마트폰 만족감(종속변수)에 영향을 미치는 요소들(독립변수) 중에서 가장 영향도가 높은 것이
	  무엇인지 알아내시오 !

	reg <- function(y, x) {
	    x <- as.matrix(x)
	    x<- cbind(intercept = 1, x)
	    b <- solve(t(x)%*%x)%*%t(x)%*%y
	    colnames(b) <- "estimate"
	    return(b)
	}
	reg(y=multi_hg$만족감, x=multi_hg[1:3])
	
	multi_hg <- read.csv("multi_hg.csv", header = T)
	head(multi_hg)
	model <- lm(만족감~., data = multi_hg)
	summary(model)

	Call:
	lm(formula = 만족감 ~ ., data = multi_hg)
	
	Residuals:
	    Min      1Q  Median      3Q     Max
	-0.9565 -0.4136 -0.1178  0.3998  1.7643
	
	Coefficients:
	            Estimate Std. Error t value Pr(>|t|)    
	(Intercept)  3.51360    0.07001  50.185  < 2e-16 ***
	외관         0.26943    0.07471   3.606 0.000553 ***
	편의성       0.21052    0.07488   2.812 0.006269 **
	유용성       0.16232    0.07633   2.127 0.036707 *  
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
	
	Residual standard error: 0.6159 on 76 degrees of freedom
	Multiple R-squared:  0.3732,	Adjusted R-squared:  0.3485
	F-statistic: 15.08 on 3 and 76 DF,  p-value: 8.555e-08

	설명 : 스마트폰 만족감에는 외관에 가장 영향력이 높은 변수라는 것을 예측할 수 있다.

	



문제 238. 미국 대학 입학에 가장 영향을 크게 미치는 요소를 알아내시오 !

	sports <- read.csv("sports.csv", header = T)
	head(sports)
	model <- lm(acceptance ~ academic + sports + music, data = sports)
	summary(model)

	Call:
	lm(formula = acceptance ~ academic + sports + music, data = sports)
	
	Residuals:
	    Min      1Q  Median      3Q     Max
	-29.179  -2.454   1.226   4.130   9.558
	
	Coefficients:
	             Estimate Std. Error t value Pr(>|t|)    
	(Intercept) 11.490280   1.052578  10.916  < 2e-16 ***
	academic     0.155774   0.005796  26.877  < 2e-16 ***
	sports       0.572686   0.039688  14.430  < 2e-16 ***
	music        0.104601   0.023427   4.465 1.35e-05 ***
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
	
	Residual standard error: 5.948 on 196 degrees of freedom
	Multiple R-squared:  0.9067,	Adjusted R-squared:  0.9053
	F-statistic: 634.8 on 3 and 196 DF,  p-value: < 2.2e-16






문제 239. (점심시간 문제) 의료비 데이터 회귀 모델의 성능(R제곱값)이 75%의 설명력을 높이기 위해 책
	  278페이지에 나오는 파생변수인 age2가 이 회귀 모델의 설명력을 높이는지 확인하시오 !

	기존 설명력
	Multiple R-squared:  0.7509,	Adjusted R-squared:  0.7494

	insurance <- read.csv("insurance.csv", header=T)
	insurance$age2 <- insurance$age**2
	head(insurance)
	ins_model <- lm(expenses~ age+age2+sex+bmi+children+smoker+region, data = insurance)
	summary(ins_model)

	Multiple R-squared:  0.7537,	Adjusted R-squared:  0.7521






문제 240. 의료비 데이터를 정규화 한후에 회귀 계수를 정규화 하지 않았을 때의 회귀계수와 비교하시오 !
	정규화 안했을 때 :
		insurance <- read.csv("insurance.csv", header=T)
		summary(insurance)
		lmfit <- lm(expenses~., data = insurance)
		summary(lmfit)

		Call:
		lm(formula = expenses ~ ., data = insurance)
		
		Residuals:
		     Min       1Q   Median       3Q      Max
		-11302.7  -2850.9   -979.6   1383.9  29981.7
		
		Coefficients:
		                Estimate Std. Error t value Pr(>|t|)    
		(Intercept)     -11941.6      987.8 -12.089  < 2e-16 ***
		age                256.8       11.9  21.586  < 2e-16 ***
		sexmale           -131.3      332.9  -0.395 0.693255    
		bmi                339.3       28.6  11.864  < 2e-16 ***
		children           475.7      137.8   3.452 0.000574 ***
		smokeryes        23847.5      413.1  57.723  < 2e-16 ***
		regionnorthwest   -352.8      476.3  -0.741 0.458976    
		regionsoutheast  -1035.6      478.7  -2.163 0.030685 *  
		regionsouthwest   -959.3      477.9  -2.007 0.044921 *  
		---
		Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
		
		Residual standard error: 6062 on 1329 degrees of freedom
		Multiple R-squared:  0.7509,	Adjusted R-squared:  0.7494
		F-statistic: 500.9 on 8 and 1329 DF,  p-value: < 2.2e-16
		
	정규화 했을 때 :
		normalize <-  function(x) {
		    return   ((x - min(x) ) / ( max(x) - min(x) ))
		}
		insurance <- read.csv("insurance.csv", header=T)
		head(insurance)
		insurance_temp <- as.data.frame(lapply(insurance[, c(1, 3, 4, 7)], normalize))
		insurance_n <- cbind(insurance_temp, insurance[, c(2, 5, 6)])
		model_n <- lm(expenses~., data = insurance_n)
		summary(model_n)

		Call:
		lm(formula = expenses ~ ., data = insurance_n)
		
			Residuals:
		     Min       1Q   Median       3Q      Max
		-0.18041 -0.04551 -0.01564  0.02209  0.47857
		
		Coefficients:
		                 Estimate Std. Error t value Pr(>|t|)    
		(Intercept)     -0.048073   0.009359  -5.137 3.21e-07 ***
		age              0.188585   0.008737  21.586  < 2e-16 ***
		bmi              0.200925   0.016936  11.864  < 2e-16 ***
		children         0.037965   0.010998   3.452 0.000574 ***
		sexmale         -0.002097   0.005314  -0.395 0.693255    
		smokeryes        0.380655   0.006595  57.723  < 2e-16 ***
		regionnorthwest -0.005631   0.007602  -0.741 0.458976    
		regionsoutheast -0.016530   0.007641  -2.163 0.030685 *  
		regionsouthwest -0.015312   0.007628  -2.007 0.044921 *  
		---
			Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
		
		Residual standard error: 0.09676 on 1329 degrees of freedom
		Multiple R-squared:  0.7509,	Adjusted R-squared:  0.7494
		F-statistic: 500.9 on 8 and 1329 DF,  p-value: < 2.2e-16






문제 241. 보스턴 하우징 데이터(보스턴 지역의 집값) 을 이용해서 회귀트리 모델을 생성하시오 !
	  범죄율, 방의 갯수, 지역의 학교교사의 숫자, 강과 인접한 거리등의 데이터를 확인해서 회귀트리
	  생성
	  (라벨 : MEDV(집값), cat.NEDV(주택가격이 3만달러가 넘는지 안넘는지에 대한 라벨))

	# 데이터를 로드한다.
	boston <- read.csv("D:/data/boston.csv")
	
	# 본래 데이터의 최소값, 최대값 비교
	summary(boston$MEDV)
	
	
	# 훈련과 테스트 데이터 생성
	boston_train <- boston[1:495, ]
	boston_test <- boston[496:506, ]
	
	str(boston_train)
	
	# 회귀트리 모델을 생성한다.
	
	model <-  rpart( MEDV ~ . , data=boston_train)
	
	model
	
	# 생성된 모델과 테스트 데이터로 예측한다.
	
	result <- predict(model, boston_test)
	
	# 결과와 실제 테스트 라벨과의 상관정도를 확인한다.
	
	cor(result, boston_test$MEDV)
	
	0.2808209
	
	# 결과와 실제 테스트 라벨과의 평균절대오차를 확인한다.
	
	MAE <-  function( actual, predicted) {
	  mean(  abs( actual - predicted) )
	}
	
	MAE( result, boston_test$MEDV)
	
	 3.484211
	
	# 이번에는 보스톤 하우징 데이터를 모델트리로 구현해서 성능을
	  높여본다.
	
	library(RWeka)
	
	m.m5p <- M5P(MEDV ~ . , data=boston_train)
	
	p.m5p <- predict( m.m5p, boston_test)

	cor( p.m5p , boston_test$MEDV )
	
	0.506185
	
	MAE( boston_test$MEDV, p.m5p)
	
	2.869352
	




문제 241. (점심시간 문제) R 샤이니 최종 코드에 다중회귀 메뉴를 추가하시오 !
	  왓슨 메인화면 ─▶ 의사결정 트리,





문제 242. R로 relu함수를 만들고 relu 함수 그래프를 그리시오

	파이썬 코드 :
	
		import  numpy  as  np
		
		def  relu(x):
		    return  np.maximum(0,x)  # 0 과 x 값중에 큰값을 출력해라 !
		
		print (relu(-2))
		print (relu(0.3))

	R코드 :

		relu <- function(x) { ifelse( x>0 , x, 0 ) }
		
		x <- seq(-10, 10, 0.01)
		
		plot( x, relu(x), col = "red")




문제 243. 계단함수를 R로 구현하고 계단함수 그래프를 그리시오.

	* 계단함수 f(0.3) = 1, f(-0.2) = 0

                    0을 임계치로 해서 임계치 이상이면 1 아니면 0을 출력하는 함수로 생성하세요


	step <- function(x) { ifelse( x>=0, 1, 0 ) }
	
	x <- seq( -5, 5, 0.01)
	
	plot( x, step(x), col = "blue", type='l')




문제244. R 로 시그모이드 함수를 생성하고 그래프로 시각화 하시오 !

	파이썬 :

		x = np.arange(-5,5,0.1)
		print (x)
	
		def  sigmoid(x):
		    return 1 / (1 + np.exp(-x) )
		
		y = sigmoid(x)
	
	R 코드 :

		sigmoid <- function(x) { ifelse( 1 / (1 + exp(-x))) }
		
		x <- seq( -5, 5, 0.01)





문제 245. 위의 신경망의 뉴런수를 늘려서 1개 못맞춘것도 맞추는지 100%의 정확도가 될 수 있도록 성능을
	  높이시오 (오늘의 마지막 문제)

	library(nnet)
	wine <- read.csv("wine.csv")
	head(wine)
	str(wine)
	wine_norm <- cbind(wine[1], scale(wine[-1]) )
	size <- nrow(wine_norm)
	size
	summary(wine_norm)
	set.seed(100)
	index <- c( sample(1:size, size *0.7) )
	index
	train <- wine_norm[index, ]
	test  <- wine_norm[-index, ]
	test
	wine_model <- nnet(Type ~ ., data = train, size=10,
	                   decay=5e-04 , maxit=200 )  
	predicted_result2 <- predict(wine_model, test, type = 'class')
	
	predicted_result2
	actual <- test$Type
	table(actual, predicted_result2)
	
	model.confusion.matrix <- table(actual, predicted_result2)
	
	library(gmodels)
	CrossTable(model.confusion.matrix)

	             | predicted_result2
	      actual |        t1 |        t2 |        t3 | Row Total |
	-------------|-----------|-----------|-----------|-----------|
	          t1 |        20 |         0 |         0 |        20 |
	             |    21.407 |     7.778 |     4.815 |           |
	             |     1.000 |     0.000 |     0.000 |     0.370 |
	             |     1.000 |     0.000 |     0.000 |           |
	             |     0.370 |     0.000 |     0.000 |           |
	-------------|-----------|-----------|-----------|-----------|
	          t2 |         0 |        21 |         0 |        21 |
	             |     7.778 |    20.167 |     5.056 |           |
	             |     0.000 |     1.000 |     0.000 |     0.389 |
	             |     0.000 |     1.000 |     0.000 |           |
	             |     0.000 |     0.389 |     0.000 |           |
	-------------|-----------|-----------|-----------|-----------|
	          t3 |         0 |         0 |        13 |        13 |
	             |     4.815 |     5.056 |    31.130 |           |
	             |     0.000 |     0.000 |     1.000 |     0.241 |
	             |     0.000 |     0.000 |     1.000 |           |
	             |     0.000 |     0.000 |     0.241 |           |
	-------------|-----------|-----------|-----------|-----------|
	Column Total |        20 |        21 |        13 |        54 |
	             |     0.370 |     0.389 |     0.241 |           |
	-------------|-----------|-----------|-----------|-----------|





문제246. nnet 패키지 신경망에 mnist 필기체 데이터를 넣고
         정확도를 확인하시오 !

	setwd("d:\\data")
	
	drat:::addRepo("dmlc")
	
	cran <- getOption("repos")
	
	cran["dmlc"] <- "https://s3-us-west-2.amazonaws.com/apache-mxnet/R/CRAN/"
	
	options(repos = cran)
	
	install.packages("mxnet",dependencies = T)
	
	library(mxnet)
	
	train<-read.csv('short_prac_train.csv')
	
	test<-read.csv('short_prac_test.csv')
	
	
	train<-data.matrix(train)  # 행렬 형태로 변환한다.
	
	test<-data.matrix(test)    # 행렬 형태로 변환한다.
	
	train.x<-train[,-1]  # 훈련 데이터
	
	train.y<-train[,1]   # 훈련 데이터의 라벨
	
	train.x<-t(train.x/255)  # 훈련데이터를 정규화
	
	test_org<-test   # test 원본 데이터
	
	test<-test[,-1]  # test 데이터의 라벨
	
	test<-t(test/255)  # 정규화한 테스트 데이터
	
	
	# Deep NN
	
	data <- mx.symbol.Variable("data")  # data 라는 변수 생성
	
	fc1 <- mx.symbol.FullyConnected(data, name="fc1", num_hidden=128) # 1층
	
	act1 <- mx.symbol.Activation(fc1, name="relu1", act_type="relu") # relu함수
	
	fc2 <- mx.symbol.FullyConnected(act1, name="fc2", num_hidden=64) # 2층
	
	act2 <- mx.symbol.Activation(fc2, name="relu2", act_type="relu") # relu함수
	
	fc3 <- mx.symbol.FullyConnected(act2, name="fc3", num_hidden=10) # 3층
	
	softmax <- mx.symbol.SoftmaxOutput(fc3, name="sm") # 소프트 맥스 함수
	
	devices <- mx.cpu() # cpu 사용  
	
	mx.set.seed(0)
	
	model <- mx.model.FeedForward.create(softmax, X=train.x, y=train.y,                                    
	                                     ctx=devices, num.round=10,                                      	
array.batch.size=100,
	                                     
	                                     learning.rate=0.07, momentum=0.9,                                      
	  eval.metric=mx.metric.accuracy,                                     
	                                     initializer=mx.init.uniform(0.07),
	                                     
	                 epoch.end.callback=mx.callback.log.train.metric(100))
	
	preds <- predict(model, test)
	
	pred.label <- max.col(t(preds)) - 1
	
	table(test_org[,1],pred.label)
	
	sum(diag(table(test_org[,1],pred.label)))/1000  # 정확도 확인
	
	> pred.label <- max.col(t(preds)) - 1
	>
	> table(test_org[,1],pred.label)
	
	   pred.label
	     0  1  2  3  4  5  6  7  8  9
	  0 94  0  0  0  0  1  1  2  1  1
	  1  0 97  1  0  0  0  0  1  1  0
	  2  0  0 98  0  1  0  0  1  0  0
	  3  0  0  1 95  0  2  0  0  0  2
	  4  0  1  0  0 90  0  1  2  0  6
	  5  0  0  0  3  0 94  1  0  1  1
	  6  2  0  0  0  0  2 96  0  0  0
	  7  0  0  0  0  1  0  0 98  0  1
	  8  0  0  1  1  0  3  1  0 94  0
	  9  0  0  0  0  2  1  0  8  0 89
	>
	> sum(diag(table(test_org[,1],pred.label)))/1000
	[1] 0.945
	>






문제246. 위의 신경망을 3층 신경망인데 4층 신경망으로 늘리면 정확도가
         더 올라가는지 확인하시오 !


	setwd("d:\\data")
	
	drat:::addRepo("dmlc")
	
	cran <- getOption("repos")
	
	cran["dmlc"] <- "https://s3-us-west-2.amazonaws.com/apache-mxnet/R/CRAN/"
	
	options(repos = cran)
	
	#install.packages("mxnet",dependencies = T)
	
	library(mxnet)
	
	
	train<-read.csv('short_prac_train.csv')
	
	test<-read.csv('short_prac_test.csv')
	

	train<-data.matrix(train)
	
	test<-data.matrix(test)
	
	train.x<-train[,-1]
	
	train.y<-train[,1]
	
	train.x<-t(train.x/255)
	
	test_org<-test
	
	test<-test[,-1]
	
	test<-t(test/255)
	

	# Deep NN
	
	data <- mx.symbol.Variable("data")
	
	fc1 <- mx.symbol.FullyConnected(data, name="fc1", num_hidden=128)
	
	act1 <- mx.symbol.Activation(fc1, name="relu1", act_type="relu")
	
	fc2 <- mx.symbol.FullyConnected(act1, name="fc2", num_hidden=64)
	
	act2 <- mx.symbol.Activation(fc2, name="relu2", act_type="relu")
	
	fc3 <- mx.symbol.FullyConnected(act2, name="fc3", num_hidden=64)
	
	act3 <- mx.symbol.Activation(fc3, name="relu2", act_type="relu")
	
	fc4 <- mx.symbol.FullyConnected(act3, name="fc4", num_hidden=10)
	
	
	softmax <- mx.symbol.SoftmaxOutput(fc4, name="sm")
	
	devices <- mx.cpu()
	
	mx.set.seed(0)
	
	model <- mx.model.FeedForward.create(softmax, X=train.x, y=train.y,
	                                     
	                                     ctx=devices, num.round=10, array.batch.size=100,
	                                     
	                                     learning.rate=0.07, momentum=0.9,  eval.metric=mx.metric.accuracy,
	                                     
	                                     initializer=mx.init.uniform(0.07),
	                                     
	                                     epoch.end.callback=mx.callback.log.train.metric(100))
	
	
	
	
	preds <- predict(model, test)
	
	pred.label <- max.col(t(preds)) - 1
	
	table(test_org[,1],pred.label)
	
	sum(diag(table(test_org[,1],pred.label)))/1000








문제247. R 로 CNN 을 구현해서 필기체 데이터의 정확도를 올리시오 !

	setwd("d:\\data")
	
	drat:::addRepo("dmlc")
	
	cran <- getOption("repos")
	
	cran["dmlc"] <- "https://s3-us-west-2.amazonaws.com/apache-mxnet/R/CRAN/"
	
	options(repos = cran)
	
	#install.packages("mxnet",dependencies = T)
	
	library(mxnet)
	
	
	train<-read.csv('short_prac_train.csv')
	
	test<-read.csv('short_prac_test.csv')
	
	train<-data.matrix(train)
	
	test<-data.matrix(test)
	
	train.x<-train[,-1]
	
	train.y<-train[,1]
	
	train.x<-t(train.x/255)
	
	test_org<-test
	
	test<-test[,-1]
	
	test<-t(test/255)
	
		
	# Convolutional NN
	data <- mx.symbol.Variable('data')
	
	# first conv
	conv1 <- mx.symbol.Convolution(data=data, kernel=c(5,5), num_filter=20)
	tanh1 <- mx.symbol.Activation(data=conv1, act_type="tanh")
	pool1 <- mx.symbol.Pooling(data=tanh1, pool_type="max", kernel=c(2,2), stride=c(2,2))
	
	# second conv
	conv2 <- mx.symbol.Convolution(data=pool1, kernel=c(5,5), num_filter=50)
	tanh2 <- mx.symbol.Activation(data=conv2, act_type="tanh")
	pool2 <- mx.symbol.Pooling(data=tanh2, pool_type="max", kernel=c(2,2), stride=c(2,2))
	
	# first fullc
	flatten <- mx.symbol.Flatten(data=pool2)
	fc1 <- mx.symbol.FullyConnected(data=flatten, num_hidden=500)
	tanh3 <- mx.symbol.Activation(data=fc1, act_type="tanh")
	
	
	# second fullc
	fc2 <- mx.symbol.FullyConnected(data=tanh3, num_hidden=10)
	
	# loss
	lenet <- mx.symbol.SoftmaxOutput(data=fc2)	
	train.array <- train.x
	dim(train.array) <- c(28, 28, 1, ncol(train.x))
	test.array <- test
	dim(test.array) <- c(28, 28, 1, ncol(test))
	mx.set.seed(0)
	tic <- proc.time()
	device.cpu <- mx.cpu()
	
	model <- mx.model.FeedForward.create(lenet, X=train.array, y=train.y,
	                                     ctx=device.cpu, num.round=20, array.batch.size=100,
	                                     learning.rate=0.05, momentum=0.9, wd=0.00001,
	                                     eval.metric=mx.metric.accuracy,
	                                     epoch.end.callback=mx.callback.log.train.metric(100))
	
	preds <- predict(model, test)
	
	pred.label <- max.col(t(preds)) - 1
	
	table(test_org[,1],pred.label)
	
	sum(diag(table(test_org[,1],pred.label)))/1000






문제248. 회귀트리와 모델트리로 보스톤 집값을 예측하는 모델을 만들었을때
         최종 상관정도 0.50 이었는데 신경망이 이 상관정도를 더 높일수
         있는지 테스트 하시오 !

	cor( p.m5p , boston_test$MEDV )
	
	0.506185
	
	답:
	
	#데이터 읽기와 구조 확인
	
	boston<-read.csv("boston.csv")
	
	str(boston)
	
	head(boston)
	
	
	# 정규화 함수
	
	normalize <- function(x) {  
	
	return((x - min(x)) / (max(x) - min(x)))
	
	}
	
	
	# 전체 데이터 프레임에 정규화 적용
	
	boston_norm <- as.data.frame(lapply(boston, normalize))
	
	# 0과1 사이에 범위 확인
	
	summary(boston_norm$MEDV)
	
	
	# 본래 데이터의 최소값, 최대값 비교
	
	summary(boston$MEDV)
	
	
	# 훈련과 테스트 데이터 생성
	
	
	
	dim(boston_norm)
	
	
	set.seed(1)
	
	s_cnt<-round(0.7*(nrow(boston_norm)))
	
	s_index<-sample(1:nrow(boston_norm), s_cnt, replace=F)
	
	boston_train <- boston_norm[s_index, ]
	
	boston_test <- boston_norm[-s_index, ]
	
	
	head(boston_train)
	
	
	## 3단계 : 데이터로 모델 훈련 ----
	
	# neuralnet 모델 훈련
	
	library(neuralnet)
	
	
	# 하나의 은닉 뉴런에 대한 단순한 ANN
	
	boston_model <- neuralnet(MEDV~CRIM+ZN+INDUS+CHAS+NOX+RM+AGE+DIS+RAD+TAX+PTRATIO+B+LSTAT, 	
data=boston_train, hidden=10)
	
	
	## 4단계 : 모델 성능 평가 ----
	
	
	# 모델 결과
	
	model_results <- compute(boston_model, boston_test[1:13])
	
	# 강도값 예측
	
	
	predicted_strength <- model_results$net.result
	
	
	
	# 예측값과 실제값간의 상관 관계 확인
	
	cor(predicted_strength, boston_test$MEDV)
	
	0.9340361






문제249.  hidden=10  파라미터를 조정해서 2층을 3층으로 늘리고 노드수도
          늘려서 정확도가 올라가는지 테스트 하시오 !

	hidden= c(  5,               2     )
	            ↑               ↑
	    은닉1층의 노드수    은닉2층의 노드수
	
	
	hidden =c(10 , 5.5)  # 95






문제250. (점심시간 문제) neuralnet 패키지를 이용해서 concreat 데이터로
         신경망 구축했던 코드를 이용해서 샤이니에 추가하시오 !
         ( 다중회귀 밑에 추가하시오! )


	concrete_model2 <- neuralnet(formula=strength ~ cement + slag + ash  +water +superplastic + coarseagg  + 	
fineagg  + age,
	 data =concrete_train,  hidden= c(5,2) )  
	
	 ui input 에  두개 생성  
	
	   은닉1층 노드수 :   5
	
	   은닉2층 노드수 :   2
	
	
	 상관계수값 출력





문제251.  상가 건물 데이터의 연관성 분석을 하고 시각화를 하시오 !  
          건물 상가에 서로 연관이 있는 업중이 무엇인가 ?
          건물에 병원이 있으면 약국이 있는가 ?

          " 보습학원이 있는 건물에는 어떤 업종의 매장이 연관되어 있는지
            찾아내시오 ! "


	build <- read.csv("building.csv" , header = T)
	
	build[is.na(build)] <- 0  
	build <- build[-1]
	build
	
	install.packages("arules")
	library(arules)
	trans <- as.matrix(build , "Transaction")
	
	rules1 <- apriori(trans , parameter = list(supp=0.2 , conf = 0.6 ,
	               target = "rules"))
	
	rules1
	
	inspect(sort(rules1))
	
	     lhs                                   rhs              support confidence lift     count
	[1]  {일반음식점}                       => {패밀리레스토랑} 0.40    1.0000000  2.222222 8    
	[2]  {패밀리레스토랑}                   => {일반음식점}     0.40    0.8888889  2.222222 8    
	[3]  {약국}                             => {휴대폰매장}     0.25    1.0000000  3.333333 5    
	[4]  {휴대폰매장}                       => {약국}           0.25    0.8333333  3.333333 5    
	[5]  {약국}                             => {병원}           0.25    1.0000000  3.333333 5    
	[6]  {병원}                             => {약국}           0.25    0.8333333  3.333333 5    
	[7]  {휴대폰매장}                       => {병원}           0.25    0.8333333  2.777778 5    
	[8]  {병원}                             => {휴대폰매장}     0.25    0.8333333  2.777778 5    
	[9]  {편의점}                           => {일반음식점}     0.25    1.0000000  2.500000 5    
	[10] {일반음식점}                       => {편의점}         0.25    0.6250000  2.500000 5    
	[11] {편의점}                           => {패밀리레스토랑} 0.25    1.0000000  2.222222 5    
	[12] {화장품}                           => {패밀리레스토랑} 0.25    0.8333333  1.851852 5    
	[13] {약국,휴대폰매장}                  => {병원}           0.25    1.0000000  3.333333 5    
	[14] {병원,약국}                        => {휴대폰매장}     0.25    1.0000000  3.333333 5    
	[15] {병원,휴대폰매장}                  => {약국}           0.25    1.0000000  4.000000 5    
	[16] {일반음식점,편의점}                => {패밀리레스토랑} 0.25    1.0000000  2.222222 5    
	[17] {패밀리레스토랑,편의점}            => {일반음식점}     0.25    1.0000000  2.500000 5    
	[18] {일반음식점,패밀리레스토랑}        => {편의점}         0.25    0.6250000  2.500000 5    
	[19] {보습학원}                         => {은행}           0.20    1.0000000  5.000000 4    
	[20] {은행}                             => {보습학원}       0.20    1.0000000  5.000000 4    
	[21] {보습학원}                         => {카페}           0.20    1.0000000  4.000000 4    
	[22] {카페}                             => {보습학원}       0.20    0.8000000  4.000000 4    
	[23] {은행}                             => {카페}           0.20    1.0000000  4.000000 4    
	[24] {카페}                             => {은행}           0.20    0.8000000  4.000000 4    
	[25] {당구장}                           => {일반음식점}     0.20    0.8000000  2.000000 4    
	[26] {당구장}                           => {패밀리레스토랑} 0.20    0.8000000  1.777778 4    
	[27] {편의점}                           => {화장품}         0.20    0.8000000  2.666667 4    
	[28] {화장품}                           => {편의점}         0.20    0.6666667  2.666667 4    
	[29] {화장품}                           => {일반음식점}     0.20    0.6666667  1.666667 4    
	[30] {보습학원,은행}                    => {카페}           0.20    1.0000000  4.000000 4    
	[31] {카페,보습학원}                    => {은행}           0.20    1.0000000  5.000000 4    
	[32] {카페,은행}                        => {보습학원}       0.20    1.0000000  5.000000 4    
	[33] {일반음식점,당구장}                => {패밀리레스토랑} 0.20    1.0000000  2.222222 4    
	[34] {패밀리레스토랑,당구장}            => {일반음식점}     0.20    1.0000000  2.500000 4    
	[35] {편의점,화장품}                    => {일반음식점}     0.20    1.0000000  2.500000 4    
	[36] {일반음식점,편의점}                => {화장품}         0.20    0.8000000  2.666667 4    
	[37] {일반음식점,화장품}                => {편의점}         0.20    1.0000000  4.000000 4    
	[38] {편의점,화장품}                    => {패밀리레스토랑} 0.20    1.0000000  2.222222 4    
	[39] {패밀리레스토랑,편의점}            => {화장품}         0.20    0.8000000  2.666667 4    
	[40] {패밀리레스토랑,화장품}            => {편의점}         0.20    0.8000000  3.200000 4    
	[41] {일반음식점,화장품}                => {패밀리레스토랑} 0.20    1.0000000  2.222222 4    
	[42] {패밀리레스토랑,화장품}            => {일반음식점}     0.20    0.8000000  2.000000 4    
	[43] {일반음식점,편의점,화장품}         => {패밀리레스토랑} 0.20    1.0000000  2.222222 4    
	[44] {패밀리레스토랑,편의점,화장품}     => {일반음식점}     0.20    1.0000000  2.500000 4    
	[45] {일반음식점,패밀리레스토랑,편의점} => {화장품}         0.20    0.8000000  2.666667 4    
	[46] {일반음식점,패밀리레스토랑,화장품} => {편의점}         0.20    1.0000000  4.000000 4    
	>
	
	* 시각화 코드
	
	
	rules2 <- subset(rules1 , subset = lhs %pin% '보습학원' & confidence > 0.7)
	inspect(sort(rules2))
	
	rules3 <- subset(rules1 , subset = rhs %pin% '편의점' & confidence > 0.7)
	rules3
	inspect(sort(rules3))
	
	#visualization
	b2 <- t(as.matrix(build)) %*% as.matrix(build)
	install.packages("sna")
	install.packages("rgl")
	library(sna)
	library(rgl)
	b2.w <- b2 - diag(diag(b2))
	#rownames(b2.w)
	#colnames(b2.w)
	gplot(b2.w , displaylabel=T , vertex.cex=sqrt(diag(b2)) , vertex.col = "green" , edge.col="blue" , 	
boxed.labels=F , arrowhead.cex = .3 , label.pos = 3 , edge.lwd = b2.w*2)







문제252. 라라랜드의 긍정적 평가 게시판의 글들을 명사만
         추출한 다음 단어들간의 연관관계를 출력하시오


	답 :
	
	1. 관련된 패키지 설치
	
	library(KoNLP)
	library(wordcloud)
	library(tm)
	library(stringr)
	library(arules)
	
	2. 명사 추출하는 코드
	lala_positive <- sapply(lala_positive, extractNoun, USE.NAMES=F)
	head(lala_positive)
	
	3. unlist 로 변환한후에 철자가 2개이상이고 5개 이하인
	   것만 추출
	
	c <- unlist(lala_positive)
	lala_positive2 <- Filter(function(x) { nchar(x) >= 2 &
	                               nchar(x) <= 5 }  , c)
	
	4. 데이터 정재작업( 분석하기에 너무 많이 나오는 단어를
	    삭제하는 작업 )
	
	# 숫자제거
	lala_positive2 <- gsub('\\d+','',lala_positive2)
	
	
	lala_positive2 <- gsub('관람객','',lala_positive2)
	lala_positive2 <- gsub('평점', '', lala_positive2)
	lala_positive2 <- gsub('영화', '', lala_positive2)
	lala_positive2 <- gsub('진짜', '', lala_positive2)
	lala_positive2 <- gsub('완전', '', lala_positive2)
	lala_positive2 <- gsub('시간', '', lala_positive2)
	lala_positive2 <- gsub('올해', '', lala_positive2)
	lala_positive2 <- gsub('장면', '', lala_positive2)
	lala_positive2 <- gsub('남자', '', lala_positive2)
	lala_positive2 <- gsub('여자', '', lala_positive2)
	lala_positive2 <- gsub('만큼', '', lala_positive2)
	lala_positive2 <- gsub('니가', '', lala_positive2)
	lala_positive2 <- gsub('년대', '', lala_positive2)
	lala_positive2 <- gsub('옆사람', '', lala_positive2)
	lala_positive2 <- gsub('들이', '', lala_positive2)
	lala_positive2 <- gsub('저녁', '', lala_positive2)
	lala_positive2 <- gsub('영화', '', lala_positive2)
	
	lala_positive2
	
	5. 한글이 아닌 데이터를 제거하는 작업
	res <- str_replace_all(lala_positive2, "[^[:alpha:]]","")
	
	6.  ""  데이터 제거하는 작업
		res <- res[res != ""]
	
	7. 단어와 그 건수를 출력하는 작업
	wordcount <- table(res)
	wordcount2 <- sort( table(res), decreasing=T)
		
	8. 단어의 건수가 100 보다 큰것만 필터링
	keyword <- names( wordcount2[wordcount2>100] )
	length(lala_positive)
	
	9. 아프리오리 분석을 위해서 표형태로 만드는 작업
	contents <- c()
	for(i in 1:length(lala_positive)) {
	  inter <- intersect(lala_positive[[i]] , keyword)
	  contents <- rbind(contents ,table(inter)[keyword])
	}
	
	10. 표의 컬럼명에 단어가 들어가게한다.
	colnames(contents) <- keyword
	
	11. na 를 숫자 0 으로 변경한다.
	contents[which(is.na(contents))] <- 0
	
	dim(lala_positive)
	
	12. 아프리오리 데이터 분석
	
	detach(package:tm, unload=T)
	library(arules)
	rules_lala <- apriori(contents , parameter = list(supp = 0.007 , conf = 0.3 , target = "rules"))
	rules_lala
	inspect(sort(rules_lala ))






문제 253. 위의 data를 factoextra패키지를 이용해서 시각화 하시오 !

	install.packages("factoextra")
	library(factoextra)
	km <- kmeans(data, 2)
	fviz_cluster(km, data = data, stand = F)









문제 254. 국영수 점수 데이터를 가지고 k값을 4두고 학생들을 분류하시오 ! 분류하고 시각화도 하시오 !
	 	  (수학점수와 영어점수로만 분류)

	academy <- read.csv("academy.csv")
	academy[3:4]
	km <- kmeans(academy[3:4], 4)
	km
	fviz_cluster(km, data = academy[3:4], stand = F)




문제 255. 학생번호, 수학점수, 영어점수, 분류번호가 같이 출력되게 하시오 !

	academy <- read.csv("academy.csv")
	cbind(academy[,c(1,3,4)], km$cluster)

	   학생번호 수학점수평균 영어점수평균 km$cluster
	1         1           75           85          4
	2         2           90           60          1
	3         3           53           48          2
	4         4           96           62          1
	5         5           89           80          4
	6         6           92           90          4
	7         7           70           66          3
	8         8           90           70          1




문제 256. 미국 대학 입학 점수를 가지고 academic 점수와 sport 점수를 x, y 축으로 두고 4가지 클래스로
		  분류하시오 !

	set.seed(11)
	enter_score <- read.csv("sports.csv")
	head(enter_score)

	enter_score <- enter_score[, c(2,3)]
	enter_score

	km <- kmeans(enter_score,4)
	km

	graphics.off()

	library(factoextra)

	fviz_cluster ( km , data= enter_score, stand=F)





문제 257. 동물 데이터를 가지고 k-means 머신러닝 기법을 수행해서 동물 데이터의 라벨과 k-means 의
		  클러스터가 일치하는지 확인해보시오 !

	머신러닝 데이터 게시판 87번 동물 데이터 zoo2.csv

	마지막 컬럼이 라벨

	1: 포유류
	2 : 조류
	3 : 파충류
	4 : 어류
	5 : 양서류
	6 : 곤충
	7 : 갑각류


	set.seed(11)
	zoo <- read.csv("zoo2.csv")
	head(zoo)

	zoo_n <- zoo[, 2:17]
	head(zoo_n)

	zoo_model <- kmeans(zoo_n,7)

	x <- cbind(zoo[,18], zoo_model$cluster)

	x2 <- data.frame(x)

	x2
	library(doBy)
	x3<- orderBy(~X1,x2)

	table(x3$X1,x3$X2)







문제 258. (점심시간 문제) 부도여부 데이터(라벨 있는 데이터) 를 k-means 머신러닝 기법으로 분류해서
		  동물데이터 처럼 라벨과 일치하는지 확인해보시오 !

	부도예측데이터3.csv

	set.seed(15)
	bankrupt <- read.csv("부도예측데이터3.csv")
	head(bankrupt)

	bankrupt_n <- bankrupt[,2:ncol(bankrupt)]
	head(bankrupt_n)

	bankrupt_model <- kmeans(bankrupt_n,2)

	graphics.off()

	library(factoextra)

	fviz_cluster ( bankrupt_model , data= bankrupt_n, stand=F)

	x <- cbind(bankrupt[,1], bankrupt_model$cluster)
	x






like.csv

문제 259. 소개팅 데이터를 kmeans 로 분석해서 소개팅했던 상대방의 라벨과 kmeans cluster 와 일치하는지
		  확인하시오 !

	set.seed(1)
	like <- read.csv("like.csv")

	like

	like_n <- like[,-8]
	like_n

	like_model <- kmeans(like_n, 3)

	x <- cbind(like[,8], like_model$cluster)

	x2 <- data.frame(x)

	table(x2)





문제 260. 위의 소개팅 상대방의 분류 결과를 시각화 하시오 !






문제 261. k-means 알고리즘을 R 샤이니에 머신러닝 탭에 추가하시오! (소개팅 like.csv 데이터를 가지고
		  코드 구현한것으로 구현)

	UI 화면에 ---> 	1. seed 값 선택
			2. k 값 선택
			
	결과 화면은 아래와 같이 출력하시오 !


	   X2
	X1  1 2 3
	  1 0 5 0
	  2 0 0 4
	  3 5 0 0





문제 262. 책 431페이지의 정확도를 보는 공식을 이용하여 아래의 분류결과의 오류율을 각각 확인하시오 !

그림 11

		 1203 + 151
	정확도 = ───── = 0.974
		    1390

	오류율 = 1 - 정확도 = 1 - 0.974 = 0.026






문제 263. 책 437페이지의 이원교차표의 카파통계량을 계산하시오 !

	햄 a : 1203+31/1390  = 0.8877
	스팸 a  : 4+152/1390 = 0.1122
	햄 b : 1203+4/1390   = 0.8683
	스팸 b : 31+152/1390 = 0.1316
	
	0.8877*0.8683 + 0.1122*0.1316
	0.7707 + 0.0147	= 0.7854 ( Pr(e) )
	
	
	0.9748 - 0.7854 / 1- 0.7854
	0.1894 / 0.2146 = 0.8825 (좋은 일치)


	정확도 뿐만아니라 kappa지수도 같이 설명하면서 모델에 나온 정확도가 어쩌다 우연히 나온 결과가
	아니다라는 것을 합리적으로 설명할 수 있어야 한다.






문제 264. 아래의 스팸/햄메일을 분류하는 모델의 이원교차표를 보고 정밀도와 재현율을 각각 구하시오 !
	  " 관심 클래스를 스팸을 기준으로 "
그림 13

참고 : 그림 14

	정밀도 = 152 / 156 = 0.9743
	
	재현율 = 152 / 183 = 0.8306



문제 264. (점심시간 문제) 스팸/햄메일을 분류하는 모델의 정밀도와 재현율, 민감도, 특이도를 caret패키지를
	  이용해서 구하시오 !

	"sms_results.csv를 이용"

	install.packages("caret")
	library(caret)
	sms <- read.csv('sms_results.csv', header = T)
	head(sms)
	nrow(sms)
	table(sms$actual_type, sms$predict_type)
	confusionMatrix(sms$actual_type, sms$predict_type, positive = "spam")
	
	Confusion Matrix and Statistics
	
	          Reference
	Prediction  ham spam
	      ham  1203    4
	      spam   31  152
	                                          
	               Accuracy : 0.9748          
	                 95% CI : (0.9652, 0.9824)
	    No Information Rate : 0.8878          
	    P-Value [Acc > NIR] : < 2.2e-16       
	                                          
	                  Kappa : 0.8825          
	 Mcnemar's Test P-Value : 1.109e-05       '
	                                          
	            Sensitivity : 0.9744          
	            Specificity : 0.9749          
	         Pos Pred Value : 0.8306          
	         Neg Pred Value : 0.9967          
	             Prevalence : 0.1122          
	         Detection Rate : 0.1094          
	   Detection Prevalence : 0.1317          
	      Balanced Accuracy : 0.9746          
	                                          
	       'Positive' Class : spam  






문제 265. (책 439쪽 참고) 파키지 irr을 설치하고 kappa2함수를 이용해서 스팸/햄 메일 분류 모델의 kappa지수를
	  구하시오 !

	install.packages("irr")
	library(irr)
	kappa2(sms[1:2])
	
	 Cohen's Kappa for 2 Raters (Weights: unweighted)                      '
	
	 Subjects = 1390
	   Raters = 2
	    Kappa = 0.883
	
	        z = 33
	  p-value = 0





문제 266. 햄/스팸 메일을 분류하는 모델의 F척도가 어떻게 되는가 ?

그림 13
	
	정밀도 : 0.9743
	재현율 : 0.8306

		2 x 정밀도 x 재현율    2 * 0.9743 * 0.8306
	F척도 = ────────── = ────────── = 0.8966
		   재현율 + 정밀도 	 0.8306 + 0.9743





문제 267. 독일 채무 불이행자에 대한 모델을 생성하는데 아래와 같이 caret패키지의 train함수의 옵션을
		  주어서 모델을 생성하고 사용자 지정 안했을 대 보다 정확도가 더 높아지는지 확인하시오 !

	library(caret)
	credit <- read.csv("credit.csv")

	ctrl <- trainControl(method="cv", number=10, selectionFunction="oneSE")
	grid <- expand.grid(.model="tree", .trials=c(1, 5, 10, 20, 25, 30, 35), .winnow="FALSE")
	m <- train(default ~. , data =credit_train  , method="C5.0", metric="Kappa", trcControl=ctrl,
		       tuneGrid=grid)
	m

	C5.0

	1000 samples
	  16 predictor
	   2 classes: 'no', 'yes'

	No pre-processing
	Resampling: Bootstrapped (25 reps)
	Summary of sample sizes: 1000, 1000, 1000, 1000, 1000, 1000, ...
	Resampling results across tuning parameters:

	  trials  Accuracy   Kappa    
	   1      0.6947856  0.2638759
	   5      0.7139042  0.2947655
	  10      0.7289651  0.3134021
	  15      0.7339478  0.3345875
	  20      0.7370405  0.3338858
	  25      0.7369206  0.3360275
	  30      0.7386061  0.3379393
	  35      0.7401694  0.3422338

	Tuning parameter 'model' was held constant at a value of
	 tree
	Tuning parameter 'winnow' was held constant at a value
	 of FALSE
	Kappa was used to select the optimal model using the
	 largest value.
	The final values used for the model were trials = 35, model
	 = tree and winnow = FALSE.


	p <- predict(m, credit)
	table( p, credit$default)

	p      no yes
	  no  700   0
	  yes   0 300






문제 268. caret 패키지의 train() 함수를 이용해서 10-폴드 교차검증과 같이 배깅트리를 사용할 수 있다.
		  책 486 페이지에 나온대로 독일 은행 채무 불이행자를 예측하는 모델을 생성하고 정확도를 확인
		  하시오 !


	library(caret)
	set.seed(300)
	ctrl <- trainControl(method="cv", number=10)
	m = train(default~., data=credit, method="treebag", trControl=ctrl)
	credit_pred <- predict(m, credit)
	table(credit_pred, credit$default)

	credit_pred  no yes
	        no  700   1
	        yes   0 299







문제 269. 소아 척추 수술에 대한 데이터를 이용해서 척추병의 완치를 예측하는 모델을 생성하시오 !
"""
kyphosis 데이터는 성형외과에서 아이들이 척추수슬후에 얼마만에 증상이 사라졌는지 아니면 그대로
존재하는지에 대한 데이터로서 독립변수가 처음 수술한 척추의 수와 관련된 척추의 수 그리고 경과 개월이다.
데이터가 81개 밖에 안되니 그냥 결정트리에 넣어서 예측과 실제 라벨을 비교해서 정확도를 보자
age : 개월수, number : 척추수, start : 경과 개월, kyposis : 후유증 유무
"""
	1. 데이터를 로드한다.
		kyphosis <- read.csv("kyphosis.csv")
		View(kyphosis)

	2. rpart 를 이용해서 결정트리 모델을 생성한다.
		library(rpart)
		fit <- rpart(kyphosis ~ age + number + start,method="class",
		                    data=kyphosis)

	3. 모델을 시각화 한다.
		install.packages("rpart")
		install.packages("rattle")
		library(rattle)
		library(rpart.plot)
		fancyRpartPlot(fi

	4. 정확도를 확인한다.
		result <- predict(fit , newdata = kyphosis)
		sum(kyphosis$kyphosis == ifelse(result[,1]>0.5 ,
		               "absent" , "present"))/NROW(kyphosis)
		[1] 0.8395062




문제 270. 랜덤 포레스트를 이용해서 위의 정확도를 올리는 모델을 생성하시오 !

	library(randomForest)
	fit <- randomForest(kyphosis ~ age + number + start,   
	                       data=kyphosis)
	res2 <- predict(fit , newdata = kyphosis)
	sum(res2 == kyphosis$kyphosis)/NROW(kyphosis)

	[1] 0.9753086





문제 277. 위의 필기체를 구분하는 svm모델의 정확도를 올리기 위해서 ksvm함수의 kernel파라미터값을
		  rbfdot로 변경해서 수행하시오 !

	library(kernlab)
	letter_classifier <- ksvm(letter ~ ., data = letters_train, kernel = "rbfdot")
	letter_classifier
	letter_predictions <- predict(letter_classifier, letters_test)
	head(letter_predictions)
	table(letter_predictions, letters_test$letter)
	agreement <- letter_predictions == letters_test$letter
	table(agreement)
	prop.table(table(agreement))

	agreement
	 FALSE   TRUE
	0.0705 0.9295





문제 278. 한국인 신체지수 데이터를 이용해서 복부 비만인지 정상인지를 예측하는 svm모델을 생성하시오!

컬럼 설명 : 성별, 나이, 키, 가슴둘레, 허리둘레, 배둘레, 엉덩이둘레, 겨드랑둘레, 얼굴수직길이, 머리둘레,
			골격근량, 체지방량, 체수분, 단백질, 무기질, 체지방률, 복부지방률, 기초대사량,
			복부지방률평가, 대사량평가

	# csv 파일 불러옴(이전에 안에 있는 한글 전부 영어로 다 바꿈)
	body <- read.csv("kbody2.csv", header = F)

	# 라이브러리 불러옴
	library(e1071)

	# na값 제거
	body1 <- na.omit(body)

	# 컬럼명 줌
	colnames(body1) <- c("gender", "age", "height", "chest", "heory", "bae", "ass", "kyeo",
	                     "face_vertical", "head", "bone", "body_fat", "body_water",
	                     "protein", "mineral", "body_fat_per", "bae_fat_per", "work", "bae_fat_test",
	                     "work_test")

	# 랜덤시드 생성
	set.seed(12345)

	# 셔플
	body_ran <- body1[order(runif(12894)), ]

	# 트레이닝셋 80%
	body_train <- body_ran[1:10314, ]

	# 테스트셋 20%
	body_test <- body_ran[10315:12894, ]

	# 선형SVM 훈련
	body_svm <- svm(work_test~., data = body_train, kernel="linear")
	body_svm

	# 모델 테스트
	p <- predict(body_svm, body_test, type="class")
	p
	table(p, body_test[, 20])

	# 분류 결과 확인
	mean(p == body_test[, 20])



문제 279. 한국인 신체지수 데이터의 svm정확도를 올리시오 !

	body_svm <- svm(work_test~., data = body_train, kernel="radial")




문제 280. (점심시간 문제) SVM을 샤이니에 추가하시오 !
