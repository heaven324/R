■ 의사 결정트리 복습

	머신러닝의 종류 3가지

		1. 지도학습 ─▶ 라벨이 있다.
			- knn : 데이터 간의 거리를 이용해서 분류
			- naive bayes : 확률을 이용해서 분류
			- decision tree : 정보 획득량으로 분류
					      ↓
					공식 ? 분할전 엔트로피 - 분할 후 엔트로피
				정보획득량으로 가장 먼저 질문해야할 변수들을 알아내고 분류를 하는
				것이다.

		2. 비지도 학습 ─▶ 라벨이 없다.

		3. 강화학습 ─▶ 환경을 스스로 agent가 학습해 나가는 방법 







■ C5.0패키지를 이용해서 분류 모델 생성

	" 백화점 화장품 고객 중에 구매가 예상이 되는 고객이 누구인가? "

	" 은행 대출 채무 불이행할 것 같은 고객이 누구인가 ? "
			↓
	의사결정 트리로 분류를 할 것이다.







★ 백화점 화장품 고객 중에 구매가 예상이 되는 고객이 누구인가?

	1. 의사결정 패키지인 c50 패키지를 설치한다.
		install.packages("C50")
		library(C50)
	
	2. 백화점 화장품 고객 데이터를 로드하고 shuffle 한다.
		skin <- read.csv("skin.csv", header = T)
		nrow(skin)
		
		skin_real_test_cust <- skin[30, ]
		skin2 <- skin[1:29, ]
		nrow(skin2)
		
		   cust_no gender age job marry car cupon_react
		30      30 female  40 YES   YES  NO         YES

		skin2 <- skin2[, -1] # 고객번호를 제외시킨다.
		
		set.seed(11)
		skin2_shuffle <- skin2[sample(nrow(skin2)), ] # shuffle 시킴

	3. 화장품 고객 데이터를 9대 1로 train과 test로 나눈다.
		train_num <- round(0.7 * nrow(skin2_shuffle), 0)
		skin2_train <- skin2_shuffle[1:train_num, ]
		skin2_test <- skin2_shuffle[(train_num+1):nrow(skin2_shuffle), ]
		
		nrow(skin2_train) # 20
		nrow(skin2_test)  #9

	4. C50패키지를 이용해서 분류 모델을 생성한다.
		# skin_model <- C5.0(skin2_train[, -6], skin2_train$cupon_react, trials = 6) # 다맞춤
		skin_model <- C5.0(skin2_train[, -6], skin2_train$cupon_react) # 1개 틀림
				       ↑			↑
			    라벨을 뺀 train 전체 data   train 데이터의 라벨

	5. 위에서 만든 skin_model을 이용해서 테스트 데이터의 라벨을 예측하시오 !
		skin2_result <- predict(skin_model, skin2_test[ , -6])
							↑
					    라벨을 뺀 테스트 데이터 전체

	6. 이원 교차표로 결과를 확인하시오 !
		library(gmodels)
		CrossTable(skin2_test[, 6], skin2_result)




문제 207. 위 의사결정 트리의 성능을 높이시오 !

	library(C50)
	skin_model <- C5.0(skin2_train[, -6], skin2_train$cupon_react, trials = 6)
	skin2_result <- predict(skin_model, skin2_test[ , -6])
	
	library(gmodels)
	CrossTable(skin2_test[, 6], skin2_result)





문제 208. 아까 위에서 한건 뺀 고객 데이터 (skin_real_test_cust)이 쿠폰 반응이 있는 고객인지 아닌지 잘 
	  맞추는지 확인하시오 !

	predict(skin_model, skin_real_test_cust)
	
	[1] YES
	Levels: NO YES








★ 은행 대출 채무 불이행할 것 같은 고객이 누구인가 ?

	데이터 : cradit.csv (독일 은행의 고객데이터)

	1. 데이터를 로드한다
		credit<- read.csv("credit.csv")

	2. 데이터에 각 컬럼명을 이해한다.
		라벨컬럼 : defult ──▶ yes : 대출금 상환 안함
					 no  : 대출금 상환
		prop.table(table(credit$default))
		 no yes 
		0.7 0.3 
	    - 계좌 소개 : checking_balance ─▶ 예금계좌
			  saving_balance   ─▶ 적금계좌
	    - amount : 대출금액 250마르크 ~ 18424마르크 ( 100 마르크가 우리나라돈 6 ~ 7만원 )
		summary(credit$amount)
		   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
		    250    1366    2320    3271    3972   18424 

		은행의 목표 : 과거의 데이터를 분석해보니 대출금 상환 불이행자가 30%나 되어서 앞으로는
			      30%이내로 떨어뜨리게끔 하는게 은행의 목표라서 거기에 맞는 model을
			      생성해야 한다.

	3. 데이터가 명목형 데이터인지 확인해본다.
		str(credit)

	4. 데이터를 shuffle시킨다.
		set.seed(31)
		credit_shuffle <- credit[sample(nrow(credit)), ]

	5. 데이터를 9:1로 나눈다.
		train_num <- round(0.9 * nrow(credit_shuffle), 0)
		credit_train <- credit_shuffle[1:train_num, ]
		credit_test <- credit_shuffle[(train_num+1) : nrow(credit_shuffle), ]

	6. C5.0패키지와 훈련데이터를 이용해서 모델을 생성한다.
		library(C50)
		credit_model <- C5.0(credit_train[, -17], credit_train[, 17])


	7. 위에서 만든 모델을 이용해서 테스트 데이터의 라벨을 예측한다.
		credit_result <- predict(credit_model, credit_test[, -17])

	8. 이원 교차표로 결과를 확인한다.
		library(gmodels)
		CrossTable(credit_test[, 17], credit_result)






문제 209. 부스팅 기법을 이용해서 위의 의사결정트리 모델의 정확도를 올리시오 !

	credit_model <- C5.0(credit_train[, -17], credit_train[, 17], trial = 63)
	credit_result <- predict(credit_model, credit_test[, -17])
	library(gmodels)
	CrossTable(credit_test[, 17], credit_result)




문제 210. 의사 결정 트리 알고리즘을 R 샤이니에 붙이시오 !





문제 211. 근무하고 있는 사원중에 퇴사가 예상되는 사원이 누구인지 알아내는 의사결정 트리 모델을 
	  생성하시오 !  (hr.csv 데이터를 활용)











■ 규칙 기반 알고리즘

	1. oneR  알고리즘 : p 223

		"하나의 사실만 가지고 간단하게 분류하는 알고리즘 "
		간단하긴하지만 오류가 많아진다.

		예 : 가슴통증의 유무에 따라 심장질환이 있는지 분류
		     가슴통증 하나만 보고 심장질환이 있다고 분류하기에는 오류가 많아진다. 왜나하면
		     식도염, 폐질환도 가슴통증이 있기 때문이다.


	2. Riper 알고리즘 : p 226

		"복수개의 사실(조건)을 가지고 분류하는 알고리즘"

		예 : 하늘을 날고 털이 있다면 그것은 포유류이다.
		     땅을 걷고 털이 있다면 그것은 포유류이다.





★ 규칙 기반 분류 알고리즘 (oneR 실습)

	"독버섯 데이터"

	나이브 베이즈와 비교해보기 위해서 나이브 베이즈로 독버섯과 일반버섯을 분류한 이원 교차표를
	아래에 출력하시오 !
	
	                  | result 
	                  |    edible | poisonous | Row Total | 
	------------------|-----------|-----------|-----------|
	           edible |      1257 |         3 |      1260 | 
	                  |   558.656 |   601.007 |           | 
	                  |     0.998 |     0.002 |     0.517 | 
	                  |     0.995 |     0.003 |           | 
	                  |     0.516 |     0.001 |           | 
	------------------|-----------|-----------|-----------|
	        poisonous |         6 |      1171 |      1177 | 
	                  |   598.051 |   643.389 |           | 
	                  |     0.005 |     0.995 |     0.483 | 
	                  |     0.005 |     0.997 |           | 
	                  |     0.002 |     0.481 |           | 
	------------------|-----------|-----------|-----------|
	     Column Total |      1263 |      1174 |      2437 | 
	                  |     0.518 |     0.482 |           | 
	------------------|-----------|-----------|-----------|



	1. 버섯 데이터를 R로 로드한다.
		mushroom <- read.csv("mushrooms.csv", stringsAsFactors = T)

	2. mushroom데이터를 훈련 데이터와 테스트 데이터로 나눈다.
	   (훈련데이테 75%, 테스트 데이터 25%)
		set.seed(11)
		dim(mushroom)
		train_cnt <- round(0.75*dim(mushroom)[1])
		train_index <- sample(1:dim(mushroom)[1], train_cnt, replace = F)
		mushroom_train <- mushroom[train_index, ]
		mushroom_test <- mushroom[-train_index, ]

	3. 규칙 기반 알고리즘인 oneR을 이용해서 독버섯과 일반버섯을 분류하는 모델을 생성한다.
		install.packages("OneR")
		library(OneR)
		model1 <- OneR(type~. , data=mushroom_train)
		model1
		summary(model1)

	4. 위에서 생성한 모델을 가지고 테스트 데이터로 결과를 확인한다.
		result1 <- predict(model1, mushroom_test[ , -1])
		library(gmodels)
		CrossTable(mushroom_test[ ,1], result1)

	                   | result1 
	mushroom_test[, 1] |    edible | poisonous | Row Total | 
	-------------------|-----------|-----------|-----------|
	            edible |      1028 |         0 |      1028 | 
	                   |   446.170 |   489.958 |           | 
	                   |     1.000 |     0.000 |     0.506 | 
	                   |     0.967 |     0.000 |           | 
	                   |     0.506 |     0.000 |           | 
	-------------------|-----------|-----------|-----------|
	         poisonous |        35 |       968 |      1003 | 
	                   |   457.291 |   502.170 |           | 
	                   |     0.035 |     0.965 |     0.494 | 
	                   |     0.033 |     1.000 |           | 
	                   |     0.017 |     0.477 |           | 
	-------------------|-----------|-----------|-----------|
	      Column Total |      1063 |       968 |      2031 | 
	                   |     0.523 |     0.477 |           | 
	-------------------|-----------|-----------|-----------|








★ 규칙 기반 분류 알고리즘 (JRiper 실습)

	install.packages("RWeka")
	library(RWeka)
	
	model2 <- JRip(type~. , data=mushroom_train)
	model2
	summary(model2) # 작은 이원교차표가 하나 보임
	
	result2 <- predict(model2, mushroom_test[ , -1])
	library(gmodels)
	CrossTable(mushroom_test[, 1], result2)

	                   | result2 
	mushroom_test[, 1] |    edible | poisonous | Row Total | 
	-------------------|-----------|-----------|-----------|
	            edible |      1028 |         0 |      1028 | 
	                   |   495.327 |   507.673 |           | 
	                   |     1.000 |     0.000 |     0.506 | 
	                   |     1.000 |     0.000 |           | 
	                   |     0.506 |     0.000 |           | 
	-------------------|-----------|-----------|-----------|
	         poisonous |         0 |      1003 |      1003 | 
	                   |   507.673 |   520.327 |           | 
	                   |     0.000 |     1.000 |     0.494 | 
	                   |     0.000 |     1.000 |           | 
	                   |     0.000 |     0.494 |           | 
	-------------------|-----------|-----------|-----------|
	      Column Total |      1028 |      1003 |      2031 | 
	                   |     0.506 |     0.494 |           | 
	-------------------|-----------|-----------|-----------|








■ 6장. 회귀 분석

	* 6장 목차
		1. 단순 선형 회귀 분석 이론
		2. 단순 선형 회귀 실습1 (탄닌 함유량과 애벌레 성장간의 관계)
		3. 단순 선형 회귀 실습2 (우주 왕복선 챌린저호 폭발 원인 분석)
		4. 단순 선형 회귀 실습3 (코스피 지수 수익률과 삼성, 현대 자동차 주식 수익율의 
					 상관관계 분석)
		5. 다중 선형 회귀 이론
		6. 다중 선형 회귀 실습1 (스마트폰 만족에 미치는 영향도 분석)
		7. 다중 선형 회귀 실습2 (미국 대학 입학에 가장 영향이 높은 과목 분석)
		8. 다중 선형 회귀 실습3 (보험회사의 보험료 선정에 미치는 요소 분석)
		9. 다중 선형 회귀 실습4 (날씨와 전력사용량과의 상관관계)







★ 1. 단순 선형 회귀 분석 이론

	* 머신러닝의 종류 3가지 ?
		1. 지도학습
			- 분류 : KNN, naivebayes, decesion tree, 규칙기반 알고리즘
			- 회귀 : 

		2. 비지도 학습

		3. 강화학습






★ 회귀 분석이란 ?

	회귀 분석은 하나의 변수가 나머지 다른 변수들과의 선형적 괸계를 갖는가의 여부를 분석하는 
	방법으로 하나의 종속변수(예측하고자 하는 값)와 족립변수 사이의 관계를 명시하는 것

	예 : 집값에 가장 영향을 주는 요소가 무엇인가?

	- 독립변수 : 종속변수에 영향을 주는 변수 ( 평수, 역세권, 학군, .... )
	- 종속변수 : 서로 관계를 가지고 있는 변수들 중에서 다른 변수에 영향을 받는 변수 (집값)

	회귀식 : y = αx + β
		↓     ↓
	       집값   평수

	예 : 1986년 1월 28일 미국의 스페이스 셔틀 챌린져호의 승무원 7명이 모두 사망했다. 우주 왕복선이
	     발사 도중에 폭파하는 바람에 사망을 했다. 원인분석을 했는데 그 원인이 ?

		" 발사 온도에 대한 o형링의 파손이 원인 "

		y = αx + β

		y가 o형링의 파손수, x가 발사 온도
		여기서 회귀 모수인 α, β 를 기계가 구하게끔 해야한다.
		일단 α가 -0.057이고 β가 4.3이라고 기계학습 결과로 알아냈다면 식은 
			y = -0.057 * x + 4.3



★ 최소 제곱 추정법 (p253)

	최적의 α(기울기)와 β(절편)을 결정하기 위해서 정규 최소 제곱법으로 알려진 추정기법을 사용한다.
			 ∧
	실제값 y와 예측값 y 사이의 수직 직선이 오차(잔차)를 제곱해서 구한 총합을 알아야 한다.
			 ∧
		Σ (yi - yi)^2
		    ↑   ↑
	 	실제값  예상값
		      ∧
	     Σ (yi - yi)^2
	α = ────────
		      ∧
	     Σ (xi - xi)^2

	이를 다시 아래의 식으로 나타내면 ?

	     Σ (x값 - x값의 평균) * (y값 - y값의 평균)
	α = ─────────────────────
	              Σ (x값 - x값의 평균)^2

	     x와 y의 공분산      cov(x, y)
	α = ───────  =  ─────  =  기울기
	          분산            var(x)

	y = αx + β
	    ↓
	  기울기


문제 213. 챌린져호의 폭파원인 데이터를 R로 로드하고 x축을 온도로 하고 y축을 o형링 파손수로 해서 
	  R샤이니에 plot그래프를 그리시오 !





문제 214. 챌린저 호의 폭파 원인을 분석하기 위한 회귀 직선의 기울기를 R로 알아내시오 !

	x축 : temprature, y축 : distress_ct
	  cov(x, y)
	= ───── = 기울기
	    var(x)

	기울기 : -0.04753968

	공분산의 뜻 ? 서로 다른 변수들 사이에 얼마나 의존하는지를 수치적으로 표현한 것
