■ 회귀 트리 (p282)

	1. 회귀트리란? 수치를 예측하는 트리 ──▶ 분류
						  ↙  ↘
						구매  비구매
		- 의사결정 트리의 결과 그림
	그림 5

		- 회귀트리 결과 그림 
	그림 6


	2. 특정 숫자를 예측하는데 다중 회귀분석을 이용하지 않고 왜 회귀트리를 사용하는가?

		예측해야 하는 특정 숫자(집값) ◀── 평수, 학군, 지하철과의 거리 ....
		와인의 등급(숫자)  ◀── 휘발성, 알코올 함량, 자유 이산화황.....

		수치 예측 작업을 할 때 일반적으로 전통적인 회귀방법을 가장 먼저 선택하지만, 경우에 따라
		수치 의사결정트리가 분명한 이점을 제공하기도 한다.

		예를들어 의사결정트리의 장점을 수치 예측에 활용할 수 있다.

		의사결정 트리는 작업이 특징이 많거나 특징과 결과간에 매우 복잡하고 비선형적인 관계를
		가질 때 잘 맞는 반면 회귀는 이럴때 어려움이 있다.

		회귀의 경우는 독립변수의 갯수 많으면
			1. 다중공선성도 고려를 해야했고
			2. 결정계수를 높이기 위해 파생변수를 추가 해야하는 모델의 성능을 높이기 위한
			   작업들이 필요했다.

	3. 회귀트리의 원리?

		회귀 트리와 모델트리의 이해.pdf


	4. 회귀트리의 나눔의 기준인 SDR 테스트

		p284표
			그림 7

		속성 A와 속성 B중에 어떤게 더 균일하게 나누었는지 SDR을 확인한다.

		#원본데이터
		tee <- c(1, 1, 1, 2, 2, 3, 4, 5, 5, 6, 6, 7, 7, 7, 7)
		
		#원본데이터를 A속성으로 나누었을 때의 데이터
		
		at1 <- c(1, 1, 1, 2, 2, 3, 4, 5, 5)
		at2 <- c(6, 6, 7, 7, 7, 7)
		
		#원본 데이터를 B속성으로 나누었을 때의 데이터
		
		bt1 <- c(1, 1, 1, 2, 2, 3, 4)
		bt2 <- c(5, 5, 6, 6, 7, 7, 7, 7)
		
		# A속성과 B속성의 SDR을 구한다.
		sdr_a <- sd(tee) - (length(at1) / length(tee) * sd(at1) +
		                    length(at2) / length(tee) * sd(at2))
		sdr_b <- sd(tee) - (length(bt1) / length(tee) * sd(bt1)+
		                    length(bt2) / length(tee) * sd(bt2))
		sdr_a # [1] 1.202815
		sdr_b # [1] 1.392751
		
		
		#sdr이 더 높은 속성으로 나눔을 결정하고 각각 bt1과 bt2의 평균값을 구해서 등급을 예측!
		mean(bt1)	# 2로 예측한다.
		mean(bt2)	# 6.25로 예측한다.
		
			트리 다이어그램
				그림 8








■ 회귀 트리 (Regression Tree)  

	 1. 와인 데이터에 대한 소개 





■ 와인 데이터로 의사결정 트리 시각화 

 
	#fixed.acidity       : 고정 산도
	#volatile.acidity    : 휘발성 산도
	#citric.acid         : 시트르산
	#residual.sugar      : 잔류 설탕
	#chlorides           : 염화물
	#free.sulfur.dioxide : 자유 이산화황
	#total.sulfur.dioxide: 총 이산화황
	#density             : 밀도
	#pH                  : pH
	#sulphates           : 황산염
	#alcohol             : 알코올
	#quality             : 품질
	
		wine <- read.csv("whitewines.csv")


	2. 와인의 quality 데이터가 정규분포에 속하는 안정적인 
	   데이터 인지 확인

		hist(wine$quality)

		설명 : 와인 품질값이 6근처를 중심으로 매우 정규적인 벨 모양의 분포를 따르는 것처럼 
		       보인다.
		       대부분의 와인이 평균 품질이기 때문에 직관적으로 이해가 된다.
		이상치가 있는지 확인해본다
		summary(wine$quality)

		   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
		  3.000   5.000   6.000   5.878   6.000   9.000 
	

	3. wine 데이터를 train 데이터와 test 데이터로 나눈다.

		wine_train <- wine[1:3750,  ]
		wine_test  <- wine[3751:4898, ]


	4. train 데이터를 가지고 model 을 생성한다. 

		library(rpart)

		model <-  rpart( quality ~ . , data=wine_train)

		model 

		n= 3750 
		
		node), split, n, deviance, yval
		      * denotes terminal node
		
		 1) root 3750 2945.53200 5.870933  	
		   2) alcohol< 10.85 2372 1418.86100 5.604975  	
		     4) volatile.acidity>=0.2275 1611  821.30730 5.432030  
		       8) volatile.acidity>=0.3025 688  278.97670 5.255814 *
		       9) volatile.acidity< 0.3025 923  505.04230 5.563380 *
		     5) volatile.acidity< 0.2275 761  447.36400 5.971091 *
		   3) alcohol>=10.85 1378 1070.08200 6.328737  
		     6) free.sulfur.dioxide< 10.5 84   95.55952 5.369048 *
		     7) free.sulfur.dioxide>=10.5 1294  892.13600 6.391036  
		      14) alcohol< 11.76667 629  430.11130 6.173291  
		        28) volatile.acidity>=0.465 11   10.72727 4.545455 *
		        29) volatile.acidity< 0.465 618  389.71680 6.202265 *
		      15) alcohol>=11.76667 665  403.99400 6.596992 *

			설명 : * 표시가 있는 노드는 앞노드로, 노드에서 예측이 이뤄진다는 것을 의미한다.
			       와인 데이터이면 예측 등급이다.
			       5.97이라는 등급으로 예를 들면 alcohol < 10.85 이고 
			       volatile.acidity < 0.2275이면 모든 와인 샘플 품질값이 5.97로 예측된다.


	5. 위에서 나온 모델로 트리를 시각화 하시오 !

		library(rpart.plot)
		rpart.plot( model, digits=3)

		rpart.plot(model, digits=3, fallen.leaves=T, type=3, extra=101)


	6. 위에서 만든 모델로 테스트 데이터의 라벨을 예측하시오 !

		result <- predict(model, wine_test) 
		result

		    3751     3752     3753     3754     3755     3756     3757 
		6.596992 5.255814 6.202265 5.971091 5.563380 6.596992 5.255814 
		    3758     3759     3760     3761     3762     3763     3764 
					:
					:
		5.971091 6.596992 5.563380 5.971091 5.255814 5.563380 5.563380 
		    4745     4746     4747     4748     4749     4750 
		5.255814 6.596992 5.255814 6.202265 5.255814 6.596992 
		 [ reached getOption("max.print") -- omitted 148 entries ]


	7. 테스트 데이터의 실제 라벨(품질) 과 예측결과(품질) 을 비교한다

		cbind( round(result), wine_test$quality)


	8. 테스트 데이터의 라벨과 예측 결과와 상관관계가 어떻게 되는지
	   확인한다.

		cor(result, wine_test$quality)	# [1] 0.5369525

		설명 : 0.53은 두 데이터간의 연관 강도만 측정하는것이다.

		      그래서 두 데이터간의 오차율이 어떻게 되는지 확인해서
		      이 오차율을 줄여나가겠금 모델을 튜닝을 한다.


	9. 두 데이터간의 오차율을 확인 

		MAE <-  function( actual, predicted) {
		             mean(  abs( actual - predicted) ) 
                                     }

		MAE( result, wine_test$quality) 	# [1] 0.5872652

		0.58  <---   이 모델의 경우 다른 모델인 서포트 벡터 머신에서의
		             오차는 0.45 인데 0.58이면 상대적으로 좀 큰 오차이
		             므로 개선의 여지가 필요하다.


		개선방법이 회귀트리 ----> 모델트리로 변경해서 개선을 한다.










■ 와인 데이터의 품질을 예측하는 모델을 모델트리를 이용해서 생성


	 분할한 후에 평균값 대신 회귀식을 이용해서 수치를 예측한다. 

	1. 회귀트리 모델 생성하는 작업의 1번 ~ 3번까지 다시 반복 

	2. 모델트리를 구현하기 위한 패키지 설치

		  library(RWeka)
	
	3. 와인의 품질을 예측하는 모델을 생성한다. 
	
	4. 만든 모델과 테스트 데이터로 예측을 한다.

		  p.m5p <- predict( m.m5p, wine_test) 

	5. 예측값(p.m5p) 과 테스트 데이터의 라벨간의 상관관계를 확인한다

		  cor( p.m5p , wine_test$quality )

		  0.62729

	5. 예측값(p.m5p) 과 테스트 데이터의 라벨간의 평균절대오차를 확인한다.

		  MAE( wine_test$quality, p.m5p)  

		  0.5463


		3?? 05, 2019 11:35:00 ???? com.github.fommil.netlib.BLAS <clinit>
		????: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
		3?? 05, 2019 11:35:00 ???? com.github.fommil.netlib.BLAS <clinit>
		????: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
		3?? 05, 2019 11:35:00 ???? com.github.fommil.netlib.LAPACK <clinit>
		????: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK
		3?? 05, 2019 11:35:00 ???? com.github.fommil.netlib.LAPACK <clinit>
		????: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK










문제 241. 보스턴 하우징 데이터(보스턴 지역의 집값) 을 이용해서 회귀트리 모델을 생성하시오 !
	  범죄율, 방의 갯수, 지역의 학교교사의 숫자, 강과 인접한 거리등의 데이터를 확인해서 회귀트리 
	  생성
	  (라벨 : MEDV(집값), cat.NEDV(주택가격이 3만달러가 넘는지 안넘는지에 대한 라벨))

	# 데이터를 로드한다. 
	boston <- read.csv("D:/data/boston.csv")
	
	# 본래 데이터의 최소값, 최대값 비교
	summary(boston$MEDV)
	
	
	# 훈련과 테스트 데이터 생성
	boston_train <- boston[1:495, ]
	boston_test <- boston[496:506, ]
	
	str(boston_train)
	
	# 회귀트리 모델을 생성한다.
	
	model <-  rpart( MEDV ~ . , data=boston_train)
	
	model 
	
	# 생성된 모델과 테스트 데이터로 예측한다.
	
	result <- predict(model, boston_test) 
	
	# 결과와 실제 테스트 라벨과의 상관정도를 확인한다.
	
	cor(result, boston_test$MEDV)
	
	0.2808209
	
	# 결과와 실제 테스트 라벨과의 평균절대오차를 확인한다. 
	
	MAE <-  function( actual, predicted) {
	  mean(  abs( actual - predicted) ) 
	}
	
	MAE( result, boston_test$MEDV) 
	
	 3.484211
	
	# 이번에는 보스톤 하우징 데이터를 모델트리로 구현해서 성능을 
	  높여본다. 
	
	library(RWeka)
	
	m.m5p <- M5P(MEDV ~ . , data=boston_train)
	
	p.m5p <- predict( m.m5p, boston_test) 

	cor( p.m5p , boston_test$MEDV )
	
	0.506185
	
	MAE( boston_test$MEDV, p.m5p) 
	
	2.869352
	




문제 241. (점심시간 문제) R 샤이니 최종 코드에 다중회귀 메뉴를 추가하시오 !
	  왓슨 메인화면 ─▶ 의사결정 트리, 














■ 7장. 신경망과 서포트 벡터 머신 

	  * 목차  
	
		   1. 활성화 함수 소개
		   2. 신경망 실습 1 ( 콘크리트 데이터)
		   3. 신경망 실습 2 ( 필기체 데이터 )
		   4. 신경망 실습 3 ( 전력 생산량 데이터) 









■ 1. 활성화 함수 소개 

	  활성화 함수란 ?   입력신호의 총합이 활성화를 일으킬지를 
	                    정하는 역활을 하는 함수 

	   k =  x0*w0 + x1*w1 + x2*w2
	
	   y = f(k)
	
	   1  :  신호가 흐른다.
	   0  :  신호가 안흐른다.
	
	 * 활성화 함수의 종류 
	
		    1. 계단함수
		    2. 시그모이드 함수
		    3. 렐루 함수 



문제 242. R로 relu함수를 만들고 relu 함수 그래프를 그리시오

	파이썬 코드 :
	
		import  numpy  as  np
		
		def  relu(x):
		    return  np.maximum(0,x)  # 0 과 x 값중에 큰값을 출력해라 !
		
		print (relu(-2))
		print (relu(0.3))

	R코드 :

		relu <- function(x) { ifelse( x>0 , x, 0 ) }
		
		x <- seq(-10, 10, 0.01)
		
		plot( x, relu(x), col = "red")




문제 243. 계단함수를 R로 구현하고 계단함수 그래프를 그리시오.

	* 계단함수 f(0.3) = 1, f(-0.2) = 0

                    0을 임계치로 해서 임계치 이상이면 1 아니면 0을 출력하는 함수로 생성하세요


	step <- function(x) { ifelse( x>=0, 1, 0 ) }
	
	x <- seq( -5, 5, 0.01)
	
	plot( x, step(x), col = "blue", type='l')




문제244. R 로 시그모이드 함수를 생성하고 그래프로 시각화 하시오 !

	파이썬 : 

		x = np.arange(-5,5,0.1)
		print (x)
	
		def  sigmoid(x):
		    return 1 / (1 + np.exp(-x) )
		
		y = sigmoid(x)
	
	R 코드 : 

		sigmoid <- function(x) { ifelse( 1 / (1 + exp(-x))) }
		
		x <- seq( -5, 5, 0.01)











■ 신경망 실습1 (콘크리트 데이터)


	" 콘크리트의 강도를 예측하는 신경망을 만드는 학습 "
	
	자갈, 모래, 시멘트등을 몇대 몇 비율로 섞었을 때 어느정도 강도가 나오는지 예측하는 신경망





	1.  콘크리트 데이터 소개 
	
		* 콘크리트 데이터 
		
		 1. mount of cement: 콘크리트의 총량
		 2. slag  :  시멘트 
		 3. ash   :  분 (시멘트)
		 4. water :  물
		 5. superplasticizer :  고성능 감수재(콘크리트 강도를 높이는 첨가제)
		 6. coarse aggregate :  굵은 자갈
		 7. fine  aggregate :  잔 자갈
		 8. aging time  :  숙성시간 
		 
	2.  콘크리트 데이터를 R 로 로드한다.
	
	 -  머신러닝 데이터 116번 
	
		concrete <- read.csv("concrete.csv")
		str(concrete)
	
	3.  정규화 함수로 데이터를 정규화 작업
	
		normalize <- function(x) {
		    return ( (x-min(x)) / (max(x) - min(x) ) )
		                         }
		
		concrete_norm <- as.data.frame(lapply(concrete,normalize) ) 
	
	4.  0~1사이로 데이터가 잘 변경되었는지 확인 
	
		summary( concrete_norm$strength)
	
		# 본래 데이터의 최소값, 최대값과 비교 
		
		summary( concrete$strength)
	
	5.  훈련 데이터,테스트 데이터를 나눈다 (8:2)
	
		concrete_train <- concrete_norm[1:773, ]
		concrete_test  <- concrete_norm[774:1030, ]
	
	6.  neuralnet 패키지를 설치한다.
	
		install.packages("neuralnet")
		library(neuralnet) 
	
	7.  neuralnet 패키지에 콘크리트 훈련 데이터를 넣어서
	    모델을 생성한다.
	
		concrete_model <- neuralnet(formula=strength ~ cement + slag + ash  +
		water +superplastic + coarseagg  + fineagg  + age,
		 data =concrete_train)   
		
	
	9. 모델(신경망) 을 시각화
	
		plot(concrete_model )
	
	10. 만든 모델로 테스트 데이터를 가지고 테스트 한다
	
		model_results <-  compute(concrete_model, concrete_test[1:8])
	
		predicted_strength <-  model_results$net.result
	
	11.  예측값과 실제값간의 상관관계를 확인 
	     
		cor(predicted_strength, concrete_test$strength)
		
		 0.806285848
	
	12. 모듈의 성능 개선
	
		concrete_model2 <- neuralnet(formula = strength ~ cement + slag+
		                                ash + water + superplastic + coarseagg + fineagg + age,
		                              data = concrete_train, hidden = c(5,2) )
		
		※ 설명 : hidden c(5,         2)
  			           ↑         ↑
			은닉 1층의 노드수   은닉 2층의 노드수
		
		plot(concrete_model2)
		
	13. 만든 모델로 테스트 데이터를 가지고 테스트 한다
		
		model_results2 <-  compute(concrete_model2, concrete_test[1:8])
		
		predicted_strength2 <-  model_results2$net.result
	
	14.  예측값과 실제값간의 상관관계를 확인 
	     
		cor(predicted_strength2, concrete_test$strength)
		
		 0.9310356










■ 회귀 트리일 때 사용했던 와인 데이터를 신경망에 넣고 테스트

	회귀트리 모델의 결과 (상관관계) : 0.53





■ 5. 신경망 실습 2(와인 데이터 )

	 신경망 R 패키지 : 1. neuralnet 패키지(콘크리트 데이터)
	
	                   2. nnet  패키지 (와인 데이터)
	
	1. nnet 패키지를 설치한다
	
		install.packages("nnet")
		library(nnet)
	
	2. wine 데이터를 로드한다
	
		wine <- read.csv("wine.csv")
		head(wine)
		str(wine)
	
	3. 정규화 작업을 진행한다
	
		wine_norm <- cbind(wine[1], scale(wine[-1]) )
		size <- nrow(wine_norm)
		size
	
		summary(wine_norm)
	
	4. 7:3으로 훈련데이터와 테스트 데이터를 분리한다
	
		set.seed(100)
		index <- c( sample(1:size, size *0.7) )
		
		train <- wine_norm[index, ]
		test  <- wine_norm[-index, ]
	
	
	5. 훈련 데이터로 신경망 모델을 생성한다.
	
		wine_model <- nnet(Type ~ ., data = train, size=2,
		                    decay=5e-04 , maxit=200 )  
	
		설명 :  size =2 은닉층의 뉴런수 
		        decay = 5e-04 가중치감소
			maxit = 200    200에폭
	   
	6. 테스트 데이터를 모델에 넣어서 결과를 예측한다.
	
		predicted_result <- predict(wine_model, test, type = 'class')
		
		predicted_result
	
	7. 이원 교차표를 그리고 정확도를 확인한다.
	
		actual <- test$Type
		table(actual, predicted_result)
	
		model.confusion.matrix <- table(actual, predicted_result)
		
		library(gmodel)
		CrossTable(model.confusion.matrix)
	
		             | predicted_result2 
		      actual |        t1 |        t2 |        t3 | Row Total | 
		-------------|-----------|-----------|-----------|-----------|
		          t1 |        18 |         0 |         0 |        18 | 
		             |    24.000 |     6.000 |     6.000 |           | 
		             |     1.000 |     0.000 |     0.000 |     0.333 | 
		             |     1.000 |     0.000 |     0.000 |           | 
		             |     0.333 |     0.000 |     0.000 |           | 
		-------------|-----------|-----------|-----------|-----------|
		          t2 |         0 |        18 |         1 |        19 | 
		             |     6.333 |    21.491 |     4.491 |           | 
		             |     0.000 |     0.947 |     0.053 |     0.352 | 
		             |     0.000 |     1.000 |     0.056 |           | 
		             |     0.000 |     0.333 |     0.019 |           | 
		-------------|-----------|-----------|-----------|-----------|
		          t3 |         0 |         0 |        17 |        17 | 
		             |     5.667 |     5.667 |    22.667 |           | 
		             |     0.000 |     0.000 |     1.000 |     0.315 | 
		             |     0.000 |     0.000 |     0.944 |           | 
		             |     0.000 |     0.000 |     0.315 |           | 
		-------------|-----------|-----------|-----------|-----------|
		Column Total |        18 |        18 |        18 |        54 | 
		             |     0.333 |     0.333 |     0.333 |           | 
		-------------|-----------|-----------|-----------|-----------|




문제 245. 위의 신경망의 뉴런수를 늘려서 1개 못맞춘것도 맞추는지 100%의 정확도가 될 수 있도록 성능을 
	  높이시오 (오늘의 마지막 문제)

	library(nnet)
	wine <- read.csv("wine.csv")
	head(wine)
	str(wine)
	wine_norm <- cbind(wine[1], scale(wine[-1]) )
	size <- nrow(wine_norm)
	size
	summary(wine_norm)
	set.seed(100)
	index <- c( sample(1:size, size *0.7) )
	index
	train <- wine_norm[index, ]
	test  <- wine_norm[-index, ]
	test
	wine_model <- nnet(Type ~ ., data = train, size=10,
	                   decay=5e-04 , maxit=200 )  
	predicted_result2 <- predict(wine_model, test, type = 'class')
	
	predicted_result2
	actual <- test$Type
	table(actual, predicted_result2)
	
	model.confusion.matrix <- table(actual, predicted_result2)
	
	library(gmodels)
	CrossTable(model.confusion.matrix)

	             | predicted_result2 
	      actual |        t1 |        t2 |        t3 | Row Total | 
	-------------|-----------|-----------|-----------|-----------|
	          t1 |        20 |         0 |         0 |        20 | 
	             |    21.407 |     7.778 |     4.815 |           | 
	             |     1.000 |     0.000 |     0.000 |     0.370 | 
	             |     1.000 |     0.000 |     0.000 |           | 
	             |     0.370 |     0.000 |     0.000 |           | 
	-------------|-----------|-----------|-----------|-----------|
	          t2 |         0 |        21 |         0 |        21 | 
	             |     7.778 |    20.167 |     5.056 |           | 
	             |     0.000 |     1.000 |     0.000 |     0.389 | 
	             |     0.000 |     1.000 |     0.000 |           | 
	             |     0.000 |     0.389 |     0.000 |           | 
	-------------|-----------|-----------|-----------|-----------|
	          t3 |         0 |         0 |        13 |        13 | 
	             |     4.815 |     5.056 |    31.130 |           | 
	             |     0.000 |     0.000 |     1.000 |     0.241 | 
	             |     0.000 |     0.000 |     1.000 |           | 
	             |     0.000 |     0.000 |     0.241 |           | 
	-------------|-----------|-----------|-----------|-----------|
	Column Total |        20 |        21 |        13 |        54 | 
	             |     0.370 |     0.389 |     0.241 |           | 
	-------------|-----------|-----------|-----------|-----------|